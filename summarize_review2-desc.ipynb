{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing Text with Desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "To build our model we will use a two-layered bidirectional RNN with LSTMs on the input data and two layers, each with an LSTM using bahdanau attention on the target data.\n",
    "\n",
    "The sections of this project are:\n",
    "- [1.Inspecting the Data](#1.-Insepcting-the-Data)\n",
    "- [2.Preparing the Data](#2.-Preparing-the-Data)\n",
    "- [3.Building the Model](#3.-Building-the-Model)\n",
    "- [4.Training the Model](#4.-Training-the-Model)\n",
    "- [5.Making Our Own Summaries](#5.-Making-Our-Own-Summaries)\n",
    "\n",
    "The model is trained with amazon review data.\n",
    "\n",
    "## Download data\n",
    "Amazon Reviews Data: [Reviews.csv](https://www.kaggle.com/snap/amazon-fine-food-reviews/downloads/Reviews.csv)\n",
    "\n",
    "\n",
    "Data set locations for testing:\n",
    "\n",
    "https://drive.google.com/drive/folders/1QMxZaAMIDFBGCJaWc-453z4NLUDQHE9X?usp=sharing\n",
    "\n",
    "word embeddings [numberbatch-en-17.06.txt.gz] (https://conceptnet.s3.amazonaws.com/downloads/2017/numberbatch/numberbatch-en-17.06.txt.gz)\n",
    "after download, extract to **./model/numberbatch-en-17.06.txt**\n",
    "\n",
    "\n",
    "or glove \n",
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.12.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import tensor_array_ops\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def __pickleStuff(filename, stuff):\n",
    "    save_stuff = open(filename, \"wb\")\n",
    "    pickle.dump(stuff, save_stuff)\n",
    "    save_stuff.close()\n",
    "def __loadStuff(filename):\n",
    "    saved_stuff = open(filename,\"rb\")\n",
    "    stuff = pickle.load(saved_stuff)\n",
    "    saved_stuff.close()\n",
    "    return stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you 'll\": \"you will\",\n",
    "\"you're\": \"you are\",\n",
    " \"km\" : \"kilometers\",\n",
    "    \"mi\" : \"miles\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_text (data,keys):\n",
    "    tokens_list = []\n",
    "    for item in data:\n",
    "        for i in keys:\n",
    "            d = item[i] \n",
    "            d = d.encode(\"utf8\") \n",
    "            tokens = clean_doc(d)    \n",
    "             \n",
    "            tokens_list.append(str(tokens))\n",
    "     \n",
    "    return tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "# turn a doc into clean tokens\n",
    "\n",
    "regnumber = re.compile(r'^\\d+(?:[,.]\\d*)?$')\n",
    "alpha = r'[a-zA-Z]+'\n",
    "number = r'[-+]?[0-9]*(\\.|:)?[0-9]+'\n",
    "def clean_doc(doc):\n",
    "    # split into tokens by white space\n",
    "    ##tokens = doc.split()\n",
    "    # remove punctuation from each token\n",
    "    #table = string.maketrans('', '', punctuaion)\n",
    "    #tokens = [w.translate(table) for w in tokens]\n",
    "    \n",
    "    # We are not using \"text.split()\" here\n",
    "    #since it is not fool proof, e.g. words followed by punctuations \"Are you kidding?I think you aren't.\"\n",
    "    #text = re.findall(r\"[a-zA-Z]+\", doc) #[-+]?[0-9]*\\.?[0-9]+\n",
    "    text = re.findall(r\"([a-zA-Z\\'']+|[-+]?[0-9]*\\.?[0-9]+)\", doc)\n",
    "    \n",
    "    #text = re.findall(r\"[a-zA-Z\\'']+\",doc)\n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        if word in contractions:\n",
    "            new_text.append(contractions[word])\n",
    "             \n",
    "        else:\n",
    "\n",
    "            new_text.append(word)\n",
    "    #new_text = [w for w in new_text if w in vocab]\n",
    "    text = \" \".join(new_text)\n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%!:#$@\\[\\]/]', ' ', text) #skip \".,?\"\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    return text\n",
    "                      \n",
    "    #for w in tokens:         \n",
    "    #    w =  re.sub('['+string.punctuation+']', '', w )       \n",
    "    # filter out tokens not in vocab\n",
    "    \n",
    "    #tokens = [w for w in tokens if w in vocab]\n",
    "    #tokens = ' '.join(tokens)\n",
    "     \n",
    "    #return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os import listdir\n",
    "# load all docs in a directory\n",
    "def process_docs(directory):\n",
    "\tdocuments = []\n",
    "\t# walk through all files in the folder\n",
    "\tfor filename in listdir(directory):\n",
    "\t    # create the full path of the file to open\n",
    "\t    path = directory + '/' + filename\n",
    "\t    # load the doc\n",
    "\t    #doc = load_doc(path)\n",
    "\t    with open(path, \"r\") as f:\n",
    "\t \t     doc = json.load(f)\n",
    "\t    #tokens_list = select_text (doc ,['description','facility','nearby'])\n",
    "\t    # clean doc\n",
    "\t    tokens_list = select_text (doc ,['description']) \n",
    "\t    #tokens = clean_doc(doc[, vocab)\n",
    "\t    # add to list\n",
    "\t    documents.extend(tokens_list)\n",
    "        #print(tokens_list[:5])\n",
    "\treturn documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['With a stay at Petpimarn Boutique Resort in Bangkok Chatuchak you will be within a 15 minute drive of Kasetsart University and IMPACT Arena This hotel is 9.7 miles 15.6 kilometers from Temple of the Emerald Buddha and 10 miles 16.2 kilometers from Wat Arun Make yourself at home in one of the 89 air conditioned rooms featuring refrigerators Complimentary wireless Internet access keeps you connected and digital programming is available for your entertainment Bathrooms have showers and complimentary toiletries Conveniences include desks and complimentary bottled water and housekeeping is provided daily Make use of convenient amenities which include complimentary wireless Internet access and tour ticket assistance At Petpimarn Boutique Resort enjoy a satisfying meal at the restaurant English breakfasts are available daily from 6 30 AM to 10 AM for a fee Featured amenities include dry cleaning laundry services a 24 hour front desk and luggage storage Free self parking is available onsite',\n",
       " 'Airport Suite Bangkok Don Muang Airport is located in area city Don Mueang Airport The hotel has a very good location also near the Don Mueang International Airport DMK which is only 2.85 kilometers away There are plenty of tourist attractions nearby such as IT Square within 1.18 kilometers and Central Ramintra within 2.67 kilometers Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at Airport Suite Bangkok Don Muang Airport The hotel s fitness center is a must try during your stay here Have an enjoyable and relaxing day at the pool whether you re traveling solo or with your loved ones Get the best deal for finest quality of spa treatment to unwind and rejuvenate yourself 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from Airport Suite Bangkok Don Muang Airport exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends With all facilities offered Airport Suite Bangkok Don Muang Airport is the right place to stay',\n",
       " 'With a stay at The Riche Residence in Bangkok Don Muang you will be 12 minutes by car from Kasetsart University This hotel is 11.2 miles 18 kilometers from Temple of the Emerald Buddha and 11.6 miles 18.6 kilometers from Wat Arun Make yourself at home in one of the 68 air conditioned rooms featuring refrigerators and flat screen televisions Rooms have private balconies Complimentary wireless Internet access keeps you connected and cable programming is available for your entertainment Private bathrooms with showers feature complimentary toiletries and hair dryers For lunch or dinner stop by The Riche Residence a restaurant that specializes in fusion cuisine Dining is also available at the coffee shop caf and 24 hour room service is provided Continental breakfasts are available daily from 6 AM to 10 AM for a fee Featured amenities include dry cleaning laundry services a 24 hour front desk and luggage storage Free self parking is available onsite',\n",
       " 'With a stay at Regent Home 1 at Donmuang in Bangkok Don Muang you will be 9.3 miles 15 kilometers from Chatuchak Weekend Market and 17.2 miles 27.7 kilometers from Temple of the Emerald Buddha This apartment is 17.6 miles 28.3 kilometers from Grand Palace and 17.7 miles 28.4 kilometers from Wat Pho Make yourself at home in one of the 2 air conditioned rooms featuring kitchens with refrigerators and ovens Rooms have private balconies 32 inch LCD televisions with digital programming provide entertainment while complimentary wireless Internet access keeps you connected Conveniences include separate sitting areas and electric kettles and housekeeping is provided once per stay Take advantage of recreation opportunities including an outdoor pool and a fitness center Featured amenities include dry cleaning laundry services luggage storage and an elevator lift Free self parking is available onsite',\n",
       " 'With a stay at Charoenpong Apartment in Bangkok Don Muang you will be 13 minutes by car from Sripatum University This guesthouse is 10.2 miles 16.4 kilometers from Chatuchak Weekend Market and 13.9 miles 22.4 kilometers from Suan Pakkard Palace Make yourself at home in one of the 5 air conditioned rooms featuring flat screen televisions Complimentary wireless Internet access keeps you connected and cable programming is available for your entertainment Bathrooms have showers and complimentary toiletries Conveniences include desks and blackout drapes curtains and housekeeping is provided daily Take in the views from a terrace and make use of amenities such as complimentary wireless Internet access Featured amenities include a 24 hour front desk and laundry facilities Free self parking is available onsite']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all training text\n",
    "hotel_docs = process_docs('./datajson')\n",
    "hotel_docs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load those prepared data and skip to section \"[3. Building the Model](#3.-Building-the-Model)\"\n",
    "Once we have run through the \"[2.Preparing the Data](#2.-Preparing-the-Data)\" section, we should have those data, uncomment and run those lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_summaries = __loadStuff(\"./data/clean_summaries.p\")\n",
    "clean_texts = __loadStuff(\"./data/clean_texts.p\")\n",
    "\n",
    "sorted_summaries = __loadStuff(\"./data/sorted_summaries.p\")\n",
    "sorted_texts = __loadStuff(\"./data/sorted_texts.p\")\n",
    "word_embedding_matrix = __loadStuff(\"./data/word_embedding_matrix.p\")\n",
    "\n",
    "vocab_to_int = __loadStuff(\"./data/vocab_to_int.p\")\n",
    "int_to_vocab = __loadStuff(\"./data/int_to_vocab.p\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Insepcting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         0\n",
       "ProductId                  0\n",
       "UserId                     0\n",
       "ProfileName               16\n",
       "HelpfulnessNumerator       0\n",
       "HelpfulnessDenominator     0\n",
       "Score                      0\n",
       "Time                       0\n",
       "Summary                   27\n",
       "Text                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for any nulls values\n",
    "reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove null values and unneeded features\n",
    "reviews = reviews.dropna()\n",
    "reviews = reviews.drop(['Id','ProductId','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator',\n",
    "                        'Score','Time'], 1)\n",
    "reviews = reviews.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568411, 2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Summary                                               Text\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...\n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...\n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...\n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...\n",
       "4            Great taffy  Great taffy at a great price.  There was a wid..."
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Review #', 1)\n",
      "Good Quality Dog Food\n",
      "I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.\n",
      "()\n",
      "('Review #', 2)\n",
      "Not as Advertised\n",
      "Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
      "()\n",
      "('Review #', 3)\n",
      "\"Delight\" says it all\n",
      "This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.\n",
      "()\n",
      "('Review #', 4)\n",
      "Cough Medicine\n",
      "If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal.\n",
      "()\n",
      "('Review #', 5)\n",
      "Great taffy\n",
      "Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# Inspecting some of the reviews\n",
    "for i in range(5):\n",
    "    print(\"Review #\",i+1)\n",
    "    print(reviews.Summary[i])\n",
    "    print(reviews.Text[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\",\n",
    " \"km\"   : 'kilometers',\n",
    "    \"mi\": 'miles'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "regnumber = re.compile(r'^\\d+(?:[,.]\\d*)?$')\n",
    "\n",
    "def clean_text(text, remove_stopwords = True):\n",
    "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
    "    \n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace contractions with their longer forms \n",
    "    if True:\n",
    "        # We are not using \"text.split()\" here\n",
    "        #since it is not fool proof, e.g. words followed by punctuations \"Are you kidding?I think you aren't.\"\n",
    "        text = re.findall(r\"[\\w']+\", text)\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "    \n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)# remove links\n",
    "    text = re.sub(r'\\<a href', ' ', text)# remove html link tag\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great movie believe may'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(\"That's a great movie,Can you believe it?I've.But you may not.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the summaries and texts\n",
    "We will remove the stopwords from the texts because they do not provide much use for training our model. However, we will keep them for our summaries so that they sound more like natural phrases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries are complete.\n",
      "Texts are complete.\n"
     ]
    }
   ],
   "source": [
    "clean_summaries = []\n",
    "for summary in reviews.Summary:\n",
    "    clean_summaries.append(clean_text(summary, remove_stopwords=False))\n",
    "print(\"Summaries are complete.\")\n",
    "\n",
    "clean_texts = []\n",
    "for text in reviews.Text:\n",
    "    clean_texts.append(clean_text(text))\n",
    "print(\"Texts are complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Clean Review #', 1)\n",
      "good quality dog food\n",
      "bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better\n",
      "()\n",
      "('Clean Review #', 2)\n",
      "not as advertised\n",
      "product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo\n",
      "()\n",
      "('Clean Review #', 3)\n",
      "delight says it all\n",
      "confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story c lewis lion witch wardrobe treat seduces edmund selling brother sisters witch\n",
      "()\n",
      "('Clean Review #', 4)\n",
      "cough medicine\n",
      "looking secret ingredient robitussin believe found got addition root beer extract ordered good made cherry soda flavor medicinal\n",
      "()\n",
      "('Clean Review #', 5)\n",
      "great taffy\n",
      "great taffy great price wide assortment yummy taffy delivery quick taffy lover deal\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# Inspect the cleaned summaries and texts to ensure they have been cleaned well\n",
    "for i in range(5):\n",
    "    print(\"Clean Review #\",i+1)\n",
    "    print(clean_summaries[i])\n",
    "    print(clean_texts[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the number of occurrences of each word in a set of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(count_dict, text):\n",
    "    for sentence in text:\n",
    "        for word in sentence.split():\n",
    "            if word not in count_dict:\n",
    "                count_dict[word] = 1\n",
    "            else:\n",
    "                count_dict[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give the function a try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2, 'dog': 2, 'great': 4, 'have': 1, 'is': 1, 'that': 1, 'you': 1}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {}\n",
    "count_words(mydict, [\"that is a great great great dog\",\"you have a great dog\"])\n",
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Size of Vocabulary:', 125808)\n"
     ]
    }
   ],
   "source": [
    "word_counts = {}\n",
    "count_words(word_counts, clean_summaries)\n",
    "count_words(word_counts, clean_texts)\n",
    "print(\"Size of Vocabulary:\", len(word_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how may \"hero\" occurs in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts[\"hero\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load Conceptnet Numberbatch's (CN) embeddings, similar to GloVe, but probably better \n",
    " (https://github.com/commonsense/conceptnet-numberbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.word2vec as w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename50 =\"../trained/hotel2vec_desc-50.w2v\"\n",
    "filename300 =\"../trained/hotel2vec_desc-300.w2v\"\n",
    "filename_dnum =\"../trained/hotel2vec_desc-number.w2v\"\n",
    "filename_d_gg = '../trained/hotel2vec-gg-desc-300.w2v'\n",
    "\n",
    "filename_glove_300 = '../glove.6B.300d.txt'\n",
    "filename_glove_50 = '../glove.6B.50d.txt'\n",
    "filename_num = '../numberbatch-en-17.02.txt'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#load model gg\n",
    "model_gg =  KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin',binary=True)\n",
    "vocab_gg = model_gg.vocab.keys()\n",
    "wordsInVocab = len(vocab_gg)\n",
    " \n",
    "embeddings_index = {}\n",
    "for v in vocab_gg:\n",
    "     \n",
    "    word = v \n",
    "    embedding = np.asarray(model_gg.wv[v], dtype='float32')\n",
    "    embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings:', len(embeddings_index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load extra des on top of model_gg\n",
    "\n",
    "filename = filename_d_gg\n",
    "\n",
    "model_gg_d =  w2v.Word2Vec.load(filename)\n",
    "word_vectors = model_gg_d.wv\n",
    "\n",
    "vocab_gg = word_vectors.vocab\n",
    " \n",
    "for v in vocab_gg:\n",
    "     \n",
    "    word = v.decode('utf-8')\n",
    "    embedding = np.asarray(model_gg_d.wv[v], dtype='float32')\n",
    "    embeddings_index[word] = embedding\n",
    "\n",
    "\n",
    "print('Word embeddings:', len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Word embeddings:', 400000)\n",
      "('Word embeddings:', 400918)\n"
     ]
    }
   ],
   "source": [
    "#load based model\n",
    "filename = filename_glove_50\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(filename) as f:\n",
    "#with open('./model/numberbatch-en-17.06.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0].decode('utf-8')\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings:', len(embeddings_index))\n",
    "\n",
    "#load desc model\n",
    "filename = filename50\n",
    "\n",
    "\n",
    "\n",
    "model_d =  w2v.Word2Vec.load(filename)\n",
    "word_vectors = model_d.wv\n",
    "\n",
    "vocab_gg = word_vectors.vocab\n",
    " \n",
    "for v in vocab_gg:\n",
    "     \n",
    "    word = v \n",
    "    embedding = np.asarray(model_d.wv[v], dtype='float32')\n",
    "    embeddings_index[word] = embedding\n",
    "    \n",
    "print('Word embeddings:', len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-64c1bc41c6dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m        \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m        \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m        \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m        \u001b[0membeddings_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " #load based model\n",
    "filename = filename_glove_300\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(filename) as f:\n",
    "#with open('./model/numberbatch-en-17.06.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0].decode('utf-8')\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings:', len(embeddings_index))\n",
    "\n",
    "#load desc model\n",
    "filename = filename300\n",
    "\n",
    "model_d =  w2v.Word2Vec.load(filename)\n",
    "word_vectors = model_d.wv\n",
    "\n",
    "vocab_gg = word_vectors.vocab\n",
    " \n",
    "for v in vocab_gg:\n",
    "     \n",
    "    word = v \n",
    "    embedding = np.asarray(model_d.wv[v], dtype='float32')\n",
    "    embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings:', len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Word embeddings:', 484557)\n"
     ]
    }
   ],
   "source": [
    "#load based model\n",
    "filename = filename_num\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(filename) as f:\n",
    "#with open('./model/numberbatch-en-17.06.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0].decode('utf-8')\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings:', len(embeddings_index))\n",
    "\n",
    "#load desc model\n",
    "filename = filename_dnum\n",
    "\n",
    "model_d =  w2v.Word2Vec.load(filename)\n",
    "word_vectors = model_d.wv\n",
    "\n",
    "vocab_gg = word_vectors.vocab\n",
    " \n",
    "for v in vocab_gg:\n",
    "     \n",
    "    word = v.decode('utf-8')\n",
    "    embedding = np.asarray(model_d.wv[v], dtype='float32')\n",
    "    embeddings_index[word] = embedding\n",
    " \n",
    "\n",
    "print('Word embeddings:', len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the CN embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index[\"hero\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the number of words that are missing from CN, and are used more than our threshold.\n",
    "\n",
    "I use a **threshold** of 20, so that words not in CN can be added to our **word_embedding_matrix**, but they need to be common enough in the reviews so that the model can understand their meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of words missing from CN:', 1972)\n",
      "Percent of words that are missing from vocabulary: 0.0%\n"
     ]
    }
   ],
   "source": [
    "missing_words = 0\n",
    "threshold = 20\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    if count > threshold:\n",
    "        if word not in embeddings_index:\n",
    "            missing_words += 1\n",
    "            \n",
    "missing_ratio = round(missing_words/len(word_counts),4)*100\n",
    "            \n",
    "print(\"Number of words missing from CN:\", missing_words)\n",
    "print(\"Percent of words that are missing from vocabulary: {}%\".format(missing_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are those missing words in the CN\n",
    "Looks mostly products' brand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pizzle', 54),\n",
       " ('27g', 38),\n",
       " ('shelties', 129),\n",
       " ('cuddlecuss', 21),\n",
       " ('sandies', 50),\n",
       " ('golean', 276),\n",
       " ('33oz', 35),\n",
       " ('detangling', 32),\n",
       " ('calbee', 45),\n",
       " ('caribu', 29),\n",
       " ('eiermann', 31),\n",
       " ('bluberry', 31),\n",
       " ('completly', 88),\n",
       " ('wheatena', 77),\n",
       " ('flatulance', 29),\n",
       " ('perfumey', 86),\n",
       " ('caramello', 30),\n",
       " ('peanutty', 179),\n",
       " ('eacute', 945),\n",
       " ('wayy', 24),\n",
       " ('unpleasent', 27),\n",
       " ('sprouter', 121),\n",
       " ('shakeology', 27),\n",
       " ('xylosweet', 56),\n",
       " ('foodshouldtastegood', 99),\n",
       " ('teavana', 532),\n",
       " ('cyto', 30),\n",
       " ('proteinate', 233),\n",
       " ('tobacman', 39),\n",
       " ('recomended', 191)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_words = []\n",
    "for word, count in word_counts.items():\n",
    "    if count > threshold and word not in embeddings_index:\n",
    "        missing_words.append((word,count))\n",
    "missing_words[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words to indexes, indexes to words dicts\n",
    "Limit the vocab that we will use to words that appear ≥ threshold or are in CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total number of unique words:', 125808)\n",
      "('Number of words we will use:', 63898)\n",
      "Percent of words we will use: 0.0%\n"
     ]
    }
   ],
   "source": [
    "#dictionary to convert words to integers\n",
    "vocab_to_int = {} \n",
    "# Index words from 0\n",
    "value = 0\n",
    "for word, count in word_counts.items():\n",
    "    if count >= threshold or word in embeddings_index:\n",
    "        vocab_to_int[word] = value\n",
    "        value += 1\n",
    "\n",
    "# Special tokens that will be added to our vocab\n",
    "codes = [\"<UNK>\",\"<PAD>\",\"<EOS>\",\"<GO>\"]   \n",
    "\n",
    "# Add codes to vocab\n",
    "for code in codes:\n",
    "    vocab_to_int[code] = len(vocab_to_int)\n",
    "\n",
    "# Dictionary to convert integers to words\n",
    "int_to_vocab = {}\n",
    "for word, value in vocab_to_int.items():\n",
    "    int_to_vocab[value] = word\n",
    "\n",
    "usage_ratio = round(len(vocab_to_int) / len(word_counts),4)*100\n",
    "\n",
    "print(\"Total number of unique words:\", len(word_counts))\n",
    "print(\"Number of words we will use:\", len(vocab_to_int))\n",
    "print(\"Percent of words we will use: {}%\".format(usage_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create word embedding matrix\n",
    "It has shape (nb_words, embedding_dim) i.e. (59072, 300) in this case. 1st dim is word index, 2nd dim is from CN or random generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63898\n"
     ]
    }
   ],
   "source": [
    "# Need to use 300 for embedding dimensions to match CN's vectors.\n",
    "embedding_dim =  50 # 50 for ./glove.6B.50d.txt\n",
    "nb_words = len(vocab_to_int)\n",
    "\n",
    "# Create matrix with default values of zero\n",
    "word_embedding_matrix = np.zeros((nb_words, embedding_dim), dtype=np.float32)\n",
    "for word, i in vocab_to_int.items():\n",
    "    if word in embeddings_index:\n",
    "        word_embedding_matrix[i] = embeddings_index[word]\n",
    "    else:\n",
    "        # If word not in CN, create a random embedding for it\n",
    "        new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
    "        embeddings_index[word] = new_embedding\n",
    "        word_embedding_matrix[i] = new_embedding\n",
    "\n",
    "# Check if value matches len(vocab_to_int)\n",
    "print(len(word_embedding_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to convert sentences to sequence of words indexes\n",
    "It also use `<UNK>` index to replace unknown words, append `<EOS>` (End of Sentence) to the sequences if eos is set True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ints(text, word_count, unk_count, eos=False):\n",
    "    '''Convert words in text to an integer.\n",
    "       If word is not in vocab_to_int, use UNK's integer.\n",
    "       Total the number of words and UNKs.\n",
    "       Add EOS token to the end of texts'''\n",
    "    ints = []\n",
    "    for sentence in text:\n",
    "        sentence_ints = []\n",
    "        for word in sentence.split():\n",
    "            word_count += 1\n",
    "            if word in vocab_to_int:\n",
    "                sentence_ints.append(vocab_to_int[word])\n",
    "            else:\n",
    "                sentence_ints.append(vocab_to_int[\"<UNK>\"])\n",
    "                unk_count += 1\n",
    "        if eos:\n",
    "            sentence_ints.append(vocab_to_int[\"<EOS>\"])\n",
    "        ints.append(sentence_ints)\n",
    "    return ints, word_count, unk_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply convert_to_ints to clean_summaries and clean_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total number of words in headlines:', 26232257)\n",
      "('Total number of UNKs in headlines:', 147342)\n",
      "Percent of words that are UNK: 0.0%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word_count = 0\n",
    "unk_count = 0\n",
    "\n",
    "int_summaries, word_count, unk_count = convert_to_ints(clean_summaries, word_count, unk_count)\n",
    "int_texts, word_count, unk_count = convert_to_ints(clean_texts, word_count, unk_count, eos=True)\n",
    "\n",
    "unk_percent = round(unk_count/word_count,4)*100\n",
    "\n",
    "print(\"Total number of words in headlines:\", word_count)\n",
    "print(\"Total number of UNKs in headlines:\", unk_count)\n",
    "print(\"Percent of words that are UNK: {}%\".format(unk_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at what the sequence looks like\n",
    "Each number here represents a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[60993, 59530, 52011, 2878],\n",
       " [34310, 8935, 35494],\n",
       " [52121, 54938, 12305, 22910]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_summaries[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get the length of each sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lengths(text):\n",
    "    '''Create a data frame of the sentence lengths from a text'''\n",
    "    lengths = []\n",
    "    for sentence in text:\n",
    "        lengths.append(len(sentence))\n",
    "    return pd.DataFrame(lengths, columns=['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   counts\n",
       "0       4\n",
       "1       3\n",
       "2       4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_lengths(int_summaries[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get statistic summary of the length of summaries and texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries:\n",
      "              counts\n",
      "count  568411.000000\n",
      "mean        4.181230\n",
      "std         2.657248\n",
      "min         0.000000\n",
      "25%         2.000000\n",
      "50%         4.000000\n",
      "75%         5.000000\n",
      "max        48.000000\n",
      "()\n",
      "Texts:\n",
      "              counts\n",
      "count  568411.000000\n",
      "mean       42.968927\n",
      "std        44.164343\n",
      "min         2.000000\n",
      "25%        18.000000\n",
      "50%        30.000000\n",
      "75%        51.000000\n",
      "max      2063.000000\n"
     ]
    }
   ],
   "source": [
    "lengths_summaries = create_lengths(int_summaries)\n",
    "lengths_texts = create_lengths(int_texts)\n",
    "\n",
    "print(\"Summaries:\")\n",
    "print(lengths_summaries.describe())\n",
    "print()\n",
    "print(\"Texts:\")\n",
    "print(lengths_texts.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See what's the max squence length we can cover by percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.0\n",
      "118.0\n",
      "216.0\n"
     ]
    }
   ],
   "source": [
    "# Inspect the length of texts\n",
    "print(np.percentile(lengths_texts.counts, 89.5))\n",
    "print(np.percentile(lengths_texts.counts, 95))\n",
    "print(np.percentile(lengths_texts.counts, 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n",
      "9.0\n",
      "13.0\n"
     ]
    }
   ],
   "source": [
    "# Inspect the length of summaries\n",
    "print(np.percentile(lengths_summaries.counts, 90))\n",
    "print(np.percentile(lengths_summaries.counts, 95))\n",
    "print(np.percentile(lengths_summaries.counts, 99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to counts the number of time `<UNK>` appears in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unk_counter(sentence):\n",
    "    '''Counts the number of time UNK appears in a sentence.'''\n",
    "    unk_count = 0\n",
    "    for word in sentence:\n",
    "        if word == vocab_to_int[\"<UNK>\"]:\n",
    "            unk_count += 1\n",
    "    return unk_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter** for length limit and number of `<UNK>`s\n",
    "\n",
    "**Sort** the summaries and texts by the length of the element in **texts** from shortest to longest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430497\n",
      "430497\n"
     ]
    }
   ],
   "source": [
    "max_text_length = 83 # This will cover up to 89.5% lengthes\n",
    "max_summary_length = 13 # This will cover up to 99% lengthes\n",
    "min_length = 2\n",
    "unk_text_limit = 1 # text can contain up to 1 UNK word\n",
    "unk_summary_limit = 0 # Summary should not contain any UNK word\n",
    "\n",
    "def filter_condition(item):\n",
    "    int_summary = item[0]\n",
    "    int_text = item[1]\n",
    "    if(len(int_summary) >= min_length and \n",
    "       len(int_summary) <= max_summary_length and \n",
    "       len(int_text) >= min_length and \n",
    "       len(int_text) <= max_text_length and \n",
    "       unk_counter(int_summary) <= unk_summary_limit and \n",
    "       unk_counter(int_text) <= unk_text_limit):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "int_text_summaries = list(zip(int_summaries , int_texts))\n",
    "int_text_summaries_filtered = list(filter(filter_condition, int_text_summaries))\n",
    "sorted_int_text_summaries = sorted(int_text_summaries_filtered, key=lambda item: len(item[1]))\n",
    "sorted_int_text_summaries = list(zip(*sorted_int_text_summaries))\n",
    "sorted_summaries = list(sorted_int_text_summaries[0])\n",
    "sorted_texts = list(sorted_int_text_summaries[1])\n",
    "# Delete those temporary varaibles\n",
    "del int_text_summaries, sorted_int_text_summaries, int_text_summaries_filtered\n",
    "# Compare lengths to ensure they match\n",
    "print(len(sorted_summaries))\n",
    "print(len(sorted_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the length of text in sorted_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths_texts = [len(text) for text in sorted_texts]\n",
    "lengths_texts[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "__pickleStuff(\"./data/clean_summaries.p\",clean_summaries)\n",
    "__pickleStuff(\"./data/clean_texts.p\",clean_texts)\n",
    "\n",
    "__pickleStuff(\"./data/sorted_summaries.p\",sorted_summaries)\n",
    "__pickleStuff(\"./data/sorted_texts.p\",sorted_texts)\n",
    "__pickleStuff(\"./data/word_embedding_matrix.p\",word_embedding_matrix)\n",
    "\n",
    "__pickleStuff(\"./data/vocab_to_int.p\",vocab_to_int)\n",
    "__pickleStuff(\"./data/int_to_vocab.p\",int_to_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create palceholders for inputs to the model\n",
    "\n",
    "**summary_length** and **text_length** are the sentence lengths in a batch, and **max_summary_length** is the maximum length of a summary in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inputs():\n",
    "    input_data = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    lr = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    summary_length = tf.placeholder(tf.int32, (None,), name='summary_length')\n",
    "    max_summary_length = tf.reduce_max(summary_length, name='max_dec_len')\n",
    "    text_length = tf.placeholder(tf.int32, (None,), name='text_length')\n",
    "\n",
    "    return input_data, targets, lr, keep_prob, summary_length, max_summary_length, text_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the last word id from each batch and concatenate the id of `<GO>` to the begining of each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_encoding_input(target_data, vocab_to_int, batch_size):  \n",
    "    ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1]) # slice it to target_data[0:batch_size, 0: -1]\n",
    "    dec_input = tf.concat([tf.fill([batch_size, 1], vocab_to_int['<GO>']), ending], 1)\n",
    "\n",
    "    return dec_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the encoding layers\n",
    "\n",
    "bidirectional_dynamic_rnn\n",
    "use **tf.variable_scope** so that variables are reused with each layer\n",
    "\n",
    "parameters\n",
    "- **rnn_size**: The number of units in the LSTM cell\n",
    "- **sequence_length**: size [batch_size], containing the actual lengths for each of the sequences in the batch\n",
    "- **num_layers**: number of bidirectional RNN layer\n",
    "- **rnn_inputs**: number of bidirectional RNN layer\n",
    "- **keep_prob**: RNN dropout input keep probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_layer(rnn_size, sequence_length, num_layers, rnn_inputs, keep_prob):\n",
    "    for layer in range(num_layers):\n",
    "        with tf.variable_scope('encoder_{}'.format(layer)):\n",
    "            cell_fw = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                              initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "            cell_fw = tf.contrib.rnn.DropoutWrapper(cell_fw, \n",
    "                                                    input_keep_prob = keep_prob)\n",
    "\n",
    "            cell_bw = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                              initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "            cell_bw = tf.contrib.rnn.DropoutWrapper(cell_bw, \n",
    "                                                    input_keep_prob = keep_prob)\n",
    "\n",
    "            enc_output, enc_state = tf.nn.bidirectional_dynamic_rnn(cell_fw, \n",
    "                                                                    cell_bw, \n",
    "                                                                    rnn_inputs,\n",
    "                                                                    sequence_length,\n",
    "                                                                    dtype=tf.float32)\n",
    "            enc_output = tf.concat(enc_output,2)\n",
    "            # original code is missing this line below, that is how we connect layers \n",
    "            # by feeding the current layer's output to next layer's input\n",
    "            rnn_inputs = enc_output\n",
    "    return enc_output, enc_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training decoding layer\n",
    "parameters\n",
    "- **dec_embed_input**: output of embedding_lookup for a batch of inputs\n",
    "- **summary_length**: length of each padded summary sequences in batch, since padded, all lengths should be same number \n",
    "- **dec_cell**: the decoder RNN cells' output with attention wapper\n",
    "- **output_layer**: fully connected layer to apply to the RNN output\n",
    "- **vocab_size**: vocabulary size i.e. len(vocab_to_int)+1\n",
    "- **max_summary_length**: the maximum length of a summary in a batch\n",
    "- **batch_size**: number of input sequences in a batch\n",
    "\n",
    "Three components\n",
    "\n",
    "- **TraingHelper** reads a sequence of integers from the encoding layer.\n",
    "- **BasicDecoder** processes the sequence with the decoding cell, and an output layer, which is a fully connected layer. **initial_state** set to zero state.\n",
    "- **dynamic_decode** creates our outputs that will be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_decoding_layer(dec_embed_input, summary_length, dec_cell, output_layer,\n",
    "                            vocab_size, max_summary_length,batch_size):\n",
    "    training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=dec_embed_input,\n",
    "                                                        sequence_length=summary_length,\n",
    "                                                        time_major=False)\n",
    "\n",
    "    training_decoder = tf.contrib.seq2seq.BasicDecoder(cell=dec_cell,\n",
    "                                                       helper=training_helper,\n",
    "                                                       initial_state=dec_cell.zero_state(dtype=tf.float32, batch_size=batch_size),\n",
    "                                                       output_layer = output_layer)\n",
    "\n",
    "    training_logits = tf.contrib.seq2seq.dynamic_decode(training_decoder,\n",
    "                                                           output_time_major=False,\n",
    "                                                           impute_finished=True,\n",
    "                                                           maximum_iterations=max_summary_length)\n",
    "    return training_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create infer decoding layer\n",
    "\n",
    "parameters\n",
    "- **embeddings**: the CN's word_embedding_matrix\n",
    "- **start_token**: the id of `<GO>`\n",
    "- **end_token**: the id of `<EOS>`\n",
    "- **dec_cell**: the decoder RNN cells' output with attention wapper\n",
    "- **output_layer**: fully connected layer to apply to the RNN output\n",
    "- **max_summary_length**: the maximum length of a summary in a batch\n",
    "- **batch_size**: number of input sequences in a batch\n",
    "\n",
    "**GreedyEmbeddingHelper** argument **start_tokens**: int32 vector shaped [batch_size], the start tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_decoding_layer(embeddings, start_token, end_token, dec_cell, output_layer,\n",
    "                             max_summary_length, batch_size):\n",
    "    '''Create the inference logits'''\n",
    "    \n",
    "    start_tokens = tf.tile(tf.constant([start_token], dtype=tf.int32), [batch_size], name='start_tokens')\n",
    "    \n",
    "    inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embeddings,\n",
    "                                                                start_tokens,\n",
    "                                                                end_token)\n",
    "                \n",
    "    inference_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                                        inference_helper,\n",
    "                                                        dec_cell.zero_state(dtype=tf.float32, batch_size=batch_size),\n",
    "                                                        output_layer)\n",
    "                \n",
    "    inference_logits = tf.contrib.seq2seq.dynamic_decode(inference_decoder,\n",
    "                                                            output_time_major=False,\n",
    "                                                            impute_finished=True,\n",
    "                                                            maximum_iterations=max_summary_length)\n",
    "    \n",
    "    return inference_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Decoding layer\n",
    "3 parts: decoding cell, attention, and getting our logits.\n",
    "#### Decoding Cell: \n",
    "Just a two layer LSTM with dropout.\n",
    "#### Attention: \n",
    "Using Bhadanau, since trains faster than Luong. \n",
    "\n",
    "**AttentionWrapper** applies the attention mechanism to our decoding cell.\n",
    "\n",
    "parameters\n",
    "- **dec_embed_input**: output of embedding_lookup for a batch of inputs\n",
    "- **embeddings**: the CN's word_embedding_matrix\n",
    "- **enc_output**: encoder layer output, containing the forward and the backward rnn output\n",
    "- **enc_state**: encoder layer state, a tuple containing the forward and the backward final states of bidirectional rnn.\n",
    "- **vocab_size**: vocabulary size i.e. len(vocab_to_int)+1\n",
    "- **text_length**: the actual lengths for each of the input text sequences in the batch\n",
    "- **summary_length**: the actual lengths for each of the input summary sequences in the batch\n",
    "- **max_summary_length**: the maximum length of a summary in a batch\n",
    "- **rnn_size**: The number of units in the LSTM cell\n",
    "- **vocab_to_int**: vocab_to_int the dictionary\n",
    "- **keep_prob**: RNN dropout input keep probability\n",
    "- **batch_size**: number of input sequences in a batch\n",
    "- **num_layers**: number of decoder RNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell(lstm_size, keep_prob):\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    return tf.contrib.rnn.DropoutWrapper(cell, input_keep_prob = keep_prob)\n",
    "\n",
    "def decoding_layer(dec_embed_input, embeddings, enc_output, enc_state, vocab_size, text_length, summary_length,\n",
    "                   max_summary_length, rnn_size, vocab_to_int, keep_prob, batch_size, num_layers):\n",
    "    '''Create the decoding cell and attention for the training and inference decoding layers'''\n",
    "    dec_cell = tf.contrib.rnn.MultiRNNCell([lstm_cell(rnn_size, keep_prob) for _ in range(num_layers)])\n",
    "    output_layer = Dense(vocab_size,kernel_initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1))\n",
    "    attn_mech = tf.contrib.seq2seq.BahdanauAttention(rnn_size,\n",
    "                                                     enc_output,\n",
    "                                                     text_length,\n",
    "                                                     normalize=False,\n",
    "                                                     name='BahdanauAttention')\n",
    "    dec_cell = tf.contrib.seq2seq.AttentionWrapper(dec_cell,attn_mech,rnn_size)\n",
    "    with tf.variable_scope(\"decode\"):\n",
    "        training_logits = training_decoding_layer(dec_embed_input,summary_length,dec_cell,\n",
    "                                                  output_layer,\n",
    "                                                  vocab_size,\n",
    "                                                  max_summary_length,\n",
    "                                                  batch_size)\n",
    "    with tf.variable_scope(\"decode\", reuse=True):\n",
    "        inference_logits = inference_decoding_layer(embeddings,\n",
    "                                                    vocab_to_int['<GO>'],\n",
    "                                                    vocab_to_int['<EOS>'],\n",
    "                                                    dec_cell,\n",
    "                                                    output_layer,\n",
    "                                                    max_summary_length,\n",
    "                                                    batch_size)\n",
    "    return training_logits, inference_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_model(input_data, target_data, keep_prob, text_length, summary_length, max_summary_length, \n",
    "                  vocab_size, rnn_size, num_layers, vocab_to_int, batch_size):\n",
    "    '''Use the previous functions to create the training and inference logits'''\n",
    "    \n",
    "    # Use Numberbatch's embeddings and the newly created ones as our embeddings\n",
    "    embeddings = word_embedding_matrix\n",
    "    enc_embed_input = tf.nn.embedding_lookup(embeddings, input_data)\n",
    "    enc_output, enc_state = encoding_layer(rnn_size, text_length, num_layers, enc_embed_input, keep_prob)\n",
    "    dec_input = process_encoding_input(target_data, vocab_to_int, batch_size) #shape=(batch_size, senquence length) each seq start with index of<GO>\n",
    "    dec_embed_input = tf.nn.embedding_lookup(embeddings, dec_input)\n",
    "    training_logits, inference_logits  = decoding_layer(dec_embed_input, \n",
    "                                                        embeddings,\n",
    "                                                        enc_output,\n",
    "                                                        enc_state, \n",
    "                                                        vocab_size, \n",
    "                                                        text_length, \n",
    "                                                        summary_length, \n",
    "                                                        max_summary_length,\n",
    "                                                        rnn_size, \n",
    "                                                        vocab_to_int, \n",
    "                                                        keep_prob, \n",
    "                                                        batch_size,\n",
    "                                                        num_layers)\n",
    "    return training_logits, inference_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad sentences for batch\n",
    "Pad so the actual lengths for each of the sequences in the batch have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch):\n",
    "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [vocab_to_int['<PAD>']] * (max_sentence - len(sentence)) for sentence in sentence_batch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to generate batch data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(summaries, texts, batch_size):\n",
    "    \"\"\"Batch summaries, texts, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(texts)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        summaries_batch = summaries[start_i:start_i + batch_size]\n",
    "        texts_batch = texts[start_i:start_i + batch_size]\n",
    "        pad_summaries_batch = np.array(pad_sentence_batch(summaries_batch))\n",
    "        pad_texts_batch = np.array(pad_sentence_batch(texts_batch))\n",
    "        \n",
    "        # Need the lengths for the _lengths parameters\n",
    "        pad_summaries_lengths = []\n",
    "        for summary in pad_summaries_batch:\n",
    "            pad_summaries_lengths.append(len(summary))\n",
    "        \n",
    "        pad_texts_lengths = []\n",
    "        for text in pad_texts_batch:\n",
    "            pad_texts_lengths.append(len(text))\n",
    "        \n",
    "        yield pad_summaries_batch, pad_texts_batch, pad_summaries_lengths, pad_texts_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just to test \"get_batches\" function\n",
    "Here we generate a batch with size of 5\n",
    "\n",
    "Checkout those \"59069\" they are `<PAD>`s, also all sequences' lengths are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<PAD>' has id: 63895\n",
      "pad summaries batch samples:\n",
      "\r",
      " [[52734 17911 10689 46839 46839 28625 21049 41655 19282 35002 14931 38129]\n",
      " [26884 60014 51125 12313  4864 63895 63895 63895 63895 63895 63895 63895]\n",
      " [34310  8935 38628  8935  7728 61835 24200 44506  1787 44342 14923 41818]\n",
      " [25421 12302 32350 14931 42071  8213 62980 39334 38602 63895 63895 63895]\n",
      " [43581 45712 38602 12253  1124 63895 63895 63895 63895 63895 63895 63895]]\n"
     ]
    }
   ],
   "source": [
    "print(\"'<PAD>' has id: {}\".format(vocab_to_int['<PAD>']))\n",
    "sorted_summaries_samples = sorted_summaries[7:50]\n",
    "sorted_texts_samples = sorted_texts[7:50]\n",
    "pad_summaries_batch_samples, pad_texts_batch_samples, pad_summaries_lengths_samples, pad_texts_lengths_samples = next(get_batches(\n",
    "    sorted_summaries_samples, sorted_texts_samples, 5))\n",
    "print(\"pad summaries batch samples:\\n\\r {}\".format(pad_summaries_batch_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "rnn_size = 256\n",
    "#rnn_size = 64\n",
    "num_layers = 2\n",
    "learning_rate = 0.005\n",
    "keep_probability = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-e5ed514e649b>:2: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "Graph is built.\n",
      "./graph\n"
     ]
    }
   ],
   "source": [
    "# Build the graph\n",
    "train_graph = tf.Graph()\n",
    "# Set the graph to default to ensure that it is ready for training\n",
    "with train_graph.as_default():\n",
    "    \n",
    "    # Load the model inputs    \n",
    "    input_data, targets, lr, keep_prob, summary_length, max_summary_length, text_length = model_inputs()\n",
    "\n",
    "    # Create the training and inference logits\n",
    "    training_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]),\n",
    "                                                      targets, \n",
    "                                                      keep_prob,   \n",
    "                                                      text_length,\n",
    "                                                      summary_length,\n",
    "                                                      max_summary_length,\n",
    "                                                      len(vocab_to_int)+1,\n",
    "                                                      rnn_size, \n",
    "                                                      num_layers, \n",
    "                                                      vocab_to_int,\n",
    "                                                      batch_size)\n",
    "    \n",
    "    # Create tensors for the training logits and inference logits\n",
    "    training_logits = tf.identity(training_logits[0].rnn_output, 'logits')\n",
    "    inference_logits = tf.identity(inference_logits[0].sample_id, name='predictions')\n",
    "    \n",
    "    # Create the weights for sequence_loss, the sould be all True across since each batch is padded\n",
    "    masks = tf.sequence_mask(summary_length, max_summary_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        # Loss function\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            training_logits,\n",
    "            targets,\n",
    "            masks)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)\n",
    "print(\"Graph is built.\")\n",
    "graph_location = \"./graph\"\n",
    "print(graph_location)\n",
    "train_writer = tf.summary.FileWriter(graph_location)\n",
    "train_writer.add_graph(train_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the Model\n",
    "\n",
    "Only going to use a subset of the data to reduce the traing time for this demo.\n",
    "\n",
    "We chose not use use the start of the subset because because those are shorter sequences and we don't want to make it too easy for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The shortest text length:', 25)\n",
      "('The longest text length:', 31)\n"
     ]
    }
   ],
   "source": [
    "# Subset the data for training\n",
    "start = 200000\n",
    "end = start + 50000\n",
    "sorted_summaries_short = sorted_summaries[start:end]\n",
    "sorted_texts_short = sorted_texts[start:end]\n",
    "print(\"The shortest text length:\", len(sorted_texts_short[0]))\n",
    "print(\"The longest text length:\",len(sorted_texts_short[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/100 Batch   20/1562 - Loss:  5.870, Seconds: 3.29\n",
      "Epoch   1/100 Batch   40/1562 - Loss:  3.138, Seconds: 3.76\n",
      "Epoch   1/100 Batch   60/1562 - Loss:  3.186, Seconds: 3.82\n",
      "Epoch   1/100 Batch   80/1562 - Loss:  3.174, Seconds: 3.25\n",
      "Epoch   1/100 Batch  100/1562 - Loss:  3.078, Seconds: 2.98\n",
      "Epoch   1/100 Batch  120/1562 - Loss:  3.189, Seconds: 3.29\n",
      "Epoch   1/100 Batch  140/1562 - Loss:  2.969, Seconds: 3.46\n",
      "Epoch   1/100 Batch  160/1562 - Loss:  2.966, Seconds: 3.35\n",
      "Epoch   1/100 Batch  180/1562 - Loss:  3.152, Seconds: 3.40\n",
      "Epoch   1/100 Batch  200/1562 - Loss:  2.914, Seconds: 3.61\n",
      "Epoch   1/100 Batch  220/1562 - Loss:  2.752, Seconds: 3.28\n",
      "Epoch   1/100 Batch  240/1562 - Loss:  3.052, Seconds: 3.13\n",
      "Epoch   1/100 Batch  260/1562 - Loss:  2.865, Seconds: 2.97\n",
      "Epoch   1/100 Batch  280/1562 - Loss:  2.811, Seconds: 3.36\n",
      "Epoch   1/100 Batch  300/1562 - Loss:  2.833, Seconds: 3.56\n",
      "Epoch   1/100 Batch  320/1562 - Loss:  2.891, Seconds: 3.36\n",
      "Epoch   1/100 Batch  340/1562 - Loss:  3.128, Seconds: 3.14\n",
      "Epoch   1/100 Batch  360/1562 - Loss:  2.979, Seconds: 3.29\n",
      "Epoch   1/100 Batch  380/1562 - Loss:  2.753, Seconds: 2.97\n",
      "Epoch   1/100 Batch  400/1562 - Loss:  2.900, Seconds: 3.53\n",
      "Epoch   1/100 Batch  420/1562 - Loss:  2.883, Seconds: 3.62\n",
      "Epoch   1/100 Batch  440/1562 - Loss:  2.664, Seconds: 3.60\n",
      "Epoch   1/100 Batch  460/1562 - Loss:  2.768, Seconds: 3.63\n",
      "Epoch   1/100 Batch  480/1562 - Loss:  2.569, Seconds: 3.60\n",
      "Epoch   1/100 Batch  500/1562 - Loss:  2.552, Seconds: 3.12\n",
      "('Average loss for this update:', 3.032)\n",
      "New Record!\n",
      "Epoch   1/100 Batch  520/1562 - Loss:  2.768, Seconds: 3.39\n",
      "Epoch   1/100 Batch  540/1562 - Loss:  2.465, Seconds: 3.71\n",
      "Epoch   1/100 Batch  560/1562 - Loss:  2.757, Seconds: 3.80\n",
      "Epoch   1/100 Batch  580/1562 - Loss:  2.552, Seconds: 3.54\n",
      "Epoch   1/100 Batch  600/1562 - Loss:  2.663, Seconds: 3.46\n",
      "Epoch   1/100 Batch  620/1562 - Loss:  2.886, Seconds: 2.85\n",
      "Epoch   1/100 Batch  640/1562 - Loss:  2.715, Seconds: 3.52\n",
      "Epoch   1/100 Batch  660/1562 - Loss:  2.670, Seconds: 3.77\n",
      "Epoch   1/100 Batch  680/1562 - Loss:  2.739, Seconds: 3.56\n",
      "Epoch   1/100 Batch  700/1562 - Loss:  2.436, Seconds: 3.67\n",
      "Epoch   1/100 Batch  720/1562 - Loss:  2.687, Seconds: 3.53\n",
      "Epoch   1/100 Batch  740/1562 - Loss:  2.500, Seconds: 3.62\n",
      "Epoch   1/100 Batch  760/1562 - Loss:  2.513, Seconds: 3.91\n",
      "Epoch   1/100 Batch  780/1562 - Loss:  2.329, Seconds: 3.52\n",
      "Epoch   1/100 Batch  800/1562 - Loss:  2.469, Seconds: 3.25\n",
      "Epoch   1/100 Batch  820/1562 - Loss:  2.553, Seconds: 3.59\n",
      "Epoch   1/100 Batch  840/1562 - Loss:  2.353, Seconds: 3.45\n",
      "Epoch   1/100 Batch  860/1562 - Loss:  2.571, Seconds: 3.43\n",
      "Epoch   1/100 Batch  880/1562 - Loss:  2.632, Seconds: 3.32\n",
      "Epoch   1/100 Batch  900/1562 - Loss:  2.771, Seconds: 3.79\n",
      "Epoch   1/100 Batch  920/1562 - Loss:  2.543, Seconds: 3.81\n",
      "Epoch   1/100 Batch  940/1562 - Loss:  2.711, Seconds: 3.73\n",
      "Epoch   1/100 Batch  960/1562 - Loss:  2.521, Seconds: 3.64\n",
      "Epoch   1/100 Batch  980/1562 - Loss:  2.542, Seconds: 3.72\n",
      "Epoch   1/100 Batch 1000/1562 - Loss:  2.567, Seconds: 3.82\n",
      "Epoch   1/100 Batch 1020/1562 - Loss:  2.499, Seconds: 3.96\n",
      "('Average loss for this update:', 2.576)\n",
      "New Record!\n",
      "Epoch   1/100 Batch 1040/1562 - Loss:  2.290, Seconds: 3.64\n",
      "Epoch   1/100 Batch 1060/1562 - Loss:  2.360, Seconds: 3.94\n",
      "Epoch   1/100 Batch 1080/1562 - Loss:  2.282, Seconds: 3.12\n",
      "Epoch   1/100 Batch 1100/1562 - Loss:  2.444, Seconds: 3.23\n",
      "Epoch   1/100 Batch 1120/1562 - Loss:  2.344, Seconds: 3.21\n",
      "Epoch   1/100 Batch 1140/1562 - Loss:  2.300, Seconds: 3.98\n",
      "Epoch   1/100 Batch 1160/1562 - Loss:  2.589, Seconds: 3.84\n",
      "Epoch   1/100 Batch 1180/1562 - Loss:  2.655, Seconds: 3.78\n",
      "Epoch   1/100 Batch 1200/1562 - Loss:  2.794, Seconds: 3.79\n",
      "Epoch   1/100 Batch 1220/1562 - Loss:  2.690, Seconds: 3.86\n",
      "Epoch   1/100 Batch 1240/1562 - Loss:  2.464, Seconds: 3.74\n",
      "Epoch   1/100 Batch 1260/1562 - Loss:  2.635, Seconds: 3.77\n",
      "Epoch   1/100 Batch 1280/1562 - Loss:  2.582, Seconds: 3.60\n",
      "Epoch   1/100 Batch 1300/1562 - Loss:  2.351, Seconds: 4.00\n",
      "Epoch   1/100 Batch 1320/1562 - Loss:  2.517, Seconds: 3.57\n",
      "Epoch   1/100 Batch 1340/1562 - Loss:  2.349, Seconds: 3.78\n",
      "Epoch   1/100 Batch 1360/1562 - Loss:  2.312, Seconds: 3.48\n",
      "Epoch   1/100 Batch 1380/1562 - Loss:  2.224, Seconds: 3.68\n",
      "Epoch   1/100 Batch 1400/1562 - Loss:  2.265, Seconds: 3.70\n",
      "Epoch   1/100 Batch 1420/1562 - Loss:  2.525, Seconds: 4.07\n",
      "Epoch   1/100 Batch 1440/1562 - Loss:  2.633, Seconds: 3.62\n",
      "Epoch   1/100 Batch 1460/1562 - Loss:  2.601, Seconds: 3.67\n",
      "Epoch   1/100 Batch 1480/1562 - Loss:  2.479, Seconds: 3.60\n",
      "Epoch   1/100 Batch 1500/1562 - Loss:  2.534, Seconds: 3.92\n",
      "Epoch   1/100 Batch 1520/1562 - Loss:  2.365, Seconds: 4.22\n",
      "Epoch   1/100 Batch 1540/1562 - Loss:  2.397, Seconds: 3.59\n",
      "('Average loss for this update:', 2.459)\n",
      "New Record!\n",
      "Epoch   1/100 Batch 1560/1562 - Loss:  2.268, Seconds: 4.01\n",
      "Epoch   2/100 Batch   20/1562 - Loss:  2.515, Seconds: 3.26\n",
      "Epoch   2/100 Batch   40/1562 - Loss:  2.202, Seconds: 3.38\n",
      "Epoch   2/100 Batch   60/1562 - Loss:  2.326, Seconds: 3.48\n",
      "Epoch   2/100 Batch   80/1562 - Loss:  2.383, Seconds: 3.19\n",
      "Epoch   2/100 Batch  100/1562 - Loss:  2.304, Seconds: 3.05\n",
      "Epoch   2/100 Batch  120/1562 - Loss:  2.412, Seconds: 3.33\n",
      "Epoch   2/100 Batch  140/1562 - Loss:  2.232, Seconds: 3.24\n",
      "Epoch   2/100 Batch  160/1562 - Loss:  2.258, Seconds: 3.17\n",
      "Epoch   2/100 Batch  180/1562 - Loss:  2.406, Seconds: 3.59\n",
      "Epoch   2/100 Batch  200/1562 - Loss:  2.226, Seconds: 3.59\n",
      "Epoch   2/100 Batch  220/1562 - Loss:  2.028, Seconds: 3.06\n",
      "Epoch   2/100 Batch  240/1562 - Loss:  2.329, Seconds: 3.19\n",
      "Epoch   2/100 Batch  260/1562 - Loss:  2.264, Seconds: 3.00\n",
      "Epoch   2/100 Batch  280/1562 - Loss:  2.106, Seconds: 3.40\n",
      "Epoch   2/100 Batch  300/1562 - Loss:  2.101, Seconds: 3.33\n",
      "Epoch   2/100 Batch  320/1562 - Loss:  2.288, Seconds: 3.27\n",
      "Epoch   2/100 Batch  340/1562 - Loss:  2.521, Seconds: 3.02\n",
      "Epoch   2/100 Batch  360/1562 - Loss:  2.377, Seconds: 3.71\n",
      "Epoch   2/100 Batch  380/1562 - Loss:  2.203, Seconds: 3.15\n",
      "Epoch   2/100 Batch  400/1562 - Loss:  2.368, Seconds: 3.80\n",
      "Epoch   2/100 Batch  420/1562 - Loss:  2.315, Seconds: 3.56\n",
      "Epoch   2/100 Batch  440/1562 - Loss:  2.147, Seconds: 3.64\n",
      "Epoch   2/100 Batch  460/1562 - Loss:  2.253, Seconds: 3.52\n",
      "Epoch   2/100 Batch  480/1562 - Loss:  2.041, Seconds: 3.44\n",
      "Epoch   2/100 Batch  500/1562 - Loss:  1.966, Seconds: 3.40\n",
      "('Average loss for this update:', 2.262)\n",
      "New Record!\n",
      "Epoch   2/100 Batch  520/1562 - Loss:  2.241, Seconds: 3.35\n",
      "Epoch   2/100 Batch  540/1562 - Loss:  1.987, Seconds: 3.89\n",
      "Epoch   2/100 Batch  560/1562 - Loss:  2.216, Seconds: 3.56\n",
      "Epoch   2/100 Batch  580/1562 - Loss:  2.028, Seconds: 3.57\n",
      "Epoch   2/100 Batch  600/1562 - Loss:  2.139, Seconds: 3.04\n",
      "Epoch   2/100 Batch  620/1562 - Loss:  2.429, Seconds: 3.01\n",
      "Epoch   2/100 Batch  640/1562 - Loss:  2.304, Seconds: 3.49\n",
      "Epoch   2/100 Batch  660/1562 - Loss:  2.240, Seconds: 3.22\n",
      "Epoch   2/100 Batch  680/1562 - Loss:  2.291, Seconds: 3.62\n",
      "Epoch   2/100 Batch  700/1562 - Loss:  2.029, Seconds: 3.53\n",
      "Epoch   2/100 Batch  720/1562 - Loss:  2.259, Seconds: 3.40\n",
      "Epoch   2/100 Batch  740/1562 - Loss:  2.114, Seconds: 4.01\n",
      "Epoch   2/100 Batch  760/1562 - Loss:  2.086, Seconds: 3.73\n",
      "Epoch   2/100 Batch  780/1562 - Loss:  1.872, Seconds: 3.40\n",
      "Epoch   2/100 Batch  800/1562 - Loss:  2.029, Seconds: 3.49\n",
      "Epoch   2/100 Batch  820/1562 - Loss:  2.119, Seconds: 3.66\n",
      "Epoch   2/100 Batch  840/1562 - Loss:  1.986, Seconds: 3.65\n",
      "Epoch   2/100 Batch  860/1562 - Loss:  2.125, Seconds: 3.44\n",
      "Epoch   2/100 Batch  880/1562 - Loss:  2.209, Seconds: 3.91\n",
      "Epoch   2/100 Batch  900/1562 - Loss:  2.366, Seconds: 3.62\n",
      "Epoch   2/100 Batch  920/1562 - Loss:  2.170, Seconds: 3.86\n",
      "Epoch   2/100 Batch  940/1562 - Loss:  2.303, Seconds: 3.39\n",
      "Epoch   2/100 Batch  960/1562 - Loss:  2.117, Seconds: 3.75\n",
      "Epoch   2/100 Batch  980/1562 - Loss:  2.132, Seconds: 3.74\n",
      "Epoch   2/100 Batch 1000/1562 - Loss:  2.165, Seconds: 3.59\n",
      "Epoch   2/100 Batch 1020/1562 - Loss:  2.113, Seconds: 3.61\n",
      "('Average loss for this update:', 2.144)\n",
      "New Record!\n",
      "Epoch   2/100 Batch 1040/1562 - Loss:  1.892, Seconds: 3.98\n",
      "Epoch   2/100 Batch 1060/1562 - Loss:  1.932, Seconds: 3.30\n",
      "Epoch   2/100 Batch 1080/1562 - Loss:  1.904, Seconds: 3.53\n",
      "Epoch   2/100 Batch 1100/1562 - Loss:  2.074, Seconds: 3.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2/100 Batch 1120/1562 - Loss:  2.011, Seconds: 3.26\n",
      "Epoch   2/100 Batch 1140/1562 - Loss:  1.906, Seconds: 3.62\n",
      "Epoch   2/100 Batch 1160/1562 - Loss:  2.209, Seconds: 3.92\n",
      "Epoch   2/100 Batch 1180/1562 - Loss:  2.289, Seconds: 4.36\n",
      "Epoch   2/100 Batch 1200/1562 - Loss:  2.407, Seconds: 3.67\n",
      "Epoch   2/100 Batch 1220/1562 - Loss:  2.325, Seconds: 3.54\n",
      "Epoch   2/100 Batch 1240/1562 - Loss:  2.097, Seconds: 3.71\n",
      "Epoch   2/100 Batch 1260/1562 - Loss:  2.230, Seconds: 3.47\n",
      "Epoch   2/100 Batch 1280/1562 - Loss:  2.239, Seconds: 3.46\n",
      "Epoch   2/100 Batch 1300/1562 - Loss:  1.986, Seconds: 3.94\n",
      "Epoch   2/100 Batch 1320/1562 - Loss:  2.101, Seconds: 3.52\n",
      "Epoch   2/100 Batch 1340/1562 - Loss:  1.989, Seconds: 3.37\n",
      "Epoch   2/100 Batch 1360/1562 - Loss:  1.981, Seconds: 3.88\n",
      "Epoch   2/100 Batch 1380/1562 - Loss:  1.907, Seconds: 3.62\n",
      "Epoch   2/100 Batch 1400/1562 - Loss:  1.926, Seconds: 3.83\n",
      "Epoch   2/100 Batch 1420/1562 - Loss:  2.215, Seconds: 4.04\n",
      "Epoch   2/100 Batch 1440/1562 - Loss:  2.315, Seconds: 3.87\n",
      "Epoch   2/100 Batch 1460/1562 - Loss:  2.272, Seconds: 3.91\n",
      "Epoch   2/100 Batch 1480/1562 - Loss:  2.182, Seconds: 3.87\n",
      "Epoch   2/100 Batch 1500/1562 - Loss:  2.203, Seconds: 3.87\n",
      "Epoch   2/100 Batch 1520/1562 - Loss:  2.077, Seconds: 3.62\n",
      "Epoch   2/100 Batch 1540/1562 - Loss:  2.101, Seconds: 3.55\n",
      "('Average loss for this update:', 2.108)\n",
      "New Record!\n",
      "Epoch   2/100 Batch 1560/1562 - Loss:  1.959, Seconds: 4.42\n",
      "Epoch   3/100 Batch   20/1562 - Loss:  2.322, Seconds: 3.23\n",
      "Epoch   3/100 Batch   40/1562 - Loss:  1.988, Seconds: 3.31\n",
      "Epoch   3/100 Batch   60/1562 - Loss:  2.075, Seconds: 3.35\n",
      "Epoch   3/100 Batch   80/1562 - Loss:  2.109, Seconds: 3.15\n",
      "Epoch   3/100 Batch  100/1562 - Loss:  2.059, Seconds: 2.95\n",
      "Epoch   3/100 Batch  120/1562 - Loss:  2.109, Seconds: 3.09\n",
      "Epoch   3/100 Batch  140/1562 - Loss:  1.987, Seconds: 3.09\n",
      "Epoch   3/100 Batch  160/1562 - Loss:  2.019, Seconds: 3.35\n",
      "Epoch   3/100 Batch  180/1562 - Loss:  2.145, Seconds: 3.44\n",
      "Epoch   3/100 Batch  200/1562 - Loss:  1.952, Seconds: 3.60\n",
      "Epoch   3/100 Batch  220/1562 - Loss:  1.769, Seconds: 3.48\n",
      "Epoch   3/100 Batch  240/1562 - Loss:  2.049, Seconds: 3.31\n",
      "Epoch   3/100 Batch  260/1562 - Loss:  2.011, Seconds: 3.19\n",
      "Epoch   3/100 Batch  280/1562 - Loss:  1.863, Seconds: 3.58\n",
      "Epoch   3/100 Batch  300/1562 - Loss:  1.849, Seconds: 3.23\n",
      "Epoch   3/100 Batch  320/1562 - Loss:  2.050, Seconds: 3.58\n",
      "Epoch   3/100 Batch  340/1562 - Loss:  2.283, Seconds: 2.91\n",
      "Epoch   3/100 Batch  360/1562 - Loss:  2.139, Seconds: 3.60\n",
      "Epoch   3/100 Batch  380/1562 - Loss:  1.981, Seconds: 3.33\n",
      "Epoch   3/100 Batch  400/1562 - Loss:  2.122, Seconds: 3.50\n",
      "Epoch   3/100 Batch  420/1562 - Loss:  2.075, Seconds: 3.44\n",
      "Epoch   3/100 Batch  440/1562 - Loss:  1.918, Seconds: 3.92\n",
      "Epoch   3/100 Batch  460/1562 - Loss:  2.025, Seconds: 3.66\n",
      "Epoch   3/100 Batch  480/1562 - Loss:  1.818, Seconds: 3.44\n",
      "Epoch   3/100 Batch  500/1562 - Loss:  1.706, Seconds: 3.45\n",
      "('Average loss for this update:', 2.016)\n",
      "New Record!\n",
      "Epoch   3/100 Batch  520/1562 - Loss:  2.001, Seconds: 3.87\n",
      "Epoch   3/100 Batch  540/1562 - Loss:  1.771, Seconds: 3.69\n",
      "Epoch   3/100 Batch  560/1562 - Loss:  1.970, Seconds: 4.01\n",
      "Epoch   3/100 Batch  580/1562 - Loss:  1.808, Seconds: 3.63\n",
      "Epoch   3/100 Batch  600/1562 - Loss:  1.912, Seconds: 3.33\n",
      "Epoch   3/100 Batch  620/1562 - Loss:  2.210, Seconds: 3.36\n",
      "Epoch   3/100 Batch  640/1562 - Loss:  2.075, Seconds: 3.52\n",
      "Epoch   3/100 Batch  660/1562 - Loss:  2.035, Seconds: 3.28\n",
      "Epoch   3/100 Batch  680/1562 - Loss:  2.059, Seconds: 3.78\n",
      "Epoch   3/100 Batch  700/1562 - Loss:  1.804, Seconds: 3.67\n",
      "Epoch   3/100 Batch  720/1562 - Loss:  2.038, Seconds: 3.50\n",
      "Epoch   3/100 Batch  740/1562 - Loss:  1.901, Seconds: 3.71\n",
      "Epoch   3/100 Batch  760/1562 - Loss:  1.890, Seconds: 3.89\n",
      "Epoch   3/100 Batch  780/1562 - Loss:  1.659, Seconds: 3.45\n",
      "Epoch   3/100 Batch  800/1562 - Loss:  1.832, Seconds: 3.36\n",
      "Epoch   3/100 Batch  820/1562 - Loss:  1.922, Seconds: 3.71\n",
      "Epoch   3/100 Batch  840/1562 - Loss:  1.781, Seconds: 3.61\n",
      "Epoch   3/100 Batch  860/1562 - Loss:  1.903, Seconds: 3.42\n",
      "Epoch   3/100 Batch  880/1562 - Loss:  1.997, Seconds: 3.80\n",
      "Epoch   3/100 Batch  900/1562 - Loss:  2.155, Seconds: 3.92\n",
      "Epoch   3/100 Batch  920/1562 - Loss:  1.966, Seconds: 3.61\n",
      "Epoch   3/100 Batch  940/1562 - Loss:  2.100, Seconds: 3.32\n",
      "Epoch   3/100 Batch  960/1562 - Loss:  1.900, Seconds: 3.19\n",
      "Epoch   3/100 Batch  980/1562 - Loss:  1.912, Seconds: 3.64\n",
      "Epoch   3/100 Batch 1000/1562 - Loss:  1.946, Seconds: 3.87\n",
      "Epoch   3/100 Batch 1020/1562 - Loss:  1.910, Seconds: 3.55\n",
      "('Average loss for this update:', 1.93)\n",
      "New Record!\n",
      "Epoch   3/100 Batch 1040/1562 - Loss:  1.704, Seconds: 3.24\n",
      "Epoch   3/100 Batch 1060/1562 - Loss:  1.728, Seconds: 3.46\n",
      "Epoch   3/100 Batch 1080/1562 - Loss:  1.718, Seconds: 3.33\n",
      "Epoch   3/100 Batch 1100/1562 - Loss:  1.889, Seconds: 3.48\n",
      "Epoch   3/100 Batch 1120/1562 - Loss:  1.834, Seconds: 3.60\n",
      "Epoch   3/100 Batch 1140/1562 - Loss:  1.753, Seconds: 3.79\n",
      "Epoch   3/100 Batch 1160/1562 - Loss:  2.040, Seconds: 3.87\n",
      "Epoch   3/100 Batch 1180/1562 - Loss:  2.090, Seconds: 3.97\n",
      "Epoch   3/100 Batch 1200/1562 - Loss:  2.199, Seconds: 3.27\n",
      "Epoch   3/100 Batch 1220/1562 - Loss:  2.112, Seconds: 3.37\n",
      "Epoch   3/100 Batch 1240/1562 - Loss:  1.911, Seconds: 3.67\n",
      "Epoch   3/100 Batch 1260/1562 - Loss:  2.015, Seconds: 3.68\n",
      "Epoch   3/100 Batch 1280/1562 - Loss:  2.038, Seconds: 3.77\n",
      "Epoch   3/100 Batch 1300/1562 - Loss:  1.785, Seconds: 3.88\n",
      "Epoch   3/100 Batch 1320/1562 - Loss:  1.862, Seconds: 3.44\n",
      "Epoch   3/100 Batch 1340/1562 - Loss:  1.795, Seconds: 3.47\n",
      "Epoch   3/100 Batch 1360/1562 - Loss:  1.795, Seconds: 3.62\n",
      "Epoch   3/100 Batch 1380/1562 - Loss:  1.716, Seconds: 3.85\n",
      "Epoch   3/100 Batch 1400/1562 - Loss:  1.771, Seconds: 3.89\n",
      "Epoch   3/100 Batch 1420/1562 - Loss:  2.035, Seconds: 3.82\n",
      "Epoch   3/100 Batch 1440/1562 - Loss:  2.146, Seconds: 3.98\n",
      "Epoch   3/100 Batch 1460/1562 - Loss:  2.098, Seconds: 3.71\n",
      "Epoch   3/100 Batch 1480/1562 - Loss:  2.019, Seconds: 3.12\n",
      "Epoch   3/100 Batch 1500/1562 - Loss:  2.016, Seconds: 3.68\n",
      "Epoch   3/100 Batch 1520/1562 - Loss:  1.873, Seconds: 4.26\n",
      "Epoch   3/100 Batch 1540/1562 - Loss:  1.933, Seconds: 3.67\n",
      "('Average loss for this update:', 1.921)\n",
      "New Record!\n",
      "Epoch   3/100 Batch 1560/1562 - Loss:  1.782, Seconds: 3.76\n",
      "Epoch   4/100 Batch   20/1562 - Loss:  2.184, Seconds: 3.11\n",
      "Epoch   4/100 Batch   40/1562 - Loss:  1.847, Seconds: 3.42\n",
      "Epoch   4/100 Batch   60/1562 - Loss:  1.903, Seconds: 3.62\n",
      "Epoch   4/100 Batch   80/1562 - Loss:  1.970, Seconds: 3.14\n",
      "Epoch   4/100 Batch  100/1562 - Loss:  1.899, Seconds: 3.08\n",
      "Epoch   4/100 Batch  120/1562 - Loss:  1.957, Seconds: 3.33\n",
      "Epoch   4/100 Batch  140/1562 - Loss:  1.825, Seconds: 3.21\n",
      "Epoch   4/100 Batch  160/1562 - Loss:  1.888, Seconds: 3.39\n",
      "Epoch   4/100 Batch  180/1562 - Loss:  1.962, Seconds: 3.47\n",
      "Epoch   4/100 Batch  200/1562 - Loss:  1.766, Seconds: 3.34\n",
      "Epoch   4/100 Batch  220/1562 - Loss:  1.601, Seconds: 3.38\n",
      "Epoch   4/100 Batch  240/1562 - Loss:  1.891, Seconds: 3.20\n",
      "Epoch   4/100 Batch  260/1562 - Loss:  1.852, Seconds: 3.01\n",
      "Epoch   4/100 Batch  280/1562 - Loss:  1.717, Seconds: 3.24\n",
      "Epoch   4/100 Batch  300/1562 - Loss:  1.722, Seconds: 3.44\n",
      "Epoch   4/100 Batch  320/1562 - Loss:  1.882, Seconds: 3.42\n",
      "Epoch   4/100 Batch  340/1562 - Loss:  2.114, Seconds: 3.03\n",
      "Epoch   4/100 Batch  360/1562 - Loss:  1.981, Seconds: 3.73\n",
      "Epoch   4/100 Batch  380/1562 - Loss:  1.828, Seconds: 3.15\n",
      "Epoch   4/100 Batch  400/1562 - Loss:  1.943, Seconds: 3.26\n",
      "Epoch   4/100 Batch  420/1562 - Loss:  1.890, Seconds: 3.42\n",
      "Epoch   4/100 Batch  440/1562 - Loss:  1.748, Seconds: 3.74\n",
      "Epoch   4/100 Batch  460/1562 - Loss:  1.869, Seconds: 3.41\n",
      "Epoch   4/100 Batch  480/1562 - Loss:  1.665, Seconds: 3.42\n",
      "Epoch   4/100 Batch  500/1562 - Loss:  1.539, Seconds: 3.32\n",
      "('Average loss for this update:', 1.857)\n",
      "New Record!\n",
      "Epoch   4/100 Batch  520/1562 - Loss:  1.850, Seconds: 3.31\n",
      "Epoch   4/100 Batch  540/1562 - Loss:  1.646, Seconds: 3.63\n",
      "Epoch   4/100 Batch  560/1562 - Loss:  1.809, Seconds: 3.66\n",
      "Epoch   4/100 Batch  580/1562 - Loss:  1.693, Seconds: 3.52\n",
      "Epoch   4/100 Batch  600/1562 - Loss:  1.788, Seconds: 3.43\n",
      "Epoch   4/100 Batch  620/1562 - Loss:  2.042, Seconds: 3.21\n",
      "Epoch   4/100 Batch  640/1562 - Loss:  1.918, Seconds: 3.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   4/100 Batch  660/1562 - Loss:  1.901, Seconds: 3.46\n",
      "Epoch   4/100 Batch  680/1562 - Loss:  1.913, Seconds: 4.05\n",
      "Epoch   4/100 Batch  700/1562 - Loss:  1.645, Seconds: 3.96\n",
      "Epoch   4/100 Batch  720/1562 - Loss:  1.874, Seconds: 3.05\n",
      "Epoch   4/100 Batch  740/1562 - Loss:  1.763, Seconds: 3.58\n",
      "Epoch   4/100 Batch  760/1562 - Loss:  1.731, Seconds: 3.75\n",
      "Epoch   4/100 Batch  780/1562 - Loss:  1.518, Seconds: 3.61\n",
      "Epoch   4/100 Batch  800/1562 - Loss:  1.708, Seconds: 3.62\n",
      "Epoch   4/100 Batch  820/1562 - Loss:  1.772, Seconds: 3.80\n",
      "Epoch   4/100 Batch  840/1562 - Loss:  1.635, Seconds: 3.66\n",
      "Epoch   4/100 Batch  860/1562 - Loss:  1.732, Seconds: 3.77\n",
      "Epoch   4/100 Batch  880/1562 - Loss:  1.832, Seconds: 3.38\n",
      "Epoch   4/100 Batch  900/1562 - Loss:  1.960, Seconds: 3.66\n",
      "Epoch   4/100 Batch  920/1562 - Loss:  1.821, Seconds: 3.76\n",
      "Epoch   4/100 Batch  940/1562 - Loss:  1.966, Seconds: 3.37\n",
      "Epoch   4/100 Batch  960/1562 - Loss:  1.725, Seconds: 3.33\n",
      "Epoch   4/100 Batch  980/1562 - Loss:  1.747, Seconds: 3.65\n",
      "Epoch   4/100 Batch 1000/1562 - Loss:  1.808, Seconds: 3.93\n",
      "Epoch   4/100 Batch 1020/1562 - Loss:  1.760, Seconds: 3.57\n",
      "('Average loss for this update:', 1.781)\n",
      "New Record!\n",
      "Epoch   4/100 Batch 1040/1562 - Loss:  1.561, Seconds: 3.39\n",
      "Epoch   4/100 Batch 1060/1562 - Loss:  1.575, Seconds: 3.91\n",
      "Epoch   4/100 Batch 1080/1562 - Loss:  1.574, Seconds: 3.46\n",
      "Epoch   4/100 Batch 1100/1562 - Loss:  1.737, Seconds: 3.52\n",
      "Epoch   4/100 Batch 1120/1562 - Loss:  1.691, Seconds: 3.36\n",
      "Epoch   4/100 Batch 1140/1562 - Loss:  1.569, Seconds: 3.33\n",
      "Epoch   4/100 Batch 1160/1562 - Loss:  1.869, Seconds: 3.79\n",
      "Epoch   4/100 Batch 1180/1562 - Loss:  1.946, Seconds: 3.69\n",
      "Epoch   4/100 Batch 1200/1562 - Loss:  2.034, Seconds: 3.57\n",
      "Epoch   4/100 Batch 1220/1562 - Loss:  1.943, Seconds: 3.54\n",
      "Epoch   4/100 Batch 1240/1562 - Loss:  1.757, Seconds: 3.72\n",
      "Epoch   4/100 Batch 1260/1562 - Loss:  1.845, Seconds: 3.97\n",
      "Epoch   4/100 Batch 1280/1562 - Loss:  1.876, Seconds: 3.76\n",
      "Epoch   4/100 Batch 1300/1562 - Loss:  1.643, Seconds: 3.95\n",
      "Epoch   4/100 Batch 1320/1562 - Loss:  1.699, Seconds: 3.49\n",
      "Epoch   4/100 Batch 1340/1562 - Loss:  1.618, Seconds: 3.78\n",
      "Epoch   4/100 Batch 1360/1562 - Loss:  1.663, Seconds: 3.56\n",
      "Epoch   4/100 Batch 1380/1562 - Loss:  1.583, Seconds: 3.66\n",
      "Epoch   4/100 Batch 1400/1562 - Loss:  1.624, Seconds: 3.93\n",
      "Epoch   4/100 Batch 1420/1562 - Loss:  1.874, Seconds: 4.21\n",
      "Epoch   4/100 Batch 1440/1562 - Loss:  2.005, Seconds: 3.92\n",
      "Epoch   4/100 Batch 1460/1562 - Loss:  1.960, Seconds: 3.86\n",
      "Epoch   4/100 Batch 1480/1562 - Loss:  1.877, Seconds: 3.65\n",
      "Epoch   4/100 Batch 1500/1562 - Loss:  1.872, Seconds: 3.81\n",
      "Epoch   4/100 Batch 1520/1562 - Loss:  1.742, Seconds: 3.79\n",
      "Epoch   4/100 Batch 1540/1562 - Loss:  1.804, Seconds: 4.03\n",
      "('Average loss for this update:', 1.77)\n",
      "New Record!\n",
      "Epoch   4/100 Batch 1560/1562 - Loss:  1.650, Seconds: 3.60\n",
      "Epoch   5/100 Batch   20/1562 - Loss:  2.080, Seconds: 3.24\n",
      "Epoch   5/100 Batch   40/1562 - Loss:  1.721, Seconds: 3.18\n",
      "Epoch   5/100 Batch   60/1562 - Loss:  1.795, Seconds: 3.44\n",
      "Epoch   5/100 Batch   80/1562 - Loss:  1.836, Seconds: 3.13\n",
      "Epoch   5/100 Batch  100/1562 - Loss:  1.755, Seconds: 3.14\n",
      "Epoch   5/100 Batch  120/1562 - Loss:  1.805, Seconds: 3.24\n",
      "Epoch   5/100 Batch  140/1562 - Loss:  1.674, Seconds: 3.31\n",
      "Epoch   5/100 Batch  160/1562 - Loss:  1.736, Seconds: 3.73\n",
      "Epoch   5/100 Batch  180/1562 - Loss:  1.811, Seconds: 3.63\n",
      "Epoch   5/100 Batch  200/1562 - Loss:  1.630, Seconds: 3.61\n",
      "Epoch   5/100 Batch  220/1562 - Loss:  1.471, Seconds: 3.06\n",
      "Epoch   5/100 Batch  240/1562 - Loss:  1.745, Seconds: 3.35\n",
      "Epoch   5/100 Batch  260/1562 - Loss:  1.701, Seconds: 2.94\n",
      "Epoch   5/100 Batch  280/1562 - Loss:  1.588, Seconds: 3.60\n",
      "Epoch   5/100 Batch  300/1562 - Loss:  1.602, Seconds: 3.47\n",
      "Epoch   5/100 Batch  320/1562 - Loss:  1.767, Seconds: 3.14\n",
      "Epoch   5/100 Batch  340/1562 - Loss:  1.951, Seconds: 3.27\n",
      "Epoch   5/100 Batch  360/1562 - Loss:  1.858, Seconds: 3.66\n",
      "Epoch   5/100 Batch  380/1562 - Loss:  1.692, Seconds: 3.27\n",
      "Epoch   5/100 Batch  400/1562 - Loss:  1.792, Seconds: 3.56\n",
      "Epoch   5/100 Batch  420/1562 - Loss:  1.764, Seconds: 3.83\n",
      "Epoch   5/100 Batch  440/1562 - Loss:  1.626, Seconds: 3.42\n",
      "Epoch   5/100 Batch  460/1562 - Loss:  1.752, Seconds: 3.89\n",
      "Epoch   5/100 Batch  480/1562 - Loss:  1.558, Seconds: 3.22\n",
      "Epoch   5/100 Batch  500/1562 - Loss:  1.406, Seconds: 3.70\n",
      "('Average loss for this update:', 1.724)\n",
      "New Record!\n",
      "Epoch   5/100 Batch  520/1562 - Loss:  1.712, Seconds: 3.13\n",
      "Epoch   5/100 Batch  540/1562 - Loss:  1.523, Seconds: 3.31\n",
      "Epoch   5/100 Batch  560/1562 - Loss:  1.673, Seconds: 3.49\n",
      "Epoch   5/100 Batch  580/1562 - Loss:  1.557, Seconds: 3.77\n",
      "Epoch   5/100 Batch  600/1562 - Loss:  1.646, Seconds: 3.28\n",
      "Epoch   5/100 Batch  620/1562 - Loss:  1.910, Seconds: 3.29\n",
      "Epoch   5/100 Batch  640/1562 - Loss:  1.790, Seconds: 3.47\n",
      "Epoch   5/100 Batch  660/1562 - Loss:  1.766, Seconds: 3.51\n",
      "Epoch   5/100 Batch  680/1562 - Loss:  1.783, Seconds: 3.55\n",
      "Epoch   5/100 Batch  700/1562 - Loss:  1.549, Seconds: 3.75\n",
      "Epoch   5/100 Batch  720/1562 - Loss:  1.725, Seconds: 3.83\n",
      "Epoch   5/100 Batch  740/1562 - Loss:  1.642, Seconds: 3.49\n",
      "Epoch   5/100 Batch  760/1562 - Loss:  1.616, Seconds: 3.90\n",
      "Epoch   5/100 Batch  780/1562 - Loss:  1.390, Seconds: 3.34\n",
      "Epoch   5/100 Batch  800/1562 - Loss:  1.580, Seconds: 3.75\n",
      "Epoch   5/100 Batch  820/1562 - Loss:  1.658, Seconds: 3.59\n",
      "Epoch   5/100 Batch  840/1562 - Loss:  1.522, Seconds: 3.58\n",
      "Epoch   5/100 Batch  860/1562 - Loss:  1.600, Seconds: 3.56\n",
      "Epoch   5/100 Batch  880/1562 - Loss:  1.698, Seconds: 4.26\n",
      "Epoch   5/100 Batch  900/1562 - Loss:  1.809, Seconds: 3.54\n",
      "Epoch   5/100 Batch  920/1562 - Loss:  1.677, Seconds: 3.43\n",
      "Epoch   5/100 Batch  940/1562 - Loss:  1.834, Seconds: 3.48\n",
      "Epoch   5/100 Batch  960/1562 - Loss:  1.585, Seconds: 3.60\n",
      "Epoch   5/100 Batch  980/1562 - Loss:  1.607, Seconds: 3.36\n",
      "Epoch   5/100 Batch 1000/1562 - Loss:  1.690, Seconds: 3.53\n",
      "Epoch   5/100 Batch 1020/1562 - Loss:  1.661, Seconds: 3.86\n",
      "('Average loss for this update:', 1.653)\n",
      "New Record!\n",
      "Epoch   5/100 Batch 1040/1562 - Loss:  1.464, Seconds: 3.63\n",
      "Epoch   5/100 Batch 1060/1562 - Loss:  1.458, Seconds: 3.46\n",
      "Epoch   5/100 Batch 1080/1562 - Loss:  1.467, Seconds: 3.25\n",
      "Epoch   5/100 Batch 1100/1562 - Loss:  1.608, Seconds: 3.61\n",
      "Epoch   5/100 Batch 1120/1562 - Loss:  1.569, Seconds: 3.68\n",
      "Epoch   5/100 Batch 1140/1562 - Loss:  1.431, Seconds: 3.44\n",
      "Epoch   5/100 Batch 1160/1562 - Loss:  1.735, Seconds: 3.81\n",
      "Epoch   5/100 Batch 1180/1562 - Loss:  1.793, Seconds: 3.82\n",
      "Epoch   5/100 Batch 1200/1562 - Loss:  1.901, Seconds: 3.75\n",
      "Epoch   5/100 Batch 1220/1562 - Loss:  1.826, Seconds: 3.80\n",
      "Epoch   5/100 Batch 1240/1562 - Loss:  1.659, Seconds: 3.85\n",
      "Epoch   5/100 Batch 1260/1562 - Loss:  1.710, Seconds: 3.95\n",
      "Epoch   5/100 Batch 1280/1562 - Loss:  1.744, Seconds: 3.40\n",
      "Epoch   5/100 Batch 1300/1562 - Loss:  1.534, Seconds: 3.75\n",
      "Epoch   5/100 Batch 1320/1562 - Loss:  1.570, Seconds: 3.68\n",
      "Epoch   5/100 Batch 1340/1562 - Loss:  1.499, Seconds: 3.80\n",
      "Epoch   5/100 Batch 1360/1562 - Loss:  1.562, Seconds: 3.82\n",
      "Epoch   5/100 Batch 1380/1562 - Loss:  1.491, Seconds: 4.11\n",
      "Epoch   5/100 Batch 1400/1562 - Loss:  1.518, Seconds: 4.01\n",
      "Epoch   5/100 Batch 1420/1562 - Loss:  1.770, Seconds: 4.02\n",
      "Epoch   5/100 Batch 1440/1562 - Loss:  1.879, Seconds: 3.59\n",
      "Epoch   5/100 Batch 1460/1562 - Loss:  1.868, Seconds: 3.95\n",
      "Epoch   5/100 Batch 1480/1562 - Loss:  1.764, Seconds: 3.70\n",
      "Epoch   5/100 Batch 1500/1562 - Loss:  1.759, Seconds: 4.12\n",
      "Epoch   5/100 Batch 1520/1562 - Loss:  1.644, Seconds: 4.05\n",
      "Epoch   5/100 Batch 1540/1562 - Loss:  1.689, Seconds: 3.69\n",
      "('Average loss for this update:', 1.653)\n",
      "New Record!\n",
      "Epoch   5/100 Batch 1560/1562 - Loss:  1.532, Seconds: 3.77\n",
      "Epoch   6/100 Batch   20/1562 - Loss:  1.988, Seconds: 3.41\n",
      "Epoch   6/100 Batch   40/1562 - Loss:  1.668, Seconds: 3.74\n",
      "Epoch   6/100 Batch   60/1562 - Loss:  1.699, Seconds: 3.37\n",
      "Epoch   6/100 Batch   80/1562 - Loss:  1.732, Seconds: 3.15\n",
      "Epoch   6/100 Batch  100/1562 - Loss:  1.661, Seconds: 2.86\n",
      "Epoch   6/100 Batch  120/1562 - Loss:  1.692, Seconds: 3.04\n",
      "Epoch   6/100 Batch  140/1562 - Loss:  1.569, Seconds: 3.38\n",
      "Epoch   6/100 Batch  160/1562 - Loss:  1.633, Seconds: 3.28\n",
      "Epoch   6/100 Batch  180/1562 - Loss:  1.693, Seconds: 3.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   6/100 Batch  200/1562 - Loss:  1.530, Seconds: 3.51\n",
      "Epoch   6/100 Batch  220/1562 - Loss:  1.345, Seconds: 3.32\n",
      "Epoch   6/100 Batch  240/1562 - Loss:  1.627, Seconds: 3.12\n",
      "Epoch   6/100 Batch  260/1562 - Loss:  1.591, Seconds: 3.40\n",
      "Epoch   6/100 Batch  280/1562 - Loss:  1.482, Seconds: 3.53\n",
      "Epoch   6/100 Batch  300/1562 - Loss:  1.488, Seconds: 3.36\n",
      "Epoch   6/100 Batch  320/1562 - Loss:  1.667, Seconds: 3.45\n",
      "Epoch   6/100 Batch  340/1562 - Loss:  1.824, Seconds: 3.03\n",
      "Epoch   6/100 Batch  360/1562 - Loss:  1.732, Seconds: 3.89\n",
      "Epoch   6/100 Batch  380/1562 - Loss:  1.612, Seconds: 3.11\n",
      "Epoch   6/100 Batch  400/1562 - Loss:  1.675, Seconds: 3.34\n",
      "Epoch   6/100 Batch  420/1562 - Loss:  1.675, Seconds: 3.38\n",
      "Epoch   6/100 Batch  440/1562 - Loss:  1.515, Seconds: 3.54\n",
      "Epoch   6/100 Batch  460/1562 - Loss:  1.636, Seconds: 3.67\n",
      "Epoch   6/100 Batch  480/1562 - Loss:  1.501, Seconds: 3.40\n",
      "Epoch   6/100 Batch  500/1562 - Loss:  1.335, Seconds: 3.58\n",
      "('Average loss for this update:', 1.622)\n",
      "New Record!\n",
      "Epoch   6/100 Batch  520/1562 - Loss:  1.605, Seconds: 3.41\n",
      "Epoch   6/100 Batch  540/1562 - Loss:  1.442, Seconds: 3.50\n",
      "Epoch   6/100 Batch  560/1562 - Loss:  1.560, Seconds: 3.48\n",
      "Epoch   6/100 Batch  580/1562 - Loss:  1.451, Seconds: 3.72\n",
      "Epoch   6/100 Batch  600/1562 - Loss:  1.540, Seconds: 3.24\n",
      "Epoch   6/100 Batch  620/1562 - Loss:  1.804, Seconds: 3.41\n",
      "Epoch   6/100 Batch  640/1562 - Loss:  1.691, Seconds: 3.52\n",
      "Epoch   6/100 Batch  660/1562 - Loss:  1.663, Seconds: 3.17\n",
      "Epoch   6/100 Batch  680/1562 - Loss:  1.679, Seconds: 3.93\n",
      "Epoch   6/100 Batch  700/1562 - Loss:  1.445, Seconds: 3.91\n",
      "Epoch   6/100 Batch  720/1562 - Loss:  1.628, Seconds: 3.31\n",
      "Epoch   6/100 Batch  740/1562 - Loss:  1.558, Seconds: 3.58\n",
      "Epoch   6/100 Batch  760/1562 - Loss:  1.501, Seconds: 3.22\n",
      "Epoch   6/100 Batch  780/1562 - Loss:  1.304, Seconds: 3.50\n",
      "Epoch   6/100 Batch  800/1562 - Loss:  1.498, Seconds: 3.46\n",
      "Epoch   6/100 Batch  820/1562 - Loss:  1.564, Seconds: 3.73\n",
      "Epoch   6/100 Batch  840/1562 - Loss:  1.454, Seconds: 3.13\n",
      "Epoch   6/100 Batch  860/1562 - Loss:  1.491, Seconds: 3.32\n",
      "Epoch   6/100 Batch  880/1562 - Loss:  1.595, Seconds: 3.81\n",
      "Epoch   6/100 Batch  900/1562 - Loss:  1.697, Seconds: 3.89\n",
      "Epoch   6/100 Batch  920/1562 - Loss:  1.595, Seconds: 3.79\n",
      "Epoch   6/100 Batch  940/1562 - Loss:  1.735, Seconds: 3.76\n",
      "Epoch   6/100 Batch  960/1562 - Loss:  1.499, Seconds: 3.76\n",
      "Epoch   6/100 Batch  980/1562 - Loss:  1.527, Seconds: 3.84\n",
      "Epoch   6/100 Batch 1000/1562 - Loss:  1.590, Seconds: 3.79\n",
      "Epoch   6/100 Batch 1020/1562 - Loss:  1.574, Seconds: 4.02\n",
      "('Average loss for this update:', 1.558)\n",
      "New Record!\n",
      "Epoch   6/100 Batch 1040/1562 - Loss:  1.386, Seconds: 3.81\n",
      "Epoch   6/100 Batch 1060/1562 - Loss:  1.375, Seconds: 3.79\n",
      "Epoch   6/100 Batch 1080/1562 - Loss:  1.402, Seconds: 3.38\n",
      "Epoch   6/100 Batch 1100/1562 - Loss:  1.532, Seconds: 3.44\n",
      "Epoch   6/100 Batch 1120/1562 - Loss:  1.488, Seconds: 3.82\n",
      "Epoch   6/100 Batch 1140/1562 - Loss:  1.354, Seconds: 3.67\n",
      "Epoch   6/100 Batch 1160/1562 - Loss:  1.646, Seconds: 3.76\n",
      "Epoch   6/100 Batch 1180/1562 - Loss:  1.682, Seconds: 3.92\n",
      "Epoch   6/100 Batch 1200/1562 - Loss:  1.783, Seconds: 3.46\n",
      "Epoch   6/100 Batch 1220/1562 - Loss:  1.705, Seconds: 3.58\n",
      "Epoch   6/100 Batch 1240/1562 - Loss:  1.534, Seconds: 3.73\n",
      "Epoch   6/100 Batch 1260/1562 - Loss:  1.601, Seconds: 3.80\n",
      "Epoch   6/100 Batch 1280/1562 - Loss:  1.644, Seconds: 3.90\n",
      "Epoch   6/100 Batch 1300/1562 - Loss:  1.430, Seconds: 3.84\n",
      "Epoch   6/100 Batch 1320/1562 - Loss:  1.461, Seconds: 3.43\n",
      "Epoch   6/100 Batch 1340/1562 - Loss:  1.388, Seconds: 3.71\n",
      "Epoch   6/100 Batch 1360/1562 - Loss:  1.466, Seconds: 3.58\n",
      "Epoch   6/100 Batch 1380/1562 - Loss:  1.390, Seconds: 3.69\n",
      "Epoch   6/100 Batch 1400/1562 - Loss:  1.426, Seconds: 3.77\n",
      "Epoch   6/100 Batch 1420/1562 - Loss:  1.673, Seconds: 4.47\n",
      "Epoch   6/100 Batch 1440/1562 - Loss:  1.781, Seconds: 3.66\n",
      "Epoch   6/100 Batch 1460/1562 - Loss:  1.757, Seconds: 3.71\n",
      "Epoch   6/100 Batch 1480/1562 - Loss:  1.697, Seconds: 3.90\n",
      "Epoch   6/100 Batch 1500/1562 - Loss:  1.664, Seconds: 3.84\n",
      "Epoch   6/100 Batch 1520/1562 - Loss:  1.566, Seconds: 4.21\n",
      "Epoch   6/100 Batch 1540/1562 - Loss:  1.596, Seconds: 3.81\n",
      "('Average loss for this update:', 1.557)\n",
      "New Record!\n",
      "Epoch   6/100 Batch 1560/1562 - Loss:  1.454, Seconds: 4.04\n",
      "Epoch   7/100 Batch   20/1562 - Loss:  1.870, Seconds: 3.16\n",
      "Epoch   7/100 Batch   40/1562 - Loss:  1.565, Seconds: 3.46\n",
      "Epoch   7/100 Batch   60/1562 - Loss:  1.601, Seconds: 3.40\n",
      "Epoch   7/100 Batch   80/1562 - Loss:  1.654, Seconds: 3.25\n",
      "Epoch   7/100 Batch  100/1562 - Loss:  1.551, Seconds: 2.92\n",
      "Epoch   7/100 Batch  120/1562 - Loss:  1.609, Seconds: 3.52\n",
      "Epoch   7/100 Batch  140/1562 - Loss:  1.482, Seconds: 3.04\n",
      "Epoch   7/100 Batch  160/1562 - Loss:  1.539, Seconds: 3.50\n",
      "Epoch   7/100 Batch  180/1562 - Loss:  1.590, Seconds: 3.46\n",
      "Epoch   7/100 Batch  200/1562 - Loss:  1.425, Seconds: 3.55\n",
      "Epoch   7/100 Batch  220/1562 - Loss:  1.265, Seconds: 3.46\n",
      "Epoch   7/100 Batch  240/1562 - Loss:  1.529, Seconds: 3.38\n",
      "Epoch   7/100 Batch  260/1562 - Loss:  1.520, Seconds: 3.15\n",
      "Epoch   7/100 Batch  280/1562 - Loss:  1.415, Seconds: 3.66\n",
      "Epoch   7/100 Batch  300/1562 - Loss:  1.401, Seconds: 3.41\n",
      "Epoch   7/100 Batch  320/1562 - Loss:  1.609, Seconds: 3.47\n",
      "Epoch   7/100 Batch  340/1562 - Loss:  1.720, Seconds: 3.07\n",
      "Epoch   7/100 Batch  360/1562 - Loss:  1.632, Seconds: 3.80\n",
      "Epoch   7/100 Batch  380/1562 - Loss:  1.517, Seconds: 3.56\n",
      "Epoch   7/100 Batch  400/1562 - Loss:  1.584, Seconds: 3.27\n",
      "Epoch   7/100 Batch  420/1562 - Loss:  1.590, Seconds: 3.51\n",
      "Epoch   7/100 Batch  440/1562 - Loss:  1.446, Seconds: 3.69\n",
      "Epoch   7/100 Batch  460/1562 - Loss:  1.555, Seconds: 3.53\n",
      "Epoch   7/100 Batch  480/1562 - Loss:  1.397, Seconds: 3.40\n",
      "Epoch   7/100 Batch  500/1562 - Loss:  1.226, Seconds: 3.18\n",
      "('Average loss for this update:', 1.531)\n",
      "New Record!\n",
      "Epoch   7/100 Batch  520/1562 - Loss:  1.513, Seconds: 3.44\n",
      "Epoch   7/100 Batch  540/1562 - Loss:  1.359, Seconds: 3.48\n",
      "Epoch   7/100 Batch  560/1562 - Loss:  1.512, Seconds: 3.59\n",
      "Epoch   7/100 Batch  580/1562 - Loss:  1.395, Seconds: 3.36\n",
      "Epoch   7/100 Batch  600/1562 - Loss:  1.475, Seconds: 3.49\n",
      "Epoch   7/100 Batch  620/1562 - Loss:  1.702, Seconds: 3.59\n",
      "Epoch   7/100 Batch  640/1562 - Loss:  1.623, Seconds: 3.75\n",
      "Epoch   7/100 Batch  660/1562 - Loss:  1.595, Seconds: 3.34\n",
      "Epoch   7/100 Batch  680/1562 - Loss:  1.584, Seconds: 3.85\n",
      "Epoch   7/100 Batch  700/1562 - Loss:  1.371, Seconds: 3.61\n",
      "Epoch   7/100 Batch  720/1562 - Loss:  1.538, Seconds: 3.66\n",
      "Epoch   7/100 Batch  740/1562 - Loss:  1.476, Seconds: 3.82\n",
      "Epoch   7/100 Batch  760/1562 - Loss:  1.435, Seconds: 4.14\n",
      "Epoch   7/100 Batch  780/1562 - Loss:  1.237, Seconds: 3.16\n",
      "Epoch   7/100 Batch  800/1562 - Loss:  1.425, Seconds: 3.56\n",
      "Epoch   7/100 Batch  820/1562 - Loss:  1.494, Seconds: 3.68\n",
      "Epoch   7/100 Batch  840/1562 - Loss:  1.385, Seconds: 3.55\n",
      "Epoch   7/100 Batch  860/1562 - Loss:  1.441, Seconds: 3.49\n",
      "Epoch   7/100 Batch  880/1562 - Loss:  1.530, Seconds: 3.66\n",
      "Epoch   7/100 Batch  900/1562 - Loss:  1.592, Seconds: 3.47\n",
      "Epoch   7/100 Batch  920/1562 - Loss:  1.525, Seconds: 3.77\n",
      "Epoch   7/100 Batch  940/1562 - Loss:  1.647, Seconds: 3.36\n",
      "Epoch   7/100 Batch  960/1562 - Loss:  1.424, Seconds: 3.64\n",
      "Epoch   7/100 Batch  980/1562 - Loss:  1.434, Seconds: 4.10\n",
      "Epoch   7/100 Batch 1000/1562 - Loss:  1.498, Seconds: 3.77\n",
      "Epoch   7/100 Batch 1020/1562 - Loss:  1.504, Seconds: 3.91\n",
      "('Average loss for this update:', 1.483)\n",
      "New Record!\n",
      "Epoch   7/100 Batch 1040/1562 - Loss:  1.325, Seconds: 3.91\n",
      "Epoch   7/100 Batch 1060/1562 - Loss:  1.286, Seconds: 3.66\n",
      "Epoch   7/100 Batch 1080/1562 - Loss:  1.312, Seconds: 3.76\n",
      "Epoch   7/100 Batch 1100/1562 - Loss:  1.449, Seconds: 3.68\n",
      "Epoch   7/100 Batch 1120/1562 - Loss:  1.426, Seconds: 3.65\n",
      "Epoch   7/100 Batch 1140/1562 - Loss:  1.266, Seconds: 3.11\n",
      "Epoch   7/100 Batch 1160/1562 - Loss:  1.520, Seconds: 3.64\n",
      "Epoch   7/100 Batch 1180/1562 - Loss:  1.578, Seconds: 3.49\n",
      "Epoch   7/100 Batch 1200/1562 - Loss:  1.707, Seconds: 3.75\n",
      "Epoch   7/100 Batch 1220/1562 - Loss:  1.614, Seconds: 3.52\n",
      "Epoch   7/100 Batch 1240/1562 - Loss:  1.461, Seconds: 3.72\n",
      "Epoch   7/100 Batch 1260/1562 - Loss:  1.490, Seconds: 3.55\n",
      "Epoch   7/100 Batch 1280/1562 - Loss:  1.561, Seconds: 3.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   7/100 Batch 1300/1562 - Loss:  1.368, Seconds: 3.76\n",
      "Epoch   7/100 Batch 1320/1562 - Loss:  1.355, Seconds: 3.31\n",
      "Epoch   7/100 Batch 1340/1562 - Loss:  1.321, Seconds: 3.49\n",
      "Epoch   7/100 Batch 1360/1562 - Loss:  1.372, Seconds: 3.18\n",
      "Epoch   7/100 Batch 1380/1562 - Loss:  1.313, Seconds: 3.99\n",
      "Epoch   7/100 Batch 1400/1562 - Loss:  1.346, Seconds: 4.09\n",
      "Epoch   7/100 Batch 1420/1562 - Loss:  1.578, Seconds: 4.26\n",
      "Epoch   7/100 Batch 1440/1562 - Loss:  1.700, Seconds: 3.85\n",
      "Epoch   7/100 Batch 1460/1562 - Loss:  1.698, Seconds: 4.09\n",
      "Epoch   7/100 Batch 1480/1562 - Loss:  1.619, Seconds: 3.76\n",
      "Epoch   7/100 Batch 1500/1562 - Loss:  1.569, Seconds: 4.17\n",
      "Epoch   7/100 Batch 1520/1562 - Loss:  1.457, Seconds: 4.00\n",
      "Epoch   7/100 Batch 1540/1562 - Loss:  1.513, Seconds: 3.91\n",
      "('Average loss for this update:', 1.472)\n",
      "New Record!\n",
      "Epoch   7/100 Batch 1560/1562 - Loss:  1.396, Seconds: 3.66\n",
      "Epoch   8/100 Batch   20/1562 - Loss:  1.797, Seconds: 3.11\n",
      "Epoch   8/100 Batch   40/1562 - Loss:  1.492, Seconds: 3.45\n",
      "Epoch   8/100 Batch   60/1562 - Loss:  1.517, Seconds: 3.44\n",
      "Epoch   8/100 Batch   80/1562 - Loss:  1.586, Seconds: 2.71\n",
      "Epoch   8/100 Batch  100/1562 - Loss:  1.475, Seconds: 3.14\n",
      "Epoch   8/100 Batch  120/1562 - Loss:  1.518, Seconds: 3.03\n",
      "Epoch   8/100 Batch  140/1562 - Loss:  1.402, Seconds: 3.22\n",
      "Epoch   8/100 Batch  160/1562 - Loss:  1.472, Seconds: 3.22\n",
      "Epoch   8/100 Batch  180/1562 - Loss:  1.509, Seconds: 3.47\n",
      "Epoch   8/100 Batch  200/1562 - Loss:  1.358, Seconds: 3.48\n",
      "Epoch   8/100 Batch  220/1562 - Loss:  1.201, Seconds: 2.89\n",
      "Epoch   8/100 Batch  240/1562 - Loss:  1.460, Seconds: 3.35\n",
      "Epoch   8/100 Batch  260/1562 - Loss:  1.462, Seconds: 3.33\n",
      "Epoch   8/100 Batch  280/1562 - Loss:  1.351, Seconds: 3.62\n",
      "Epoch   8/100 Batch  300/1562 - Loss:  1.345, Seconds: 3.34\n",
      "Epoch   8/100 Batch  320/1562 - Loss:  1.507, Seconds: 3.53\n",
      "Epoch   8/100 Batch  340/1562 - Loss:  1.655, Seconds: 2.90\n",
      "Epoch   8/100 Batch  360/1562 - Loss:  1.562, Seconds: 3.83\n",
      "Epoch   8/100 Batch  380/1562 - Loss:  1.483, Seconds: 3.49\n",
      "Epoch   8/100 Batch  400/1562 - Loss:  1.500, Seconds: 3.21\n",
      "Epoch   8/100 Batch  420/1562 - Loss:  1.487, Seconds: 3.76\n",
      "Epoch   8/100 Batch  440/1562 - Loss:  1.386, Seconds: 3.40\n",
      "Epoch   8/100 Batch  460/1562 - Loss:  1.518, Seconds: 3.36\n",
      "Epoch   8/100 Batch  480/1562 - Loss:  1.341, Seconds: 3.49\n",
      "Epoch   8/100 Batch  500/1562 - Loss:  1.175, Seconds: 3.28\n",
      "('Average loss for this update:', 1.461)\n",
      "New Record!\n",
      "Epoch   8/100 Batch  520/1562 - Loss:  1.431, Seconds: 3.52\n",
      "Epoch   8/100 Batch  540/1562 - Loss:  1.305, Seconds: 3.71\n",
      "Epoch   8/100 Batch  560/1562 - Loss:  1.432, Seconds: 3.60\n",
      "Epoch   8/100 Batch  580/1562 - Loss:  1.328, Seconds: 3.86\n",
      "Epoch   8/100 Batch  600/1562 - Loss:  1.402, Seconds: 3.32\n",
      "Epoch   8/100 Batch  620/1562 - Loss:  1.609, Seconds: 3.30\n",
      "Epoch   8/100 Batch  640/1562 - Loss:  1.561, Seconds: 4.34\n",
      "Epoch   8/100 Batch  660/1562 - Loss:  1.519, Seconds: 3.47\n",
      "Epoch   8/100 Batch  680/1562 - Loss:  1.506, Seconds: 4.66\n",
      "Epoch   8/100 Batch  700/1562 - Loss:  1.321, Seconds: 3.81\n",
      "Epoch   8/100 Batch  720/1562 - Loss:  1.479, Seconds: 3.43\n",
      "Epoch   8/100 Batch  740/1562 - Loss:  1.414, Seconds: 3.78\n",
      "Epoch   8/100 Batch  760/1562 - Loss:  1.371, Seconds: 3.98\n",
      "Epoch   8/100 Batch  780/1562 - Loss:  1.165, Seconds: 3.59\n",
      "Epoch   8/100 Batch  800/1562 - Loss:  1.354, Seconds: 3.36\n",
      "Epoch   8/100 Batch  820/1562 - Loss:  1.415, Seconds: 3.81\n",
      "Epoch   8/100 Batch  840/1562 - Loss:  1.312, Seconds: 3.43\n",
      "Epoch   8/100 Batch  860/1562 - Loss:  1.345, Seconds: 3.89\n",
      "Epoch   8/100 Batch  880/1562 - Loss:  1.411, Seconds: 3.72\n",
      "Epoch   8/100 Batch  900/1562 - Loss:  1.529, Seconds: 3.40\n",
      "Epoch   8/100 Batch  920/1562 - Loss:  1.452, Seconds: 3.88\n",
      "Epoch   8/100 Batch  940/1562 - Loss:  1.549, Seconds: 3.23\n",
      "Epoch   8/100 Batch  960/1562 - Loss:  1.376, Seconds: 4.14\n",
      "Epoch   8/100 Batch  980/1562 - Loss:  1.378, Seconds: 3.66\n",
      "Epoch   8/100 Batch 1000/1562 - Loss:  1.442, Seconds: 3.70\n",
      "Epoch   8/100 Batch 1020/1562 - Loss:  1.430, Seconds: 3.81\n",
      "('Average loss for this update:', 1.411)\n",
      "New Record!\n",
      "Epoch   8/100 Batch 1040/1562 - Loss:  1.261, Seconds: 3.86\n",
      "Epoch   8/100 Batch 1060/1562 - Loss:  1.228, Seconds: 3.69\n",
      "Epoch   8/100 Batch 1080/1562 - Loss:  1.258, Seconds: 3.81\n",
      "Epoch   8/100 Batch 1100/1562 - Loss:  1.381, Seconds: 3.42\n",
      "Epoch   8/100 Batch 1120/1562 - Loss:  1.349, Seconds: 3.74\n",
      "Epoch   8/100 Batch 1140/1562 - Loss:  1.211, Seconds: 3.36\n",
      "Epoch   8/100 Batch 1160/1562 - Loss:  1.463, Seconds: 3.65\n",
      "Epoch   8/100 Batch 1180/1562 - Loss:  1.510, Seconds: 3.87\n",
      "Epoch   8/100 Batch 1200/1562 - Loss:  1.610, Seconds: 3.42\n",
      "Epoch   8/100 Batch 1220/1562 - Loss:  1.519, Seconds: 3.35\n",
      "Epoch   8/100 Batch 1240/1562 - Loss:  1.402, Seconds: 3.76\n",
      "Epoch   8/100 Batch 1260/1562 - Loss:  1.431, Seconds: 3.55\n",
      "Epoch   8/100 Batch 1280/1562 - Loss:  1.507, Seconds: 3.70\n",
      "Epoch   8/100 Batch 1300/1562 - Loss:  1.319, Seconds: 4.20\n",
      "Epoch   8/100 Batch 1320/1562 - Loss:  1.312, Seconds: 3.38\n",
      "Epoch   8/100 Batch 1340/1562 - Loss:  1.276, Seconds: 3.74\n",
      "Epoch   8/100 Batch 1360/1562 - Loss:  1.328, Seconds: 3.53\n",
      "Epoch   8/100 Batch 1380/1562 - Loss:  1.249, Seconds: 3.62\n",
      "Epoch   8/100 Batch 1400/1562 - Loss:  1.287, Seconds: 3.61\n",
      "Epoch   8/100 Batch 1420/1562 - Loss:  1.501, Seconds: 4.34\n",
      "Epoch   8/100 Batch 1440/1562 - Loss:  1.633, Seconds: 3.69\n",
      "Epoch   8/100 Batch 1460/1562 - Loss:  1.617, Seconds: 3.90\n",
      "Epoch   8/100 Batch 1480/1562 - Loss:  1.544, Seconds: 3.64\n",
      "Epoch   8/100 Batch 1500/1562 - Loss:  1.490, Seconds: 3.75\n",
      "Epoch   8/100 Batch 1520/1562 - Loss:  1.406, Seconds: 3.87\n",
      "Epoch   8/100 Batch 1540/1562 - Loss:  1.456, Seconds: 3.69\n",
      "('Average loss for this update:', 1.408)\n",
      "New Record!\n",
      "Epoch   8/100 Batch 1560/1562 - Loss:  1.320, Seconds: 3.88\n",
      "Epoch   9/100 Batch   20/1562 - Loss:  1.747, Seconds: 3.05\n",
      "Epoch   9/100 Batch   40/1562 - Loss:  1.424, Seconds: 3.32\n",
      "Epoch   9/100 Batch   60/1562 - Loss:  1.444, Seconds: 3.95\n",
      "Epoch   9/100 Batch   80/1562 - Loss:  1.521, Seconds: 3.09\n",
      "Epoch   9/100 Batch  100/1562 - Loss:  1.418, Seconds: 3.05\n",
      "Epoch   9/100 Batch  120/1562 - Loss:  1.431, Seconds: 3.37\n",
      "Epoch   9/100 Batch  140/1562 - Loss:  1.341, Seconds: 3.18\n",
      "Epoch   9/100 Batch  160/1562 - Loss:  1.412, Seconds: 3.44\n",
      "Epoch   9/100 Batch  180/1562 - Loss:  1.433, Seconds: 3.59\n",
      "Epoch   9/100 Batch  200/1562 - Loss:  1.294, Seconds: 3.90\n",
      "Epoch   9/100 Batch  220/1562 - Loss:  1.135, Seconds: 3.33\n",
      "Epoch   9/100 Batch  240/1562 - Loss:  1.359, Seconds: 3.33\n",
      "Epoch   9/100 Batch  260/1562 - Loss:  1.365, Seconds: 3.44\n",
      "Epoch   9/100 Batch  280/1562 - Loss:  1.271, Seconds: 3.38\n",
      "Epoch   9/100 Batch  300/1562 - Loss:  1.283, Seconds: 3.74\n",
      "Epoch   9/100 Batch  320/1562 - Loss:  1.464, Seconds: 4.50\n",
      "Epoch   9/100 Batch  340/1562 - Loss:  1.572, Seconds: 3.34\n",
      "Epoch   9/100 Batch  360/1562 - Loss:  1.479, Seconds: 3.73\n",
      "Epoch   9/100 Batch  380/1562 - Loss:  1.407, Seconds: 3.43\n",
      "Epoch   9/100 Batch  400/1562 - Loss:  1.428, Seconds: 3.52\n",
      "Epoch   9/100 Batch  420/1562 - Loss:  1.407, Seconds: 3.45\n",
      "Epoch   9/100 Batch  440/1562 - Loss:  1.326, Seconds: 3.65\n",
      "Epoch   9/100 Batch  460/1562 - Loss:  1.428, Seconds: 3.64\n",
      "Epoch   9/100 Batch  480/1562 - Loss:  1.287, Seconds: 3.53\n",
      "Epoch   9/100 Batch  500/1562 - Loss:  1.111, Seconds: 3.46\n",
      "('Average loss for this update:', 1.39)\n",
      "New Record!\n",
      "Epoch   9/100 Batch  520/1562 - Loss:  1.363, Seconds: 3.37\n",
      "Epoch   9/100 Batch  540/1562 - Loss:  1.232, Seconds: 4.16\n",
      "Epoch   9/100 Batch  560/1562 - Loss:  1.342, Seconds: 3.66\n",
      "Epoch   9/100 Batch  580/1562 - Loss:  1.258, Seconds: 4.22\n",
      "Epoch   9/100 Batch  600/1562 - Loss:  1.329, Seconds: 3.33\n",
      "Epoch   9/100 Batch  620/1562 - Loss:  1.552, Seconds: 3.06\n",
      "Epoch   9/100 Batch  640/1562 - Loss:  1.504, Seconds: 3.47\n",
      "Epoch   9/100 Batch  660/1562 - Loss:  1.448, Seconds: 3.63\n",
      "Epoch   9/100 Batch  680/1562 - Loss:  1.448, Seconds: 3.43\n",
      "Epoch   9/100 Batch  700/1562 - Loss:  1.263, Seconds: 3.67\n",
      "Epoch   9/100 Batch  720/1562 - Loss:  1.396, Seconds: 3.43\n",
      "Epoch   9/100 Batch  740/1562 - Loss:  1.367, Seconds: 4.01\n",
      "Epoch   9/100 Batch  760/1562 - Loss:  1.304, Seconds: 3.67\n",
      "Epoch   9/100 Batch  780/1562 - Loss:  1.084, Seconds: 3.53\n",
      "Epoch   9/100 Batch  800/1562 - Loss:  1.290, Seconds: 3.48\n",
      "Epoch   9/100 Batch  820/1562 - Loss:  1.357, Seconds: 3.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   9/100 Batch  840/1562 - Loss:  1.272, Seconds: 3.52\n",
      "Epoch   9/100 Batch  860/1562 - Loss:  1.326, Seconds: 3.73\n",
      "Epoch   9/100 Batch  880/1562 - Loss:  1.379, Seconds: 3.78\n",
      "Epoch   9/100 Batch  900/1562 - Loss:  1.499, Seconds: 3.47\n",
      "Epoch   9/100 Batch  920/1562 - Loss:  1.411, Seconds: 3.72\n",
      "Epoch   9/100 Batch  940/1562 - Loss:  1.519, Seconds: 3.50\n",
      "Epoch   9/100 Batch  960/1562 - Loss:  1.325, Seconds: 3.58\n",
      "Epoch   9/100 Batch  980/1562 - Loss:  1.312, Seconds: 3.42\n",
      "Epoch   9/100 Batch 1000/1562 - Loss:  1.374, Seconds: 3.38\n",
      "Epoch   9/100 Batch 1020/1562 - Loss:  1.380, Seconds: 3.83\n",
      "('Average loss for this update:', 1.355)\n",
      "New Record!\n",
      "Epoch   9/100 Batch 1040/1562 - Loss:  1.231, Seconds: 4.01\n",
      "Epoch   9/100 Batch 1060/1562 - Loss:  1.187, Seconds: 3.76\n",
      "Epoch   9/100 Batch 1080/1562 - Loss:  1.206, Seconds: 3.66\n",
      "Epoch   9/100 Batch 1100/1562 - Loss:  1.330, Seconds: 2.96\n",
      "Epoch   9/100 Batch 1120/1562 - Loss:  1.306, Seconds: 3.13\n",
      "Epoch   9/100 Batch 1140/1562 - Loss:  1.180, Seconds: 3.60\n",
      "Epoch   9/100 Batch 1160/1562 - Loss:  1.398, Seconds: 3.51\n",
      "Epoch   9/100 Batch 1180/1562 - Loss:  1.427, Seconds: 3.70\n",
      "Epoch   9/100 Batch 1200/1562 - Loss:  1.558, Seconds: 3.77\n",
      "Epoch   9/100 Batch 1220/1562 - Loss:  1.451, Seconds: 3.50\n",
      "Epoch   9/100 Batch 1240/1562 - Loss:  1.362, Seconds: 2.77\n",
      "Epoch   9/100 Batch 1260/1562 - Loss:  1.369, Seconds: 3.48\n",
      "Epoch   9/100 Batch 1280/1562 - Loss:  1.438, Seconds: 3.61\n",
      "Epoch   9/100 Batch 1300/1562 - Loss:  1.256, Seconds: 3.91\n",
      "Epoch   9/100 Batch 1320/1562 - Loss:  1.237, Seconds: 3.50\n",
      "Epoch   9/100 Batch 1340/1562 - Loss:  1.194, Seconds: 4.60\n",
      "Epoch   9/100 Batch 1360/1562 - Loss:  1.262, Seconds: 3.84\n",
      "Epoch   9/100 Batch 1380/1562 - Loss:  1.201, Seconds: 3.79\n",
      "Epoch   9/100 Batch 1400/1562 - Loss:  1.222, Seconds: 3.62\n",
      "Epoch   9/100 Batch 1420/1562 - Loss:  1.418, Seconds: 4.04\n",
      "Epoch   9/100 Batch 1440/1562 - Loss:  1.554, Seconds: 3.85\n",
      "Epoch   9/100 Batch 1460/1562 - Loss:  1.562, Seconds: 3.78\n",
      "Epoch   9/100 Batch 1480/1562 - Loss:  1.505, Seconds: 3.66\n",
      "Epoch   9/100 Batch 1500/1562 - Loss:  1.450, Seconds: 3.91\n",
      "Epoch   9/100 Batch 1520/1562 - Loss:  1.360, Seconds: 3.87\n",
      "Epoch   9/100 Batch 1540/1562 - Loss:  1.402, Seconds: 3.97\n",
      "('Average loss for this update:', 1.351)\n",
      "New Record!\n",
      "Epoch   9/100 Batch 1560/1562 - Loss:  1.286, Seconds: 3.68\n",
      "Epoch  10/100 Batch   20/1562 - Loss:  1.682, Seconds: 3.54\n",
      "Epoch  10/100 Batch   40/1562 - Loss:  1.371, Seconds: 3.33\n",
      "Epoch  10/100 Batch   60/1562 - Loss:  1.391, Seconds: 3.31\n",
      "Epoch  10/100 Batch   80/1562 - Loss:  1.443, Seconds: 3.15\n",
      "Epoch  10/100 Batch  100/1562 - Loss:  1.352, Seconds: 3.23\n",
      "Epoch  10/100 Batch  120/1562 - Loss:  1.382, Seconds: 3.25\n",
      "Epoch  10/100 Batch  140/1562 - Loss:  1.273, Seconds: 3.30\n",
      "Epoch  10/100 Batch  160/1562 - Loss:  1.348, Seconds: 3.68\n",
      "Epoch  10/100 Batch  180/1562 - Loss:  1.383, Seconds: 3.41\n",
      "Epoch  14/100 Batch  520/1562 - Loss:  1.102, Seconds: 3.53\n",
      "Epoch  14/100 Batch  540/1562 - Loss:  1.029, Seconds: 3.58\n",
      "Epoch  14/100 Batch  560/1562 - Loss:  1.117, Seconds: 3.56\n",
      "Epoch  14/100 Batch  580/1562 - Loss:  1.022, Seconds: 3.43\n",
      "Epoch  15/100 Batch  600/1562 - Loss:  1.057, Seconds: 3.21\n",
      "Epoch  15/100 Batch  620/1562 - Loss:  1.189, Seconds: 3.50\n",
      "Epoch  15/100 Batch  640/1562 - Loss:  1.204, Seconds: 3.84\n",
      "Epoch  15/100 Batch  660/1562 - Loss:  1.185, Seconds: 3.42\n",
      "Epoch  15/100 Batch  680/1562 - Loss:  1.170, Seconds: 3.92\n",
      "Epoch  15/100 Batch  700/1562 - Loss:  0.992, Seconds: 3.82\n",
      "Epoch  15/100 Batch  720/1562 - Loss:  1.106, Seconds: 3.40\n",
      "Epoch  15/100 Batch  740/1562 - Loss:  1.097, Seconds: 3.92\n",
      "Epoch  15/100 Batch  760/1562 - Loss:  1.068, Seconds: 3.66\n",
      "Epoch  15/100 Batch  780/1562 - Loss:  0.866, Seconds: 3.34\n",
      "Epoch  15/100 Batch  800/1562 - Loss:  1.016, Seconds: 3.41\n",
      "Epoch  15/100 Batch  820/1562 - Loss:  1.073, Seconds: 3.88\n",
      "Epoch  15/100 Batch  840/1562 - Loss:  1.000, Seconds: 3.32\n",
      "Epoch  15/100 Batch  860/1562 - Loss:  1.042, Seconds: 3.21\n",
      "Epoch  15/100 Batch  880/1562 - Loss:  1.072, Seconds: 3.67\n",
      "Epoch  15/100 Batch  900/1562 - Loss:  1.158, Seconds: 3.55\n",
      "Epoch  15/100 Batch  920/1562 - Loss:  1.134, Seconds: 3.86\n",
      "Epoch  15/100 Batch  940/1562 - Loss:  1.210, Seconds: 3.41\n",
      "Epoch  15/100 Batch  960/1562 - Loss:  1.039, Seconds: 3.47\n",
      "Epoch  15/100 Batch  980/1562 - Loss:  1.019, Seconds: 3.35\n",
      "Epoch  15/100 Batch 1000/1562 - Loss:  1.126, Seconds: 3.61\n",
      "Epoch  15/100 Batch 1020/1562 - Loss:  1.087, Seconds: 3.70\n",
      "('Average loss for this update:', 1.076)\n",
      "New Record!\n",
      "Epoch  15/100 Batch 1040/1562 - Loss:  0.984, Seconds: 3.77\n",
      "Epoch  15/100 Batch 1060/1562 - Loss:  0.927, Seconds: 3.63\n",
      "Epoch  15/100 Batch 1080/1562 - Loss:  0.980, Seconds: 3.56\n",
      "Epoch  15/100 Batch 1100/1562 - Loss:  1.059, Seconds: 3.54\n",
      "Epoch  15/100 Batch 1120/1562 - Loss:  1.058, Seconds: 3.75\n",
      "Epoch  15/100 Batch 1140/1562 - Loss:  0.919, Seconds: 3.91\n",
      "Epoch  15/100 Batch 1160/1562 - Loss:  1.085, Seconds: 3.62\n",
      "Epoch  15/100 Batch 1180/1562 - Loss:  1.145, Seconds: 3.74\n",
      "Epoch  15/100 Batch 1200/1562 - Loss:  1.196, Seconds: 3.42\n",
      "Epoch  15/100 Batch 1220/1562 - Loss:  1.134, Seconds: 3.53\n",
      "Epoch  15/100 Batch 1240/1562 - Loss:  1.052, Seconds: 3.54\n",
      "Epoch  15/100 Batch 1260/1562 - Loss:  1.082, Seconds: 3.68\n",
      "Epoch  15/100 Batch 1280/1562 - Loss:  1.147, Seconds: 3.90\n",
      "Epoch  15/100 Batch 1300/1562 - Loss:  1.015, Seconds: 3.83\n",
      "Epoch  15/100 Batch 1320/1562 - Loss:  0.962, Seconds: 3.27\n",
      "Epoch  15/100 Batch 1340/1562 - Loss:  0.958, Seconds: 3.65\n",
      "Epoch  15/100 Batch 1360/1562 - Loss:  1.020, Seconds: 4.06\n",
      "Epoch  15/100 Batch 1380/1562 - Loss:  0.982, Seconds: 3.45\n",
      "Epoch  15/100 Batch 1400/1562 - Loss:  1.011, Seconds: 3.45\n",
      "Epoch  15/100 Batch 1420/1562 - Loss:  1.145, Seconds: 4.11\n",
      "Epoch  15/100 Batch 1440/1562 - Loss:  1.267, Seconds: 3.68\n",
      "Epoch  15/100 Batch 1460/1562 - Loss:  1.318, Seconds: 3.67\n",
      "Epoch  15/100 Batch 1480/1562 - Loss:  1.235, Seconds: 3.86\n",
      "Epoch  15/100 Batch 1500/1562 - Loss:  1.175, Seconds: 3.65\n",
      "Epoch  15/100 Batch 1520/1562 - Loss:  1.113, Seconds: 4.04\n",
      "Epoch  15/100 Batch 1540/1562 - Loss:  1.160, Seconds: 3.89\n",
      "('Average loss for this update:', 1.085)\n",
      "No Improvement.\n",
      "Epoch  15/100 Batch 1560/1562 - Loss:  1.044, Seconds: 3.72\n",
      "Epoch  16/100 Batch   20/1562 - Loss:  1.415, Seconds: 3.14\n",
      "Epoch  16/100 Batch   40/1562 - Loss:  1.115, Seconds: 3.59\n",
      "Epoch  16/100 Batch   60/1562 - Loss:  1.146, Seconds: 3.45\n",
      "Epoch  16/100 Batch   80/1562 - Loss:  1.174, Seconds: 3.21\n",
      "Epoch  16/100 Batch  100/1562 - Loss:  1.100, Seconds: 2.98\n",
      "Epoch  16/100 Batch  120/1562 - Loss:  1.130, Seconds: 3.40\n",
      "Epoch  16/100 Batch  140/1562 - Loss:  1.036, Seconds: 3.27\n",
      "Epoch  16/100 Batch  160/1562 - Loss:  1.103, Seconds: 3.34\n",
      "Epoch  16/100 Batch  180/1562 - Loss:  1.099, Seconds: 3.51\n",
      "Epoch  16/100 Batch  200/1562 - Loss:  1.001, Seconds: 3.50\n",
      "Epoch  16/100 Batch  220/1562 - Loss:  0.885, Seconds: 3.24\n",
      "Epoch  16/100 Batch  240/1562 - Loss:  1.048, Seconds: 3.28\n",
      "Epoch  16/100 Batch  260/1562 - Loss:  1.050, Seconds: 3.08\n",
      "Epoch  16/100 Batch  280/1562 - Loss:  1.006, Seconds: 3.34\n",
      "Epoch  16/100 Batch  300/1562 - Loss:  1.009, Seconds: 3.47\n",
      "Epoch  16/100 Batch  320/1562 - Loss:  1.128, Seconds: 3.13\n",
      "Epoch  16/100 Batch  340/1562 - Loss:  1.184, Seconds: 3.25\n",
      "Epoch  16/100 Batch  360/1562 - Loss:  1.151, Seconds: 3.54\n",
      "Epoch  16/100 Batch  380/1562 - Loss:  1.075, Seconds: 3.62\n",
      "Epoch  16/100 Batch  400/1562 - Loss:  1.102, Seconds: 3.84\n",
      "Epoch  16/100 Batch  420/1562 - Loss:  1.057, Seconds: 3.40\n",
      "Epoch  16/100 Batch  440/1562 - Loss:  1.015, Seconds: 3.60\n",
      "Epoch  16/100 Batch  460/1562 - Loss:  1.121, Seconds: 3.69\n",
      "Epoch  16/100 Batch  480/1562 - Loss:  0.995, Seconds: 3.41\n",
      "Epoch  16/100 Batch  500/1562 - Loss:  0.808, Seconds: 3.46\n",
      "('Average loss for this update:', 1.076)\n",
      "No Improvement.\n",
      "Epoch  16/100 Batch  520/1562 - Loss:  1.036, Seconds: 3.70\n",
      "Epoch  16/100 Batch  540/1562 - Loss:  0.976, Seconds: 3.97\n",
      "Epoch  16/100 Batch  560/1562 - Loss:  1.067, Seconds: 3.62\n",
      "Epoch  16/100 Batch  580/1562 - Loss:  0.969, Seconds: 3.76\n",
      "Epoch  16/100 Batch  600/1562 - Loss:  1.062, Seconds: 3.37\n",
      "Epoch  16/100 Batch  620/1562 - Loss:  1.202, Seconds: 3.63\n",
      "Epoch  16/100 Batch  640/1562 - Loss:  1.193, Seconds: 3.22\n",
      "Epoch  16/100 Batch  660/1562 - Loss:  1.175, Seconds: 3.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  16/100 Batch  680/1562 - Loss:  1.144, Seconds: 3.97\n",
      "Epoch  16/100 Batch  700/1562 - Loss:  1.014, Seconds: 3.52\n",
      "Epoch  16/100 Batch  720/1562 - Loss:  1.099, Seconds: 3.41\n",
      "Epoch  16/100 Batch  740/1562 - Loss:  1.084, Seconds: 3.84\n",
      "Epoch  16/100 Batch  760/1562 - Loss:  1.050, Seconds: 3.43\n",
      "Epoch  16/100 Batch  780/1562 - Loss:  0.858, Seconds: 3.53\n",
      "Epoch  16/100 Batch  800/1562 - Loss:  1.012, Seconds: 3.38\n",
      "Epoch  16/100 Batch  820/1562 - Loss:  1.029, Seconds: 3.81\n",
      "Epoch  16/100 Batch  840/1562 - Loss:  0.976, Seconds: 3.54\n",
      "Epoch  16/100 Batch  860/1562 - Loss:  1.008, Seconds: 3.60\n",
      "Epoch  16/100 Batch  880/1562 - Loss:  1.018, Seconds: 3.62\n",
      "Epoch  16/100 Batch  900/1562 - Loss:  1.127, Seconds: 3.66\n",
      "Epoch  16/100 Batch  920/1562 - Loss:  1.076, Seconds: 3.58\n",
      "Epoch  16/100 Batch  940/1562 - Loss:  1.181, Seconds: 3.71\n",
      "Epoch  16/100 Batch  960/1562 - Loss:  1.019, Seconds: 3.24\n",
      "Epoch  16/100 Batch  980/1562 - Loss:  1.016, Seconds: 3.60\n",
      "Epoch  16/100 Batch 1000/1562 - Loss:  1.102, Seconds: 3.60\n",
      "Epoch  16/100 Batch 1020/1562 - Loss:  1.105, Seconds: 3.66\n",
      "('Average loss for this update:', 1.058)\n",
      "New Record!\n",
      "Epoch  16/100 Batch 1040/1562 - Loss:  0.938, Seconds: 3.70\n",
      "Epoch  16/100 Batch 1060/1562 - Loss:  0.919, Seconds: 3.70\n",
      "Epoch  16/100 Batch 1080/1562 - Loss:  0.952, Seconds: 3.12\n",
      "Epoch  16/100 Batch 1100/1562 - Loss:  1.042, Seconds: 4.15\n",
      "Epoch  16/100 Batch 1120/1562 - Loss:  1.039, Seconds: 3.81\n",
      "Epoch  16/100 Batch 1140/1562 - Loss:  0.882, Seconds: 3.81\n",
      "Epoch  16/100 Batch 1160/1562 - Loss:  1.069, Seconds: 4.15\n",
      "Epoch  16/100 Batch 1180/1562 - Loss:  1.111, Seconds: 3.61\n",
      "Epoch  16/100 Batch 1200/1562 - Loss:  1.174, Seconds: 3.63\n",
      "Epoch  16/100 Batch 1220/1562 - Loss:  1.124, Seconds: 3.63\n",
      "Epoch  16/100 Batch 1240/1562 - Loss:  1.029, Seconds: 3.49\n",
      "Epoch  16/100 Batch 1260/1562 - Loss:  1.020, Seconds: 3.65\n",
      "Epoch  16/100 Batch 1280/1562 - Loss:  1.121, Seconds: 3.53\n",
      "Epoch  16/100 Batch 1300/1562 - Loss:  0.968, Seconds: 4.16\n",
      "Epoch  16/100 Batch 1320/1562 - Loss:  0.946, Seconds: 3.51\n",
      "Epoch  16/100 Batch 1340/1562 - Loss:  0.940, Seconds: 3.69\n",
      "Epoch  16/100 Batch 1360/1562 - Loss:  0.988, Seconds: 4.31\n",
      "Epoch  16/100 Batch 1380/1562 - Loss:  0.930, Seconds: 3.51\n",
      "Epoch  16/100 Batch 1400/1562 - Loss:  0.997, Seconds: 3.91\n",
      "Epoch  16/100 Batch 1420/1562 - Loss:  1.131, Seconds: 3.89\n",
      "Epoch  16/100 Batch 1440/1562 - Loss:  1.228, Seconds: 3.70\n",
      "Epoch  16/100 Batch 1460/1562 - Loss:  1.259, Seconds: 3.75\n",
      "Epoch  16/100 Batch 1480/1562 - Loss:  1.180, Seconds: 3.75\n",
      "Epoch  16/100 Batch 1500/1562 - Loss:  1.159, Seconds: 3.88\n",
      "Epoch  16/100 Batch 1520/1562 - Loss:  1.088, Seconds: 4.20\n",
      "Epoch  16/100 Batch 1540/1562 - Loss:  1.104, Seconds: 3.86\n",
      "('Average loss for this update:', 1.054)\n",
      "New Record!\n",
      "Epoch  16/100 Batch 1560/1562 - Loss:  0.998, Seconds: 3.67\n",
      "Epoch  17/100 Batch   20/1562 - Loss:  1.388, Seconds: 3.27\n",
      "Epoch  17/100 Batch   40/1562 - Loss:  1.082, Seconds: 3.63\n",
      "Epoch  17/100 Batch   60/1562 - Loss:  1.094, Seconds: 3.83\n",
      "Epoch  17/100 Batch   80/1562 - Loss:  1.163, Seconds: 3.26\n",
      "Epoch  17/100 Batch  100/1562 - Loss:  1.067, Seconds: 3.26\n",
      "Epoch  17/100 Batch  120/1562 - Loss:  1.108, Seconds: 3.30\n",
      "Epoch  17/100 Batch  140/1562 - Loss:  1.009, Seconds: 3.43\n",
      "Epoch  17/100 Batch  160/1562 - Loss:  1.056, Seconds: 3.42\n",
      "Epoch  17/100 Batch  180/1562 - Loss:  1.064, Seconds: 3.74\n",
      "Epoch  17/100 Batch  200/1562 - Loss:  0.939, Seconds: 3.48\n",
      "Epoch  17/100 Batch  220/1562 - Loss:  0.851, Seconds: 3.23\n",
      "Epoch  17/100 Batch  240/1562 - Loss:  1.008, Seconds: 3.07\n",
      "Epoch  17/100 Batch  260/1562 - Loss:  1.034, Seconds: 3.36\n",
      "Epoch  17/100 Batch  280/1562 - Loss:  0.966, Seconds: 3.64\n",
      "Epoch  17/100 Batch  300/1562 - Loss:  0.970, Seconds: 3.23\n",
      "Epoch  17/100 Batch  320/1562 - Loss:  1.089, Seconds: 3.33\n",
      "Epoch  17/100 Batch  340/1562 - Loss:  1.147, Seconds: 3.13\n",
      "Epoch  17/100 Batch  360/1562 - Loss:  1.114, Seconds: 4.02\n",
      "Epoch  17/100 Batch  380/1562 - Loss:  1.016, Seconds: 3.59\n",
      "Epoch  17/100 Batch  400/1562 - Loss:  1.062, Seconds: 3.44\n",
      "Epoch  17/100 Batch  420/1562 - Loss:  1.048, Seconds: 3.68\n",
      "Epoch  17/100 Batch  440/1562 - Loss:  0.981, Seconds: 3.68\n",
      "Epoch  17/100 Batch  460/1562 - Loss:  1.084, Seconds: 3.38\n",
      "Epoch  17/100 Batch  480/1562 - Loss:  0.967, Seconds: 3.34\n",
      "Epoch  17/100 Batch  500/1562 - Loss:  0.780, Seconds: 3.27\n",
      "('Average loss for this update:', 1.042)\n",
      "New Record!\n",
      "Epoch  17/100 Batch  520/1562 - Loss:  1.008, Seconds: 3.65\n",
      "Epoch  17/100 Batch  540/1562 - Loss:  0.951, Seconds: 3.64\n",
      "Epoch  17/100 Batch  560/1562 - Loss:  1.025, Seconds: 3.69\n",
      "Epoch  17/100 Batch  580/1562 - Loss:  0.937, Seconds: 3.86\n",
      "Epoch  17/100 Batch  600/1562 - Loss:  1.012, Seconds: 3.60\n",
      "Epoch  17/100 Batch  620/1562 - Loss:  1.146, Seconds: 3.27\n",
      "Epoch  17/100 Batch  640/1562 - Loss:  1.116, Seconds: 3.46\n",
      "Epoch  17/100 Batch  660/1562 - Loss:  1.122, Seconds: 3.30\n",
      "Epoch  17/100 Batch  680/1562 - Loss:  1.078, Seconds: 3.46\n",
      "Epoch  17/100 Batch  700/1562 - Loss:  0.933, Seconds: 3.73\n",
      "Epoch  17/100 Batch  720/1562 - Loss:  1.038, Seconds: 3.45\n",
      "Epoch  17/100 Batch  740/1562 - Loss:  1.027, Seconds: 3.63\n",
      "Epoch  17/100 Batch  760/1562 - Loss:  0.968, Seconds: 4.00\n",
      "Epoch  17/100 Batch  780/1562 - Loss:  0.803, Seconds: 3.40\n",
      "Epoch  17/100 Batch  800/1562 - Loss:  0.955, Seconds: 3.24\n",
      "Epoch  17/100 Batch  820/1562 - Loss:  1.002, Seconds: 3.84\n",
      "Epoch  17/100 Batch  840/1562 - Loss:  0.921, Seconds: 3.29\n",
      "Epoch  17/100 Batch  860/1562 - Loss:  0.956, Seconds: 3.46\n",
      "Epoch  17/100 Batch  880/1562 - Loss:  0.994, Seconds: 3.44\n",
      "Epoch  17/100 Batch  900/1562 - Loss:  1.090, Seconds: 3.59\n",
      "Epoch  17/100 Batch  920/1562 - Loss:  1.048, Seconds: 3.63\n",
      "Epoch  17/100 Batch  940/1562 - Loss:  1.121, Seconds: 3.26\n",
      "Epoch  17/100 Batch  960/1562 - Loss:  0.973, Seconds: 3.69\n",
      "Epoch  17/100 Batch  980/1562 - Loss:  0.958, Seconds: 3.63\n",
      "Epoch  17/100 Batch 1000/1562 - Loss:  1.061, Seconds: 3.75\n",
      "Epoch  17/100 Batch 1020/1562 - Loss:  1.078, Seconds: 3.83\n",
      "('Average loss for this update:', 1.01)\n",
      "New Record!\n",
      "Epoch  17/100 Batch 1040/1562 - Loss:  0.930, Seconds: 3.75\n",
      "Epoch  17/100 Batch 1060/1562 - Loss:  0.910, Seconds: 3.58\n",
      "Epoch  17/100 Batch 1080/1562 - Loss:  1.069, Seconds: 3.17\n",
      "Epoch  17/100 Batch 1100/1562 - Loss:  1.208, Seconds: 3.40\n",
      "Epoch  17/100 Batch 1120/1562 - Loss:  1.146, Seconds: 3.39\n",
      "Epoch  17/100 Batch 1140/1562 - Loss:  1.018, Seconds: 3.56\n",
      "Epoch  17/100 Batch 1160/1562 - Loss:  1.173, Seconds: 3.74\n",
      "Epoch  17/100 Batch 1180/1562 - Loss:  1.203, Seconds: 3.49\n",
      "Epoch  17/100 Batch 1200/1562 - Loss:  1.222, Seconds: 3.71\n",
      "Epoch  17/100 Batch 1220/1562 - Loss:  1.161, Seconds: 3.33\n",
      "Epoch  17/100 Batch 1240/1562 - Loss:  1.087, Seconds: 3.90\n",
      "Epoch  17/100 Batch 1260/1562 - Loss:  1.067, Seconds: 3.76\n",
      "Epoch  17/100 Batch 1280/1562 - Loss:  1.145, Seconds: 3.47\n",
      "Epoch  17/100 Batch 1300/1562 - Loss:  0.997, Seconds: 3.78\n",
      "Epoch  17/100 Batch 1320/1562 - Loss:  0.936, Seconds: 3.53\n",
      "Epoch  17/100 Batch 1340/1562 - Loss:  0.953, Seconds: 3.89\n",
      "Epoch  17/100 Batch 1360/1562 - Loss:  1.016, Seconds: 3.75\n",
      "Epoch  17/100 Batch 1380/1562 - Loss:  0.945, Seconds: 3.69\n",
      "Epoch  17/100 Batch 1400/1562 - Loss:  0.980, Seconds: 3.84\n",
      "Epoch  17/100 Batch 1420/1562 - Loss:  1.128, Seconds: 4.23\n",
      "Epoch  17/100 Batch 1440/1562 - Loss:  1.234, Seconds: 3.88\n",
      "Epoch  17/100 Batch 1460/1562 - Loss:  1.257, Seconds: 3.67\n",
      "Epoch  17/100 Batch 1480/1562 - Loss:  1.180, Seconds: 3.82\n",
      "Epoch  17/100 Batch 1500/1562 - Loss:  1.129, Seconds: 4.17\n",
      "Epoch  17/100 Batch 1520/1562 - Loss:  1.080, Seconds: 4.19\n",
      "Epoch  17/100 Batch 1540/1562 - Loss:  1.127, Seconds: 3.84\n",
      "('Average loss for this update:', 1.092)\n",
      "No Improvement.\n",
      "Epoch  17/100 Batch 1560/1562 - Loss:  1.011, Seconds: 3.06\n",
      "Epoch  18/100 Batch   20/1562 - Loss:  1.362, Seconds: 2.91\n",
      "Epoch  18/100 Batch   40/1562 - Loss:  1.077, Seconds: 3.62\n",
      "Epoch  18/100 Batch   60/1562 - Loss:  1.087, Seconds: 3.36\n",
      "Epoch  18/100 Batch   80/1562 - Loss:  1.148, Seconds: 2.88\n",
      "Epoch  18/100 Batch  100/1562 - Loss:  1.051, Seconds: 3.04\n",
      "Epoch  18/100 Batch  120/1562 - Loss:  1.069, Seconds: 3.26\n",
      "Epoch  18/100 Batch  140/1562 - Loss:  1.022, Seconds: 3.02\n",
      "Epoch  18/100 Batch  160/1562 - Loss:  1.052, Seconds: 3.50\n",
      "Epoch  18/100 Batch  180/1562 - Loss:  1.056, Seconds: 3.45\n",
      "Epoch  18/100 Batch  200/1562 - Loss:  0.936, Seconds: 3.51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  18/100 Batch  220/1562 - Loss:  0.856, Seconds: 3.28\n",
      "Epoch  18/100 Batch  240/1562 - Loss:  0.999, Seconds: 3.33\n",
      "Epoch  18/100 Batch  260/1562 - Loss:  1.008, Seconds: 3.39\n",
      "Epoch  18/100 Batch  280/1562 - Loss:  0.971, Seconds: 3.63\n",
      "Epoch  18/100 Batch  300/1562 - Loss:  0.942, Seconds: 3.35\n",
      "Epoch  18/100 Batch  320/1562 - Loss:  1.069, Seconds: 3.44\n",
      "Epoch  18/100 Batch  340/1562 - Loss:  1.131, Seconds: 3.28\n",
      "Epoch  18/100 Batch  360/1562 - Loss:  1.082, Seconds: 3.59\n",
      "Epoch  18/100 Batch  380/1562 - Loss:  1.011, Seconds: 3.35\n",
      "Epoch  18/100 Batch  400/1562 - Loss:  1.044, Seconds: 3.32\n",
      "Epoch  18/100 Batch  420/1562 - Loss:  1.037, Seconds: 3.67\n",
      "Epoch  18/100 Batch  440/1562 - Loss:  0.987, Seconds: 3.63\n",
      "Epoch  18/100 Batch  460/1562 - Loss:  1.059, Seconds: 3.05\n",
      "Epoch  18/100 Batch  480/1562 - Loss:  0.949, Seconds: 3.24\n",
      "Epoch  18/100 Batch  500/1562 - Loss:  0.778, Seconds: 3.37\n",
      "('Average loss for this update:', 1.03)\n",
      "No Improvement.\n",
      "Epoch  18/100 Batch  520/1562 - Loss:  0.998, Seconds: 3.67\n",
      "Epoch  18/100 Batch  540/1562 - Loss:  0.932, Seconds: 3.74\n",
      "Epoch  18/100 Batch  560/1562 - Loss:  0.983, Seconds: 3.51\n",
      "Epoch  18/100 Batch  580/1562 - Loss:  0.913, Seconds: 3.74\n",
      "Epoch  18/100 Batch  600/1562 - Loss:  0.993, Seconds: 3.40\n",
      "Epoch  18/100 Batch  620/1562 - Loss:  1.133, Seconds: 3.25\n",
      "Epoch  18/100 Batch  640/1562 - Loss:  1.096, Seconds: 3.56\n",
      "Epoch  18/100 Batch  660/1562 - Loss:  1.096, Seconds: 3.53\n",
      "Epoch  18/100 Batch  680/1562 - Loss:  1.049, Seconds: 3.53\n",
      "Epoch  18/100 Batch  700/1562 - Loss:  0.925, Seconds: 3.62\n",
      "Epoch  18/100 Batch  720/1562 - Loss:  1.027, Seconds: 3.61\n",
      "Epoch  18/100 Batch  740/1562 - Loss:  1.016, Seconds: 3.56\n",
      "Epoch  18/100 Batch  760/1562 - Loss:  0.961, Seconds: 3.44\n",
      "Epoch  18/100 Batch  780/1562 - Loss:  0.796, Seconds: 3.28\n",
      "Epoch  18/100 Batch  800/1562 - Loss:  0.943, Seconds: 3.38\n",
      "Epoch  18/100 Batch  820/1562 - Loss:  0.961, Seconds: 3.47\n",
      "Epoch  18/100 Batch  840/1562 - Loss:  0.901, Seconds: 3.37\n",
      "Epoch  18/100 Batch  860/1562 - Loss:  0.914, Seconds: 3.44\n",
      "Epoch  18/100 Batch  880/1562 - Loss:  0.969, Seconds: 3.48\n",
      "Epoch  18/100 Batch  900/1562 - Loss:  1.058, Seconds: 3.51\n",
      "Epoch  18/100 Batch  920/1562 - Loss:  1.015, Seconds: 3.38\n",
      "Epoch  18/100 Batch  940/1562 - Loss:  1.105, Seconds: 3.34\n",
      "Epoch  18/100 Batch  960/1562 - Loss:  0.939, Seconds: 3.58\n",
      "Epoch  18/100 Batch  980/1562 - Loss:  0.925, Seconds: 3.59\n",
      "Epoch  18/100 Batch 1000/1562 - Loss:  1.003, Seconds: 3.92\n",
      "Epoch  18/100 Batch 1020/1562 - Loss:  1.010, Seconds: 3.55\n",
      "('Average loss for this update:', 0.983)\n",
      "New Record!\n",
      "Epoch  18/100 Batch 1040/1562 - Loss:  0.887, Seconds: 3.93\n",
      "Epoch  18/100 Batch 1060/1562 - Loss:  0.849, Seconds: 4.16\n",
      "Epoch  18/100 Batch 1080/1562 - Loss:  0.896, Seconds: 3.31\n",
      "Epoch  18/100 Batch 1100/1562 - Loss:  0.980, Seconds: 3.48\n",
      "Epoch  18/100 Batch 1120/1562 - Loss:  0.964, Seconds: 3.45\n",
      "Epoch  18/100 Batch 1140/1562 - Loss:  0.850, Seconds: 3.73\n",
      "Epoch  18/100 Batch 1160/1562 - Loss:  1.004, Seconds: 3.82\n",
      "Epoch  18/100 Batch 1180/1562 - Loss:  1.051, Seconds: 3.29\n",
      "Epoch  18/100 Batch 1200/1562 - Loss:  1.113, Seconds: 3.72\n",
      "Epoch  18/100 Batch 1220/1562 - Loss:  1.006, Seconds: 3.53\n",
      "Epoch  18/100 Batch 1240/1562 - Loss:  0.976, Seconds: 3.60\n",
      "Epoch  18/100 Batch 1260/1562 - Loss:  0.962, Seconds: 3.66\n",
      "Epoch  18/100 Batch 1280/1562 - Loss:  1.030, Seconds: 3.53\n",
      "Epoch  18/100 Batch 1300/1562 - Loss:  0.910, Seconds: 3.76\n",
      "Epoch  18/100 Batch 1320/1562 - Loss:  0.870, Seconds: 3.40\n",
      "Epoch  18/100 Batch 1340/1562 - Loss:  0.886, Seconds: 3.86\n",
      "Epoch  18/100 Batch 1360/1562 - Loss:  0.929, Seconds: 3.46\n",
      "Epoch  18/100 Batch 1380/1562 - Loss:  0.889, Seconds: 3.44\n",
      "Epoch  18/100 Batch 1400/1562 - Loss:  0.939, Seconds: 3.76\n",
      "Epoch  18/100 Batch 1420/1562 - Loss:  1.045, Seconds: 3.84\n",
      "Epoch  18/100 Batch 1440/1562 - Loss:  1.145, Seconds: 3.71\n",
      "Epoch  18/100 Batch 1460/1562 - Loss:  1.176, Seconds: 3.73\n",
      "Epoch  18/100 Batch 1480/1562 - Loss:  1.104, Seconds: 3.75\n",
      "Epoch  18/100 Batch 1500/1562 - Loss:  1.055, Seconds: 3.41\n",
      "Epoch  18/100 Batch 1520/1562 - Loss:  1.022, Seconds: 4.05\n",
      "Epoch  18/100 Batch 1540/1562 - Loss:  1.078, Seconds: 3.53\n",
      "('Average loss for this update:', 0.988)\n",
      "No Improvement.\n",
      "Epoch  18/100 Batch 1560/1562 - Loss:  0.941, Seconds: 3.83\n",
      "Epoch  19/100 Batch   20/1562 - Loss:  1.288, Seconds: 3.12\n",
      "Epoch  19/100 Batch   40/1562 - Loss:  1.020, Seconds: 3.47\n",
      "Epoch  19/100 Batch   60/1562 - Loss:  1.031, Seconds: 3.40\n",
      "Epoch  19/100 Batch   80/1562 - Loss:  1.084, Seconds: 2.97\n",
      "Epoch  19/100 Batch  100/1562 - Loss:  0.992, Seconds: 3.58\n",
      "Epoch  19/100 Batch  120/1562 - Loss:  1.012, Seconds: 3.24\n",
      "Epoch  19/100 Batch  140/1562 - Loss:  0.950, Seconds: 3.21\n",
      "Epoch  19/100 Batch  160/1562 - Loss:  0.984, Seconds: 3.43\n",
      "Epoch  19/100 Batch  180/1562 - Loss:  1.004, Seconds: 3.20\n",
      "Epoch  19/100 Batch  200/1562 - Loss:  0.889, Seconds: 3.33\n",
      "Epoch  19/100 Batch  220/1562 - Loss:  0.790, Seconds: 3.38\n",
      "Epoch  19/100 Batch  240/1562 - Loss:  0.950, Seconds: 3.31\n",
      "Epoch  19/100 Batch  260/1562 - Loss:  0.953, Seconds: 3.11\n",
      "Epoch  19/100 Batch  280/1562 - Loss:  0.922, Seconds: 3.30\n",
      "Epoch  19/100 Batch  300/1562 - Loss:  0.924, Seconds: 3.31\n",
      "Epoch  19/100 Batch  320/1562 - Loss:  1.002, Seconds: 4.44\n",
      "Epoch  19/100 Batch  340/1562 - Loss:  1.056, Seconds: 3.18\n",
      "Epoch  19/100 Batch  360/1562 - Loss:  1.054, Seconds: 3.94\n",
      "Epoch  19/100 Batch  380/1562 - Loss:  0.958, Seconds: 3.34\n",
      "Epoch  19/100 Batch  400/1562 - Loss:  0.983, Seconds: 3.61\n",
      "Epoch  19/100 Batch  420/1562 - Loss:  0.969, Seconds: 3.76\n",
      "Epoch  19/100 Batch  440/1562 - Loss:  0.908, Seconds: 3.88\n",
      "Epoch  19/100 Batch  460/1562 - Loss:  1.000, Seconds: 3.63\n",
      "Epoch  19/100 Batch  480/1562 - Loss:  0.927, Seconds: 3.36\n",
      "Epoch  19/100 Batch  500/1562 - Loss:  0.755, Seconds: 3.18\n",
      "('Average loss for this update:', 0.974)\n",
      "New Record!\n",
      "Epoch  19/100 Batch  520/1562 - Loss:  0.921, Seconds: 3.56\n",
      "Epoch  19/100 Batch  540/1562 - Loss:  0.909, Seconds: 3.53\n",
      "Epoch  19/100 Batch  560/1562 - Loss:  0.960, Seconds: 3.60\n",
      "Epoch  19/100 Batch  580/1562 - Loss:  0.877, Seconds: 3.56\n",
      "Epoch  19/100 Batch  600/1562 - Loss:  0.944, Seconds: 3.35\n",
      "Epoch  19/100 Batch  620/1562 - Loss:  1.047, Seconds: 3.25\n",
      "Epoch  19/100 Batch  640/1562 - Loss:  1.074, Seconds: 3.64\n",
      "Epoch  19/100 Batch  660/1562 - Loss:  1.044, Seconds: 3.45\n",
      "Epoch  19/100 Batch  680/1562 - Loss:  0.999, Seconds: 3.63\n",
      "Epoch  19/100 Batch  700/1562 - Loss:  0.898, Seconds: 4.01\n",
      "Epoch  19/100 Batch  720/1562 - Loss:  0.983, Seconds: 3.30\n",
      "Epoch  19/100 Batch  740/1562 - Loss:  0.999, Seconds: 3.88\n",
      "Epoch  19/100 Batch  760/1562 - Loss:  0.947, Seconds: 4.13\n",
      "Epoch  19/100 Batch  780/1562 - Loss:  0.764, Seconds: 3.77\n",
      "Epoch  19/100 Batch  800/1562 - Loss:  0.904, Seconds: 3.95\n",
      "Epoch  19/100 Batch  820/1562 - Loss:  0.945, Seconds: 3.40\n",
      "Epoch  19/100 Batch  840/1562 - Loss:  0.883, Seconds: 3.51\n",
      "Epoch  19/100 Batch  860/1562 - Loss:  0.908, Seconds: 3.70\n",
      "Epoch  19/100 Batch  880/1562 - Loss:  0.935, Seconds: 3.78\n",
      "Epoch  19/100 Batch  900/1562 - Loss:  1.001, Seconds: 3.78\n",
      "Epoch  19/100 Batch  920/1562 - Loss:  0.983, Seconds: 3.68\n",
      "Epoch  19/100 Batch  940/1562 - Loss:  1.093, Seconds: 3.41\n",
      "Epoch  19/100 Batch  960/1562 - Loss:  0.916, Seconds: 3.42\n",
      "Epoch  19/100 Batch  980/1562 - Loss:  0.888, Seconds: 3.60\n",
      "Epoch  19/100 Batch 1000/1562 - Loss:  1.007, Seconds: 3.76\n",
      "Epoch  19/100 Batch 1020/1562 - Loss:  0.995, Seconds: 3.76\n",
      "('Average loss for this update:', 0.953)\n",
      "New Record!\n",
      "Epoch  19/100 Batch 1040/1562 - Loss:  0.865, Seconds: 3.86\n",
      "Epoch  19/100 Batch 1060/1562 - Loss:  0.825, Seconds: 3.12\n",
      "Epoch  19/100 Batch 1080/1562 - Loss:  0.879, Seconds: 3.53\n",
      "Epoch  19/100 Batch 1100/1562 - Loss:  0.948, Seconds: 3.22\n",
      "Epoch  19/100 Batch 1120/1562 - Loss:  0.967, Seconds: 3.64\n",
      "Epoch  19/100 Batch 1140/1562 - Loss:  0.836, Seconds: 3.68\n",
      "Epoch  19/100 Batch 1160/1562 - Loss:  0.957, Seconds: 3.82\n",
      "Epoch  19/100 Batch 1180/1562 - Loss:  1.035, Seconds: 3.84\n",
      "Epoch  19/100 Batch 1200/1562 - Loss:  1.065, Seconds: 3.33\n",
      "Epoch  19/100 Batch 1220/1562 - Loss:  0.999, Seconds: 3.43\n",
      "Epoch  19/100 Batch 1240/1562 - Loss:  0.967, Seconds: 3.64\n",
      "Epoch  19/100 Batch 1260/1562 - Loss:  0.925, Seconds: 3.57\n",
      "Epoch  19/100 Batch 1280/1562 - Loss:  1.012, Seconds: 3.56\n",
      "Epoch  19/100 Batch 1300/1562 - Loss:  0.913, Seconds: 3.51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  19/100 Batch 1320/1562 - Loss:  0.869, Seconds: 3.48\n",
      "Epoch  19/100 Batch 1340/1562 - Loss:  0.865, Seconds: 3.86\n",
      "Epoch  19/100 Batch 1360/1562 - Loss:  0.907, Seconds: 3.64\n",
      "Epoch  19/100 Batch 1380/1562 - Loss:  0.862, Seconds: 3.42\n",
      "Epoch  19/100 Batch 1400/1562 - Loss:  0.925, Seconds: 3.86\n",
      "Epoch  19/100 Batch 1420/1562 - Loss:  1.031, Seconds: 3.88\n",
      "Epoch  19/100 Batch 1440/1562 - Loss:  1.115, Seconds: 3.75\n",
      "Epoch  19/100 Batch 1460/1562 - Loss:  1.162, Seconds: 3.76\n",
      "Epoch  19/100 Batch 1480/1562 - Loss:  1.092, Seconds: 3.51\n",
      "Epoch  19/100 Batch 1500/1562 - Loss:  1.043, Seconds: 3.64\n",
      "Epoch  19/100 Batch 1520/1562 - Loss:  1.005, Seconds: 3.94\n",
      "Epoch  19/100 Batch 1540/1562 - Loss:  1.043, Seconds: 3.88\n",
      "('Average loss for this update:', 0.969)\n",
      "No Improvement.\n",
      "Epoch  19/100 Batch 1560/1562 - Loss:  0.929, Seconds: 3.86\n",
      "Epoch  20/100 Batch   20/1562 - Loss:  1.260, Seconds: 3.28\n",
      "Epoch  20/100 Batch   40/1562 - Loss:  1.004, Seconds: 3.17\n",
      "Epoch  20/100 Batch   60/1562 - Loss:  1.000, Seconds: 3.83\n",
      "Epoch  20/100 Batch   80/1562 - Loss:  1.079, Seconds: 3.08\n",
      "Epoch  20/100 Batch  100/1562 - Loss:  0.979, Seconds: 3.19\n",
      "Epoch  20/100 Batch  120/1562 - Loss:  0.997, Seconds: 3.11\n",
      "Epoch  20/100 Batch  140/1562 - Loss:  0.951, Seconds: 3.19\n",
      "Epoch  20/100 Batch  160/1562 - Loss:  0.997, Seconds: 3.50\n",
      "Epoch  20/100 Batch  180/1562 - Loss:  0.987, Seconds: 3.48\n",
      "Epoch  20/100 Batch  200/1562 - Loss:  0.887, Seconds: 3.50\n",
      "Epoch  20/100 Batch  220/1562 - Loss:  0.774, Seconds: 3.69\n",
      "Epoch  20/100 Batch  240/1562 - Loss:  0.941, Seconds: 3.27\n",
      "Epoch  20/100 Batch  260/1562 - Loss:  0.927, Seconds: 3.06\n",
      "Epoch  20/100 Batch  280/1562 - Loss:  0.907, Seconds: 3.83\n",
      "Epoch  20/100 Batch  300/1562 - Loss:  0.891, Seconds: 3.29\n",
      "Epoch  20/100 Batch  320/1562 - Loss:  0.998, Seconds: 3.46\n",
      "Epoch  20/100 Batch  340/1562 - Loss:  1.049, Seconds: 3.11\n",
      "Epoch  20/100 Batch  360/1562 - Loss:  1.027, Seconds: 3.50\n",
      "Epoch  20/100 Batch  380/1562 - Loss:  0.948, Seconds: 3.14\n",
      "Epoch  20/100 Batch  400/1562 - Loss:  0.950, Seconds: 3.72\n",
      "Epoch  20/100 Batch  420/1562 - Loss:  0.942, Seconds: 3.65\n",
      "Epoch  20/100 Batch  440/1562 - Loss:  0.914, Seconds: 3.32\n",
      "Epoch  20/100 Batch  460/1562 - Loss:  0.993, Seconds: 3.10\n",
      "Epoch  20/100 Batch  480/1562 - Loss:  0.888, Seconds: 3.43\n",
      "Epoch  20/100 Batch  500/1562 - Loss:  0.718, Seconds: 3.50\n",
      "('Average loss for this update:', 0.958)\n",
      "No Improvement.\n",
      "Epoch  20/100 Batch  520/1562 - Loss:  0.912, Seconds: 3.61\n",
      "Epoch  20/100 Batch  540/1562 - Loss:  0.866, Seconds: 3.51\n",
      "Epoch  20/100 Batch  560/1562 - Loss:  0.926, Seconds: 3.56\n",
      "Epoch  20/100 Batch  580/1562 - Loss:  0.851, Seconds: 3.41\n",
      "Epoch  20/100 Batch  600/1562 - Loss:  0.949, Seconds: 3.35\n",
      "Epoch  20/100 Batch  620/1562 - Loss:  1.078, Seconds: 3.38\n",
      "Epoch  20/100 Batch  640/1562 - Loss:  1.039, Seconds: 3.57\n",
      "Epoch  20/100 Batch  660/1562 - Loss:  1.037, Seconds: 3.44\n",
      "Epoch  20/100 Batch  680/1562 - Loss:  0.983, Seconds: 3.80\n",
      "Epoch  20/100 Batch  700/1562 - Loss:  0.871, Seconds: 3.59\n",
      "Epoch  20/100 Batch  720/1562 - Loss:  0.964, Seconds: 3.31\n",
      "Epoch  20/100 Batch  740/1562 - Loss:  0.975, Seconds: 3.71\n",
      "Epoch  20/100 Batch  760/1562 - Loss:  0.910, Seconds: 3.68\n",
      "Epoch  20/100 Batch  780/1562 - Loss:  0.739, Seconds: 3.57\n",
      "Epoch  20/100 Batch  800/1562 - Loss:  0.899, Seconds: 3.52\n",
      "Epoch  20/100 Batch  820/1562 - Loss:  0.912, Seconds: 3.79\n",
      "Epoch  20/100 Batch  840/1562 - Loss:  0.861, Seconds: 3.41\n",
      "Epoch  20/100 Batch  860/1562 - Loss:  0.867, Seconds: 3.52\n",
      "Epoch  20/100 Batch  880/1562 - Loss:  0.893, Seconds: 3.90\n",
      "Epoch  20/100 Batch  900/1562 - Loss:  0.982, Seconds: 3.64\n",
      "Epoch  20/100 Batch  920/1562 - Loss:  0.951, Seconds: 3.70\n",
      "Epoch  20/100 Batch  940/1562 - Loss:  1.036, Seconds: 3.21\n",
      "Epoch  20/100 Batch  960/1562 - Loss:  0.900, Seconds: 3.68\n",
      "Epoch  20/100 Batch  980/1562 - Loss:  0.861, Seconds: 3.72\n",
      "Epoch  20/100 Batch 1000/1562 - Loss:  0.983, Seconds: 3.45\n",
      "Epoch  20/100 Batch 1020/1562 - Loss:  0.951, Seconds: 4.10\n",
      "('Average loss for this update:', 0.928)\n",
      "New Record!\n",
      "Epoch  20/100 Batch 1040/1562 - Loss:  0.839, Seconds: 3.79\n",
      "Epoch  20/100 Batch 1060/1562 - Loss:  0.795, Seconds: 3.80\n",
      "Epoch  20/100 Batch 1080/1562 - Loss:  0.853, Seconds: 3.64\n",
      "Epoch  20/100 Batch 1100/1562 - Loss:  0.942, Seconds: 3.35\n",
      "Epoch  20/100 Batch 1120/1562 - Loss:  0.938, Seconds: 3.78\n",
      "Epoch  20/100 Batch 1140/1562 - Loss:  0.797, Seconds: 3.65\n",
      "Epoch  20/100 Batch 1160/1562 - Loss:  0.948, Seconds: 3.77\n",
      "Epoch  20/100 Batch 1180/1562 - Loss:  1.010, Seconds: 3.99\n",
      "Epoch  20/100 Batch 1200/1562 - Loss:  1.011, Seconds: 3.62\n",
      "Epoch  20/100 Batch 1220/1562 - Loss:  0.952, Seconds: 3.77\n",
      "Epoch  20/100 Batch 1240/1562 - Loss:  0.923, Seconds: 3.79\n",
      "Epoch  20/100 Batch 1260/1562 - Loss:  0.934, Seconds: 3.71\n",
      "Epoch  20/100 Batch 1280/1562 - Loss:  0.996, Seconds: 3.69\n",
      "Epoch  20/100 Batch 1300/1562 - Loss:  0.898, Seconds: 4.01\n",
      "Epoch  20/100 Batch 1320/1562 - Loss:  0.851, Seconds: 3.41\n",
      "Epoch  20/100 Batch 1340/1562 - Loss:  0.861, Seconds: 3.66\n",
      "Epoch  20/100 Batch 1360/1562 - Loss:  0.911, Seconds: 3.76\n",
      "Epoch  20/100 Batch 1380/1562 - Loss:  0.876, Seconds: 3.58\n",
      "Epoch  20/100 Batch 1400/1562 - Loss:  0.921, Seconds: 3.88\n",
      "Epoch  20/100 Batch 1420/1562 - Loss:  1.030, Seconds: 4.26\n",
      "Epoch  20/100 Batch 1440/1562 - Loss:  1.098, Seconds: 3.67\n",
      "Epoch  20/100 Batch 1460/1562 - Loss:  1.133, Seconds: 4.41\n",
      "Epoch  20/100 Batch 1480/1562 - Loss:  1.071, Seconds: 3.58\n",
      "Epoch  20/100 Batch 1500/1562 - Loss:  1.022, Seconds: 4.15\n",
      "Epoch  20/100 Batch 1520/1562 - Loss:  0.992, Seconds: 3.94\n",
      "Epoch  20/100 Batch 1540/1562 - Loss:  1.021, Seconds: 3.93\n",
      "('Average loss for this update:', 0.951)\n",
      "No Improvement.\n",
      "Epoch  20/100 Batch 1560/1562 - Loss:  0.924, Seconds: 3.51\n",
      "Epoch  21/100 Batch   20/1562 - Loss:  1.220, Seconds: 3.56\n",
      "Epoch  21/100 Batch   40/1562 - Loss:  0.980, Seconds: 3.74\n",
      "Epoch  21/100 Batch   60/1562 - Loss:  0.981, Seconds: 3.51\n",
      "Epoch  21/100 Batch   80/1562 - Loss:  1.041, Seconds: 3.05\n",
      "Epoch  21/100 Batch  100/1562 - Loss:  0.954, Seconds: 3.23\n",
      "Epoch  21/100 Batch  120/1562 - Loss:  0.975, Seconds: 3.15\n",
      "Epoch  21/100 Batch  140/1562 - Loss:  0.906, Seconds: 3.46\n",
      "Epoch  21/100 Batch  160/1562 - Loss:  0.940, Seconds: 3.47\n",
      "Epoch  21/100 Batch  180/1562 - Loss:  0.941, Seconds: 3.66\n",
      "Epoch  21/100 Batch  200/1562 - Loss:  0.837, Seconds: 3.43\n",
      "Epoch  21/100 Batch  220/1562 - Loss:  0.772, Seconds: 3.47\n",
      "Epoch  21/100 Batch  240/1562 - Loss:  0.905, Seconds: 3.34\n",
      "Epoch  21/100 Batch  260/1562 - Loss:  0.910, Seconds: 3.24\n",
      "Epoch  21/100 Batch  280/1562 - Loss:  0.865, Seconds: 3.40\n",
      "Epoch  21/100 Batch  300/1562 - Loss:  0.871, Seconds: 3.38\n",
      "Epoch  21/100 Batch  320/1562 - Loss:  0.960, Seconds: 3.45\n",
      "Epoch  21/100 Batch  340/1562 - Loss:  1.009, Seconds: 3.09\n",
      "Epoch  21/100 Batch  360/1562 - Loss:  0.998, Seconds: 3.90\n",
      "Epoch  21/100 Batch  380/1562 - Loss:  0.909, Seconds: 3.32\n",
      "Epoch  21/100 Batch  400/1562 - Loss:  0.920, Seconds: 3.37\n",
      "Epoch  21/100 Batch  420/1562 - Loss:  0.899, Seconds: 3.34\n",
      "Epoch  21/100 Batch  440/1562 - Loss:  0.878, Seconds: 3.31\n",
      "Epoch  21/100 Batch  460/1562 - Loss:  0.956, Seconds: 3.35\n",
      "Epoch  21/100 Batch  480/1562 - Loss:  0.865, Seconds: 3.02\n",
      "Epoch  21/100 Batch  500/1562 - Loss:  0.706, Seconds: 3.36\n",
      "('Average loss for this update:', 0.926)\n",
      "New Record!\n",
      "Epoch  21/100 Batch  520/1562 - Loss:  0.896, Seconds: 3.64\n",
      "Epoch  21/100 Batch  540/1562 - Loss:  0.875, Seconds: 3.76\n",
      "Epoch  21/100 Batch  560/1562 - Loss:  0.920, Seconds: 3.63\n",
      "Epoch  21/100 Batch  580/1562 - Loss:  0.845, Seconds: 3.09\n",
      "Epoch  21/100 Batch  600/1562 - Loss:  0.905, Seconds: 3.01\n",
      "Epoch  21/100 Batch  620/1562 - Loss:  1.024, Seconds: 3.23\n",
      "Epoch  21/100 Batch  640/1562 - Loss:  1.000, Seconds: 3.61\n",
      "Epoch  21/100 Batch  660/1562 - Loss:  0.995, Seconds: 3.61\n",
      "Epoch  21/100 Batch  680/1562 - Loss:  0.967, Seconds: 3.69\n",
      "Epoch  21/100 Batch  700/1562 - Loss:  0.860, Seconds: 3.64\n",
      "Epoch  21/100 Batch  720/1562 - Loss:  0.936, Seconds: 3.86\n",
      "Epoch  21/100 Batch  740/1562 - Loss:  0.951, Seconds: 3.49\n",
      "Epoch  21/100 Batch  760/1562 - Loss:  0.883, Seconds: 3.55\n",
      "Epoch  21/100 Batch  780/1562 - Loss:  0.733, Seconds: 3.42\n",
      "Epoch  21/100 Batch  800/1562 - Loss:  0.875, Seconds: 3.31\n",
      "Epoch  21/100 Batch  820/1562 - Loss:  0.897, Seconds: 3.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  21/100 Batch  840/1562 - Loss:  0.826, Seconds: 3.39\n",
      "Epoch  21/100 Batch  860/1562 - Loss:  0.847, Seconds: 3.28\n",
      "Epoch  21/100 Batch  880/1562 - Loss:  0.877, Seconds: 3.54\n",
      "Epoch  21/100 Batch  900/1562 - Loss:  0.935, Seconds: 3.49\n",
      "Epoch  21/100 Batch  920/1562 - Loss:  0.926, Seconds: 3.79\n",
      "Epoch  21/100 Batch  940/1562 - Loss:  1.015, Seconds: 3.70\n",
      "Epoch  21/100 Batch  960/1562 - Loss:  0.858, Seconds: 3.56\n",
      "Epoch  21/100 Batch  980/1562 - Loss:  0.839, Seconds: 3.71\n",
      "Epoch  21/100 Batch 1000/1562 - Loss:  0.930, Seconds: 3.73\n",
      "Epoch  21/100 Batch 1020/1562 - Loss:  0.956, Seconds: 3.74\n",
      "('Average loss for this update:', 0.905)\n",
      "New Record!\n",
      "Epoch  21/100 Batch 1040/1562 - Loss:  0.851, Seconds: 3.56\n",
      "Epoch  21/100 Batch 1060/1562 - Loss:  0.779, Seconds: 3.76\n",
      "Epoch  21/100 Batch 1080/1562 - Loss:  0.829, Seconds: 3.62\n",
      "Epoch  21/100 Batch 1100/1562 - Loss:  0.907, Seconds: 3.32\n",
      "Epoch  21/100 Batch 1120/1562 - Loss:  0.909, Seconds: 3.67\n",
      "Epoch  21/100 Batch 1140/1562 - Loss:  0.765, Seconds: 3.51\n",
      "Epoch  21/100 Batch 1160/1562 - Loss:  0.929, Seconds: 4.08\n",
      "Epoch  21/100 Batch 1180/1562 - Loss:  0.966, Seconds: 3.77\n",
      "Epoch  21/100 Batch 1200/1562 - Loss:  1.006, Seconds: 3.20\n",
      "Epoch  21/100 Batch 1220/1562 - Loss:  0.958, Seconds: 3.54\n",
      "Epoch  21/100 Batch 1240/1562 - Loss:  0.893, Seconds: 3.23\n",
      "Epoch  21/100 Batch 1260/1562 - Loss:  0.896, Seconds: 3.45\n",
      "Epoch  21/100 Batch 1280/1562 - Loss:  0.950, Seconds: 3.24\n",
      "Epoch  21/100 Batch 1300/1562 - Loss:  0.840, Seconds: 4.18\n",
      "Epoch  21/100 Batch 1320/1562 - Loss:  0.802, Seconds: 3.36\n",
      "Epoch  21/100 Batch 1340/1562 - Loss:  0.837, Seconds: 3.84\n",
      "Epoch  21/100 Batch 1360/1562 - Loss:  0.854, Seconds: 3.87\n",
      "Epoch  21/100 Batch 1380/1562 - Loss:  0.831, Seconds: 3.72\n",
      "Epoch  21/100 Batch 1400/1562 - Loss:  0.875, Seconds: 4.02\n",
      "Epoch  21/100 Batch 1420/1562 - Loss:  0.995, Seconds: 3.88\n",
      "Epoch  21/100 Batch 1440/1562 - Loss:  1.087, Seconds: 3.81\n",
      "Epoch  21/100 Batch 1460/1562 - Loss:  1.094, Seconds: 3.75\n",
      "Epoch  21/100 Batch 1480/1562 - Loss:  1.034, Seconds: 3.37\n",
      "Epoch  21/100 Batch 1500/1562 - Loss:  0.997, Seconds: 3.77\n",
      "Epoch  21/100 Batch 1520/1562 - Loss:  0.956, Seconds: 4.56\n",
      "Epoch  21/100 Batch 1540/1562 - Loss:  1.000, Seconds: 4.35\n",
      "('Average loss for this update:', 0.919)\n",
      "No Improvement.\n",
      "Epoch  21/100 Batch 1560/1562 - Loss:  0.880, Seconds: 3.87\n",
      "Epoch  22/100 Batch   20/1562 - Loss:  1.214, Seconds: 3.15\n",
      "Epoch  22/100 Batch   40/1562 - Loss:  0.925, Seconds: 3.46\n",
      "Epoch  22/100 Batch   60/1562 - Loss:  0.967, Seconds: 3.63\n",
      "Epoch  22/100 Batch   80/1562 - Loss:  1.007, Seconds: 2.88\n",
      "Epoch  22/100 Batch  100/1562 - Loss:  0.908, Seconds: 3.04\n",
      "Epoch  22/100 Batch  120/1562 - Loss:  0.944, Seconds: 3.25\n",
      "Epoch  22/100 Batch  140/1562 - Loss:  0.911, Seconds: 3.09\n",
      "Epoch  22/100 Batch  160/1562 - Loss:  0.940, Seconds: 3.43\n",
      "Epoch  22/100 Batch  180/1562 - Loss:  0.935, Seconds: 3.59\n",
      "Epoch  22/100 Batch  200/1562 - Loss:  0.846, Seconds: 3.51\n",
      "Epoch  22/100 Batch  220/1562 - Loss:  0.751, Seconds: 3.35\n",
      "Epoch  22/100 Batch  240/1562 - Loss:  0.887, Seconds: 3.38\n",
      "Epoch  22/100 Batch  260/1562 - Loss:  0.884, Seconds: 3.17\n",
      "Epoch  22/100 Batch  280/1562 - Loss:  0.870, Seconds: 3.31\n",
      "Epoch  22/100 Batch  300/1562 - Loss:  0.840, Seconds: 3.13\n",
      "Epoch  22/100 Batch  320/1562 - Loss:  0.951, Seconds: 3.29\n",
      "Epoch  22/100 Batch  340/1562 - Loss:  0.990, Seconds: 2.85\n",
      "Epoch  22/100 Batch  360/1562 - Loss:  0.970, Seconds: 3.55\n",
      "Epoch  22/100 Batch  380/1562 - Loss:  0.892, Seconds: 3.27\n",
      "Epoch  22/100 Batch  400/1562 - Loss:  0.904, Seconds: 3.31\n",
      "Epoch  22/100 Batch  420/1562 - Loss:  0.909, Seconds: 3.18\n",
      "Epoch  22/100 Batch  440/1562 - Loss:  0.871, Seconds: 3.60\n",
      "Epoch  22/100 Batch  460/1562 - Loss:  0.931, Seconds: 3.72\n",
      "Epoch  22/100 Batch  480/1562 - Loss:  0.828, Seconds: 2.84\n",
      "Epoch  22/100 Batch  500/1562 - Loss:  0.698, Seconds: 3.90\n",
      "('Average loss for this update:', 0.909)\n",
      "No Improvement.\n",
      "Epoch  22/100 Batch  520/1562 - Loss:  0.864, Seconds: 3.75\n",
      "Epoch  22/100 Batch  540/1562 - Loss:  0.834, Seconds: 3.31\n",
      "Epoch  22/100 Batch  560/1562 - Loss:  0.887, Seconds: 3.66\n",
      "Epoch  22/100 Batch  580/1562 - Loss:  0.829, Seconds: 3.66\n",
      "Epoch  22/100 Batch  600/1562 - Loss:  0.893, Seconds: 3.02\n",
      "Epoch  22/100 Batch  620/1562 - Loss:  1.030, Seconds: 3.33\n",
      "Epoch  22/100 Batch  640/1562 - Loss:  0.986, Seconds: 3.57\n",
      "Epoch  22/100 Batch  660/1562 - Loss:  0.985, Seconds: 3.74\n",
      "Epoch  22/100 Batch  680/1562 - Loss:  0.935, Seconds: 3.75\n",
      "Epoch  22/100 Batch  700/1562 - Loss:  0.828, Seconds: 3.97\n",
      "Epoch  22/100 Batch  720/1562 - Loss:  0.909, Seconds: 3.45\n",
      "Epoch  22/100 Batch  740/1562 - Loss:  0.917, Seconds: 3.69\n",
      "Epoch  22/100 Batch  760/1562 - Loss:  0.862, Seconds: 3.98\n",
      "Epoch  22/100 Batch  780/1562 - Loss:  0.722, Seconds: 3.43\n",
      "Epoch  22/100 Batch  800/1562 - Loss:  0.858, Seconds: 3.36\n",
      "Epoch  22/100 Batch  820/1562 - Loss:  0.880, Seconds: 3.57\n",
      "Epoch  22/100 Batch  840/1562 - Loss:  0.817, Seconds: 3.07\n",
      "Epoch  22/100 Batch  860/1562 - Loss:  0.826, Seconds: 3.42\n",
      "Epoch  22/100 Batch  880/1562 - Loss:  0.867, Seconds: 3.56\n",
      "Epoch  22/100 Batch  900/1562 - Loss:  0.938, Seconds: 3.68\n",
      "Epoch  22/100 Batch  920/1562 - Loss:  0.907, Seconds: 3.53\n",
      "Epoch  22/100 Batch  940/1562 - Loss:  0.980, Seconds: 3.06\n",
      "Epoch  22/100 Batch  960/1562 - Loss:  0.857, Seconds: 3.54\n",
      "Epoch  22/100 Batch  980/1562 - Loss:  0.830, Seconds: 3.76\n",
      "Epoch  22/100 Batch 1000/1562 - Loss:  0.923, Seconds: 3.65\n",
      "Epoch  22/100 Batch 1020/1562 - Loss:  0.920, Seconds: 3.52\n",
      "('Average loss for this update:', 0.886)\n",
      "New Record!\n",
      "Epoch  22/100 Batch 1040/1562 - Loss:  0.819, Seconds: 3.65\n",
      "Epoch  22/100 Batch 1060/1562 - Loss:  0.754, Seconds: 3.41\n",
      "Epoch  22/100 Batch 1080/1562 - Loss:  0.804, Seconds: 3.82\n",
      "Epoch  22/100 Batch 1100/1562 - Loss:  0.866, Seconds: 3.59\n",
      "Epoch  22/100 Batch 1120/1562 - Loss:  0.877, Seconds: 3.46\n",
      "Epoch  22/100 Batch 1140/1562 - Loss:  0.748, Seconds: 3.68\n",
      "Epoch  22/100 Batch 1160/1562 - Loss:  0.875, Seconds: 3.67\n",
      "Epoch  22/100 Batch 1180/1562 - Loss:  0.932, Seconds: 3.36\n",
      "Epoch  22/100 Batch 1200/1562 - Loss:  0.964, Seconds: 3.81\n",
      "Epoch  22/100 Batch 1220/1562 - Loss:  0.917, Seconds: 3.89\n",
      "Epoch  22/100 Batch 1240/1562 - Loss:  0.882, Seconds: 3.53\n",
      "Epoch  22/100 Batch 1260/1562 - Loss:  0.876, Seconds: 3.34\n",
      "Epoch  22/100 Batch 1280/1562 - Loss:  0.929, Seconds: 3.93\n",
      "Epoch  22/100 Batch 1300/1562 - Loss:  0.837, Seconds: 4.18\n",
      "Epoch  22/100 Batch 1320/1562 - Loss:  0.784, Seconds: 3.42\n",
      "Epoch  22/100 Batch 1340/1562 - Loss:  0.819, Seconds: 4.30\n",
      "Epoch  22/100 Batch 1360/1562 - Loss:  0.874, Seconds: 3.44\n",
      "Epoch  22/100 Batch 1380/1562 - Loss:  0.827, Seconds: 3.88\n",
      "Epoch  22/100 Batch 1400/1562 - Loss:  0.867, Seconds: 3.88\n",
      "Epoch  22/100 Batch 1420/1562 - Loss:  0.972, Seconds: 4.23\n",
      "Epoch  22/100 Batch 1440/1562 - Loss:  1.061, Seconds: 3.90\n",
      "Epoch  22/100 Batch 1460/1562 - Loss:  1.077, Seconds: 3.88\n",
      "Epoch  22/100 Batch 1480/1562 - Loss:  1.019, Seconds: 3.86\n",
      "Epoch  22/100 Batch 1500/1562 - Loss:  0.989, Seconds: 4.36\n",
      "Epoch  22/100 Batch 1520/1562 - Loss:  0.929, Seconds: 4.05\n",
      "Epoch  22/100 Batch 1540/1562 - Loss:  0.973, Seconds: 4.02\n",
      "('Average loss for this update:', 0.898)\n",
      "No Improvement.\n",
      "Epoch  22/100 Batch 1560/1562 - Loss:  0.874, Seconds: 3.39\n",
      "Epoch  23/100 Batch   20/1562 - Loss:  1.181, Seconds: 3.19\n",
      "Epoch  23/100 Batch   40/1562 - Loss:  0.919, Seconds: 3.24\n",
      "Epoch  23/100 Batch   60/1562 - Loss:  0.960, Seconds: 3.60\n",
      "Epoch  23/100 Batch   80/1562 - Loss:  1.008, Seconds: 3.01\n",
      "Epoch  23/100 Batch  100/1562 - Loss:  0.924, Seconds: 2.97\n",
      "Epoch  23/100 Batch  120/1562 - Loss:  0.944, Seconds: 3.11\n",
      "Epoch  23/100 Batch  140/1562 - Loss:  0.892, Seconds: 2.95\n",
      "Epoch  23/100 Batch  160/1562 - Loss:  0.939, Seconds: 3.90\n",
      "Epoch  23/100 Batch  180/1562 - Loss:  0.918, Seconds: 3.54\n",
      "Epoch  23/100 Batch  200/1562 - Loss:  0.822, Seconds: 3.58\n",
      "Epoch  23/100 Batch  220/1562 - Loss:  0.753, Seconds: 3.57\n",
      "Epoch  23/100 Batch  240/1562 - Loss:  0.892, Seconds: 3.59\n",
      "Epoch  23/100 Batch  260/1562 - Loss:  0.872, Seconds: 3.39\n",
      "Epoch  23/100 Batch  280/1562 - Loss:  0.862, Seconds: 3.40\n",
      "Epoch  23/100 Batch  300/1562 - Loss:  0.853, Seconds: 3.31\n",
      "Epoch  23/100 Batch  320/1562 - Loss:  0.925, Seconds: 3.25\n",
      "Epoch  23/100 Batch  340/1562 - Loss:  0.988, Seconds: 3.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  23/100 Batch  360/1562 - Loss:  0.961, Seconds: 3.91\n",
      "Epoch  23/100 Batch  380/1562 - Loss:  0.888, Seconds: 3.17\n",
      "Epoch  23/100 Batch  400/1562 - Loss:  0.893, Seconds: 3.33\n",
      "Epoch  23/100 Batch  420/1562 - Loss:  0.853, Seconds: 3.60\n",
      "Epoch  23/100 Batch  440/1562 - Loss:  0.870, Seconds: 3.59\n",
      "Epoch  23/100 Batch  460/1562 - Loss:  0.924, Seconds: 3.38\n",
      "Epoch  23/100 Batch  480/1562 - Loss:  0.828, Seconds: 3.29\n",
      "Epoch  23/100 Batch  500/1562 - Loss:  0.670, Seconds: 3.29\n",
      "('Average loss for this update:', 0.899)\n",
      "No Improvement.\n",
      "Epoch  23/100 Batch  520/1562 - Loss:  0.840, Seconds: 3.39\n",
      "Epoch  23/100 Batch  540/1562 - Loss:  0.833, Seconds: 3.54\n",
      "Epoch  23/100 Batch  560/1562 - Loss:  0.873, Seconds: 3.74\n",
      "Epoch  23/100 Batch  580/1562 - Loss:  0.818, Seconds: 3.72\n",
      "Epoch  23/100 Batch  600/1562 - Loss:  0.901, Seconds: 3.45\n",
      "Epoch  23/100 Batch  620/1562 - Loss:  1.008, Seconds: 3.57\n",
      "Epoch  23/100 Batch  640/1562 - Loss:  0.986, Seconds: 3.30\n",
      "Epoch  23/100 Batch  660/1562 - Loss:  0.986, Seconds: 3.45\n",
      "Epoch  23/100 Batch  680/1562 - Loss:  0.957, Seconds: 3.59\n",
      "Epoch  23/100 Batch  700/1562 - Loss:  0.822, Seconds: 3.82\n",
      "Epoch  23/100 Batch  720/1562 - Loss:  0.900, Seconds: 3.31\n",
      "Epoch  23/100 Batch  740/1562 - Loss:  0.898, Seconds: 4.01\n",
      "Epoch  23/100 Batch  760/1562 - Loss:  0.848, Seconds: 3.76\n",
      "Epoch  23/100 Batch  780/1562 - Loss:  0.711, Seconds: 3.44\n",
      "Epoch  23/100 Batch  800/1562 - Loss:  0.852, Seconds: 3.47\n",
      "Epoch  23/100 Batch  820/1562 - Loss:  0.870, Seconds: 3.45\n",
      "Epoch  23/100 Batch  840/1562 - Loss:  0.814, Seconds: 3.43\n",
      "Epoch  23/100 Batch  860/1562 - Loss:  0.832, Seconds: 3.22\n",
      "Epoch  23/100 Batch  880/1562 - Loss:  0.832, Seconds: 3.70\n",
      "Epoch  23/100 Batch  900/1562 - Loss:  0.903, Seconds: 3.77\n",
      "Epoch  23/100 Batch  920/1562 - Loss:  0.900, Seconds: 3.64\n",
      "Epoch  23/100 Batch  940/1562 - Loss:  0.980, Seconds: 3.43\n",
      "Epoch  23/100 Batch  960/1562 - Loss:  0.838, Seconds: 3.40\n",
      "Epoch  23/100 Batch  980/1562 - Loss:  0.817, Seconds: 3.31\n",
      "Epoch  23/100 Batch 1000/1562 - Loss:  0.905, Seconds: 3.58\n",
      "Epoch  23/100 Batch 1020/1562 - Loss:  0.916, Seconds: 3.35\n",
      "('Average loss for this update:', 0.877)\n",
      "New Record!\n",
      "Epoch  23/100 Batch 1040/1562 - Loss:  0.794, Seconds: 4.01\n",
      "Epoch  23/100 Batch 1060/1562 - Loss:  0.751, Seconds: 3.34\n",
      "Epoch  23/100 Batch 1080/1562 - Loss:  0.814, Seconds: 3.55\n",
      "Epoch  23/100 Batch 1100/1562 - Loss:  0.862, Seconds: 3.72\n",
      "Epoch  23/100 Batch 1120/1562 - Loss:  0.865, Seconds: 3.46\n",
      "Epoch  23/100 Batch 1140/1562 - Loss:  0.746, Seconds: 3.64\n",
      "Epoch  23/100 Batch 1160/1562 - Loss:  0.881, Seconds: 3.58\n",
      "Epoch  23/100 Batch 1180/1562 - Loss:  0.940, Seconds: 3.47\n",
      "Epoch  23/100 Batch 1200/1562 - Loss:  0.939, Seconds: 3.99\n",
      "Epoch  23/100 Batch 1220/1562 - Loss:  0.907, Seconds: 3.46\n",
      "Epoch  23/100 Batch 1240/1562 - Loss:  0.867, Seconds: 3.40\n",
      "Epoch  23/100 Batch 1260/1562 - Loss:  0.858, Seconds: 3.51\n",
      "Epoch  23/100 Batch 1280/1562 - Loss:  0.950, Seconds: 3.76\n",
      "Epoch  23/100 Batch 1300/1562 - Loss:  0.831, Seconds: 3.72\n",
      "Epoch  23/100 Batch 1320/1562 - Loss:  0.761, Seconds: 3.30\n",
      "Epoch  23/100 Batch 1340/1562 - Loss:  0.797, Seconds: 3.88\n",
      "Epoch  23/100 Batch 1360/1562 - Loss:  0.835, Seconds: 3.46\n",
      "Epoch  23/100 Batch 1380/1562 - Loss:  0.799, Seconds: 3.64\n",
      "Epoch  23/100 Batch 1400/1562 - Loss:  0.839, Seconds: 3.66\n",
      "Epoch  23/100 Batch 1420/1562 - Loss:  0.968, Seconds: 3.92\n",
      "Epoch  23/100 Batch 1440/1562 - Loss:  1.026, Seconds: 4.12\n",
      "Epoch  23/100 Batch 1460/1562 - Loss:  1.044, Seconds: 3.34\n",
      "Epoch  23/100 Batch 1480/1562 - Loss:  1.006, Seconds: 3.57\n",
      "Epoch  23/100 Batch 1500/1562 - Loss:  0.949, Seconds: 3.97\n",
      "Epoch  23/100 Batch 1520/1562 - Loss:  0.932, Seconds: 3.98\n",
      "Epoch  23/100 Batch 1540/1562 - Loss:  0.962, Seconds: 3.79\n",
      "('Average loss for this update:', 0.884)\n",
      "No Improvement.\n",
      "Epoch  23/100 Batch 1560/1562 - Loss:  0.850, Seconds: 3.81\n",
      "Epoch  24/100 Batch   20/1562 - Loss:  1.143, Seconds: 3.14\n",
      "Epoch  24/100 Batch   40/1562 - Loss:  0.911, Seconds: 3.37\n",
      "Epoch  24/100 Batch   60/1562 - Loss:  0.935, Seconds: 3.81\n",
      "Epoch  24/100 Batch   80/1562 - Loss:  0.978, Seconds: 3.22\n",
      "Epoch  24/100 Batch  100/1562 - Loss:  0.873, Seconds: 3.27\n",
      "Epoch  24/100 Batch  120/1562 - Loss:  0.921, Seconds: 3.38\n",
      "Epoch  24/100 Batch  140/1562 - Loss:  0.852, Seconds: 2.87\n",
      "Epoch  24/100 Batch  160/1562 - Loss:  0.909, Seconds: 3.24\n",
      "Epoch  24/100 Batch  180/1562 - Loss:  0.886, Seconds: 3.34\n",
      "Epoch  24/100 Batch  200/1562 - Loss:  0.807, Seconds: 3.33\n",
      "Epoch  24/100 Batch  220/1562 - Loss:  0.716, Seconds: 3.08\n",
      "Epoch  24/100 Batch  240/1562 - Loss:  0.852, Seconds: 3.51\n",
      "Epoch  24/100 Batch  260/1562 - Loss:  0.834, Seconds: 3.54\n",
      "Epoch  24/100 Batch  280/1562 - Loss:  0.826, Seconds: 3.48\n",
      "Epoch  24/100 Batch  300/1562 - Loss:  0.828, Seconds: 3.67\n",
      "Epoch  24/100 Batch  320/1562 - Loss:  0.887, Seconds: 3.44\n",
      "Epoch  24/100 Batch  340/1562 - Loss:  0.927, Seconds: 2.73\n",
      "Epoch  24/100 Batch  360/1562 - Loss:  0.929, Seconds: 3.74\n",
      "Epoch  24/100 Batch  380/1562 - Loss:  0.843, Seconds: 3.50\n",
      "Epoch  24/100 Batch  400/1562 - Loss:  0.867, Seconds: 3.66\n",
      "Epoch  24/100 Batch  420/1562 - Loss:  0.857, Seconds: 3.62\n",
      "Epoch  24/100 Batch  440/1562 - Loss:  0.848, Seconds: 3.15\n",
      "Epoch  24/100 Batch  460/1562 - Loss:  0.914, Seconds: 3.54\n",
      "Epoch  24/100 Batch  480/1562 - Loss:  0.802, Seconds: 3.54\n",
      "Epoch  24/100 Batch  500/1562 - Loss:  0.665, Seconds: 3.30\n",
      "('Average loss for this update:', 0.871)\n",
      "New Record!\n",
      "Epoch  24/100 Batch  520/1562 - Loss:  0.842, Seconds: 3.68\n",
      "Epoch  24/100 Batch  540/1562 - Loss:  0.821, Seconds: 3.49\n",
      "Epoch  24/100 Batch  560/1562 - Loss:  0.862, Seconds: 3.90\n",
      "Epoch  24/100 Batch  580/1562 - Loss:  0.796, Seconds: 3.57\n",
      "Epoch  24/100 Batch  600/1562 - Loss:  0.871, Seconds: 3.43\n",
      "Epoch  24/100 Batch  620/1562 - Loss:  0.959, Seconds: 3.38\n",
      "Epoch  24/100 Batch  640/1562 - Loss:  0.952, Seconds: 3.44\n",
      "Epoch  24/100 Batch  660/1562 - Loss:  0.945, Seconds: 3.38\n",
      "Epoch  24/100 Batch  680/1562 - Loss:  0.900, Seconds: 3.59\n",
      "Epoch  24/100 Batch  700/1562 - Loss:  0.802, Seconds: 3.69\n",
      "Epoch  24/100 Batch  720/1562 - Loss:  0.876, Seconds: 3.42\n",
      "Epoch  24/100 Batch  740/1562 - Loss:  0.870, Seconds: 3.33\n",
      "Epoch  24/100 Batch  760/1562 - Loss:  0.832, Seconds: 3.70\n",
      "Epoch  24/100 Batch  780/1562 - Loss:  0.689, Seconds: 3.23\n",
      "Epoch  24/100 Batch  800/1562 - Loss:  0.823, Seconds: 3.55\n",
      "Epoch  24/100 Batch  820/1562 - Loss:  0.834, Seconds: 3.58\n",
      "Epoch  24/100 Batch  840/1562 - Loss:  0.794, Seconds: 3.74\n",
      "Epoch  24/100 Batch  860/1562 - Loss:  0.801, Seconds: 3.54\n",
      "Epoch  24/100 Batch  880/1562 - Loss:  0.823, Seconds: 3.64\n",
      "Epoch  24/100 Batch  900/1562 - Loss:  0.872, Seconds: 3.60\n",
      "Epoch  24/100 Batch  920/1562 - Loss:  0.872, Seconds: 3.59\n",
      "Epoch  24/100 Batch  940/1562 - Loss:  0.931, Seconds: 2.93\n",
      "Epoch  24/100 Batch  960/1562 - Loss:  0.819, Seconds: 3.61\n",
      "Epoch  24/100 Batch  980/1562 - Loss:  0.809, Seconds: 4.02\n",
      "Epoch  24/100 Batch 1000/1562 - Loss:  0.896, Seconds: 3.80\n",
      "Epoch  24/100 Batch 1020/1562 - Loss:  0.914, Seconds: 3.58\n",
      "('Average loss for this update:', 0.852)\n",
      "New Record!\n",
      "Epoch  24/100 Batch 1040/1562 - Loss:  0.779, Seconds: 3.81\n",
      "Epoch  24/100 Batch 1060/1562 - Loss:  0.733, Seconds: 3.74\n",
      "Epoch  24/100 Batch 1080/1562 - Loss:  0.795, Seconds: 3.35\n",
      "Epoch  24/100 Batch 1100/1562 - Loss:  0.856, Seconds: 3.64\n",
      "Epoch  24/100 Batch 1120/1562 - Loss:  0.846, Seconds: 3.29\n",
      "Epoch  24/100 Batch 1140/1562 - Loss:  0.708, Seconds: 3.75\n",
      "Epoch  24/100 Batch 1160/1562 - Loss:  0.846, Seconds: 3.75\n",
      "Epoch  24/100 Batch 1180/1562 - Loss:  0.904, Seconds: 4.01\n",
      "Epoch  24/100 Batch 1200/1562 - Loss:  0.926, Seconds: 3.42\n",
      "Epoch  24/100 Batch 1220/1562 - Loss:  0.855, Seconds: 3.50\n",
      "Epoch  24/100 Batch 1240/1562 - Loss:  0.832, Seconds: 3.65\n",
      "Epoch  24/100 Batch 1260/1562 - Loss:  0.848, Seconds: 3.37\n",
      "Epoch  24/100 Batch 1280/1562 - Loss:  0.936, Seconds: 3.81\n",
      "Epoch  24/100 Batch 1300/1562 - Loss:  0.803, Seconds: 3.94\n",
      "Epoch  24/100 Batch 1320/1562 - Loss:  0.762, Seconds: 3.38\n",
      "Epoch  24/100 Batch 1340/1562 - Loss:  0.779, Seconds: 3.89\n",
      "Epoch  24/100 Batch 1360/1562 - Loss:  0.858, Seconds: 3.39\n",
      "Epoch  24/100 Batch 1380/1562 - Loss:  0.770, Seconds: 3.53\n",
      "Epoch  24/100 Batch 1400/1562 - Loss:  0.841, Seconds: 3.86\n",
      "Epoch  24/100 Batch 1420/1562 - Loss:  0.944, Seconds: 3.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  24/100 Batch 1440/1562 - Loss:  1.027, Seconds: 3.74\n",
      "Epoch  24/100 Batch 1460/1562 - Loss:  1.032, Seconds: 3.41\n",
      "Epoch  24/100 Batch 1480/1562 - Loss:  0.959, Seconds: 3.32\n",
      "Epoch  24/100 Batch 1500/1562 - Loss:  0.952, Seconds: 4.07\n",
      "Epoch  24/100 Batch 1520/1562 - Loss:  0.906, Seconds: 4.16\n",
      "Epoch  24/100 Batch 1540/1562 - Loss:  0.951, Seconds: 4.02\n",
      "('Average loss for this update:', 0.866)\n",
      "No Improvement.\n",
      "Epoch  24/100 Batch 1560/1562 - Loss:  0.825, Seconds: 3.87\n",
      "Epoch  25/100 Batch   20/1562 - Loss:  1.137, Seconds: 3.22\n",
      "Epoch  25/100 Batch   40/1562 - Loss:  0.906, Seconds: 3.50\n",
      "Epoch  25/100 Batch   60/1562 - Loss:  0.909, Seconds: 3.51\n",
      "Epoch  25/100 Batch   80/1562 - Loss:  0.941, Seconds: 3.24\n",
      "Epoch  25/100 Batch  100/1562 - Loss:  0.870, Seconds: 3.46\n",
      "Epoch  25/100 Batch  120/1562 - Loss:  0.896, Seconds: 3.64\n",
      "Epoch  25/100 Batch  140/1562 - Loss:  0.843, Seconds: 3.30\n",
      "Epoch  25/100 Batch  160/1562 - Loss:  0.868, Seconds: 3.42\n",
      "Epoch  25/100 Batch  180/1562 - Loss:  0.862, Seconds: 3.57\n",
      "Epoch  25/100 Batch  200/1562 - Loss:  0.915, Seconds: 3.35\n",
      "Epoch  25/100 Batch  220/1562 - Loss:  0.826, Seconds: 3.26\n",
      "Epoch  25/100 Batch  240/1562 - Loss:  0.978, Seconds: 3.38\n",
      "Epoch  25/100 Batch  260/1562 - Loss:  1.141, Seconds: 3.38\n",
      "Epoch  25/100 Batch  280/1562 - Loss:  1.122, Seconds: 3.54\n",
      "Epoch  25/100 Batch  300/1562 - Loss:  1.024, Seconds: 3.37\n",
      "Epoch  25/100 Batch  320/1562 - Loss:  1.069, Seconds: 3.74\n",
      "Epoch  25/100 Batch  340/1562 - Loss:  1.167, Seconds: 3.54\n",
      "Epoch  25/100 Batch  360/1562 - Loss:  1.136, Seconds: 3.72\n",
      "Epoch  25/100 Batch  380/1562 - Loss:  1.015, Seconds: 3.52\n",
      "Epoch  25/100 Batch  400/1562 - Loss:  1.035, Seconds: 3.58\n",
      "Epoch  25/100 Batch  420/1562 - Loss:  0.961, Seconds: 3.90\n",
      "Epoch  25/100 Batch  440/1562 - Loss:  0.945, Seconds: 3.68\n",
      "Epoch  25/100 Batch  460/1562 - Loss:  1.018, Seconds: 3.08\n",
      "Epoch  25/100 Batch  480/1562 - Loss:  0.876, Seconds: 3.11\n",
      "Epoch  25/100 Batch  500/1562 - Loss:  0.726, Seconds: 3.34\n",
      "('Average loss for this update:', 0.965)\n",
      "No Improvement.\n",
      "Epoch  25/100 Batch  520/1562 - Loss:  0.908, Seconds: 3.95\n",
      "Epoch  25/100 Batch  540/1562 - Loss:  0.876, Seconds: 3.37\n",
      "Epoch  25/100 Batch  560/1562 - Loss:  0.924, Seconds: 3.91\n",
      "Epoch  25/100 Batch  580/1562 - Loss:  0.837, Seconds: 3.61\n",
      "Epoch  25/100 Batch  600/1562 - Loss:  0.922, Seconds: 3.44\n",
      "Epoch  25/100 Batch  620/1562 - Loss:  1.014, Seconds: 3.20\n",
      "Epoch  25/100 Batch  640/1562 - Loss:  1.000, Seconds: 3.43\n",
      "Epoch  25/100 Batch  660/1562 - Loss:  0.993, Seconds: 3.60\n",
      "Epoch  25/100 Batch  680/1562 - Loss:  0.951, Seconds: 3.80\n",
      "Epoch  25/100 Batch  700/1562 - Loss:  0.837, Seconds: 3.82\n",
      "Epoch  25/100 Batch  720/1562 - Loss:  0.936, Seconds: 3.36\n",
      "Epoch  25/100 Batch  740/1562 - Loss:  0.925, Seconds: 3.53\n",
      "Epoch  25/100 Batch  760/1562 - Loss:  0.859, Seconds: 3.64\n",
      "Epoch  25/100 Batch  780/1562 - Loss:  0.706, Seconds: 3.65\n",
      "Epoch  25/100 Batch  800/1562 - Loss:  0.850, Seconds: 3.45\n",
      "Epoch  25/100 Batch  820/1562 - Loss:  0.850, Seconds: 3.68\n",
      "Epoch  25/100 Batch  840/1562 - Loss:  0.789, Seconds: 3.50\n",
      "Epoch  25/100 Batch  860/1562 - Loss:  0.816, Seconds: 3.56\n",
      "Epoch  25/100 Batch  880/1562 - Loss:  0.846, Seconds: 3.57\n",
      "Epoch  25/100 Batch  900/1562 - Loss:  0.897, Seconds: 3.78\n",
      "Epoch  25/100 Batch  920/1562 - Loss:  0.882, Seconds: 3.71\n",
      "Epoch  25/100 Batch  940/1562 - Loss:  0.950, Seconds: 3.56\n",
      "Epoch  25/100 Batch  960/1562 - Loss:  0.830, Seconds: 3.56\n",
      "Epoch  25/100 Batch  980/1562 - Loss:  0.801, Seconds: 3.57\n",
      "Epoch  25/100 Batch 1000/1562 - Loss:  0.881, Seconds: 3.64\n",
      "Epoch  25/100 Batch 1020/1562 - Loss:  0.906, Seconds: 3.63\n",
      "('Average loss for this update:', 0.879)\n",
      "No Improvement.\n",
      "Stopping Training.\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "learning_rate_decay = 0.95\n",
    "min_learning_rate = 0.0005\n",
    "display_step = 20 # Check training loss after every 20 batches\n",
    "stop_early = 0 \n",
    "stop = 3 # If the update loss does not decrease in 3 consecutive update checks, stop training\n",
    "per_epoch = 3 # Make 3 update checks per epoch\n",
    "update_check = (len(sorted_texts_short)//batch_size//per_epoch)-1\n",
    "\n",
    "update_loss = 0 \n",
    "batch_loss = 0\n",
    "summary_update_loss = [] # Record the update losses for saving improvements in the model\n",
    "\n",
    "checkpoint = \"./best_model.ckpt\" \n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "config = tf.ConfigProto(device_count = {'GPU': 1})\n",
    " \n",
    "\n",
    "with tf.Session(graph=train_graph, config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # If we want to continue training a previous session\n",
    "    #loader = tf.train.import_meta_graph(\"./\" + checkpoint + '.meta')\n",
    "    #loader.restore(sess, checkpoint)\n",
    "    \n",
    "    for epoch_i in range(1, epochs+1):\n",
    "        update_loss = 0\n",
    "        batch_loss = 0\n",
    "        for batch_i, (summaries_batch, texts_batch, summaries_lengths, texts_lengths) in enumerate(\n",
    "                get_batches(sorted_summaries_short, sorted_texts_short, batch_size)):\n",
    "            start_time = time.time()\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: texts_batch,\n",
    "                 targets: summaries_batch,\n",
    "                 lr: learning_rate,\n",
    "                 summary_length: summaries_lengths,\n",
    "                 text_length: texts_lengths,\n",
    "                 keep_prob: keep_probability})\n",
    "\n",
    "            batch_loss += loss\n",
    "            update_loss += loss\n",
    "            end_time = time.time()\n",
    "            batch_time = end_time - start_time\n",
    "\n",
    "            if batch_i % display_step == 0 and batch_i > 0:\n",
    "                print('Epoch {:>3}/{} Batch {:>4}/{} - Loss: {:>6.3f}, Seconds: {:>4.2f}'\n",
    "                      .format(epoch_i,\n",
    "                              epochs, \n",
    "                              batch_i, \n",
    "                              len(sorted_texts_short) // batch_size, \n",
    "                              batch_loss / display_step, \n",
    "                              batch_time*display_step))\n",
    "                batch_loss = 0\n",
    "\n",
    "            if batch_i % update_check == 0 and batch_i > 0:\n",
    "                print(\"Average loss for this update:\", round(update_loss/update_check,3))\n",
    "                summary_update_loss.append(update_loss)\n",
    "                \n",
    "                # If the update loss is at a new minimum, save the model\n",
    "                if update_loss <= min(summary_update_loss):\n",
    "                    print('New Record!') \n",
    "                    stop_early = 0\n",
    "                    saver = tf.train.Saver() \n",
    "                    saver.save(sess, checkpoint)\n",
    "\n",
    "                else:\n",
    "                    print(\"No Improvement.\")\n",
    "                    stop_early += 1\n",
    "                    if stop_early == stop:\n",
    "                        break\n",
    "                update_loss = 0\n",
    "            \n",
    "                    \n",
    "        # Reduce learning rate, but not below its minimum value\n",
    "        learning_rate *= learning_rate_decay\n",
    "        if learning_rate < min_learning_rate:\n",
    "            learning_rate = min_learning_rate\n",
    "        \n",
    "        if stop_early == stop:\n",
    "            print(\"Stopping Training.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Making Our Own Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the quality of the summaries that this model can generate, you can either create your own review, or use a review from the dataset. You can set the length of the summary to a fixed value, or use a random value like I have here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_seq(text):\n",
    "    '''Prepare the text for the model'''\n",
    "    \n",
    "    text = clean_text(text)\n",
    "    return [vocab_to_int.get(word, vocab_to_int['<UNK>']) for word in text.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **input_sentences**: a list of reviews strings we are going to summarize\n",
    "- **generagte_summary_length**: a int or list, if a list must be same length as input_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [text_to_seq(input_sentence) for input_sentence in hotel_docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5423\n",
      "INFO:tensorflow:Restoring parameters from ./best_model.ckpt\n",
      "- Review:\n",
      " With a stay at Petpimarn Boutique Resort in Bangkok Chatuchak you will be within a 15 minute drive of Kasetsart University and IMPACT Arena This hotel is 9.7 miles 15.6 kilometers from Temple of the Emerald Buddha and 10 miles 16.2 kilometers from Wat Arun Make yourself at home in one of the 89 air conditioned rooms featuring refrigerators Complimentary wireless Internet access keeps you connected and digital programming is available for your entertainment Bathrooms have showers and complimentary toiletries Conveniences include desks and complimentary bottled water and housekeeping is provided daily Make use of convenient amenities which include complimentary wireless Internet access and tour ticket assistance At Petpimarn Boutique Resort enjoy a satisfying meal at the restaurant English breakfasts are available daily from 6 30 AM to 10 AM for a fee Featured amenities include dry cleaning laundry services a 24 hour front desk and luggage storage Free self parking is available onsite\n",
      "- Summary:\n",
      " easy and my days 5\n",
      "\n",
      "\n",
      "- Review:\n",
      " Airport Suite Bangkok Don Muang Airport is located in area city Don Mueang Airport The hotel has a very good location also near the Don Mueang International Airport DMK which is only 2.85 kilometers away There are plenty of tourist attractions nearby such as IT Square within 1.18 kilometers and Central Ramintra within 2.67 kilometers Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at Airport Suite Bangkok Don Muang Airport The hotel s fitness center is a must try during your stay here Have an enjoyable and relaxing day at the pool whether you re traveling solo or with your loved ones Get the best deal for finest quality of spa treatment to unwind and rejuvenate yourself 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from Airport Suite Bangkok Don Muang Airport exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends With all facilities offered Airport Suite Bangkok Don Muang Airport is the right place to stay\n",
      "- Summary:\n",
      " i favorite gf mix\n",
      "\n",
      "\n",
      "- Review:\n",
      " With a stay at The Riche Residence in Bangkok Don Muang you will be 12 minutes by car from Kasetsart University This hotel is 11.2 miles 18 kilometers from Temple of the Emerald Buddha and 11.6 miles 18.6 kilometers from Wat Arun Make yourself at home in one of the 68 air conditioned rooms featuring refrigerators and flat screen televisions Rooms have private balconies Complimentary wireless Internet access keeps you connected and cable programming is available for your entertainment Private bathrooms with showers feature complimentary toiletries and hair dryers For lunch or dinner stop by The Riche Residence a restaurant that specializes in fusion cuisine Dining is also available at the coffee shop caf and 24 hour room service is provided Continental breakfasts are available daily from 6 AM to 10 AM for a fee Featured amenities include dry cleaning laundry services a 24 hour front desk and luggage storage Free self parking is available onsite\n",
      "- Summary:\n",
      " easy to use and easy to prepare up\n",
      "\n",
      "\n",
      "- Review:\n",
      " With a stay at Regent Home 1 at Donmuang in Bangkok Don Muang you will be 9.3 miles 15 kilometers from Chatuchak Weekend Market and 17.2 miles 27.7 kilometers from Temple of the Emerald Buddha This apartment is 17.6 miles 28.3 kilometers from Grand Palace and 17.7 miles 28.4 kilometers from Wat Pho Make yourself at home in one of the 2 air conditioned rooms featuring kitchens with refrigerators and ovens Rooms have private balconies 32 inch LCD televisions with digital programming provide entertainment while complimentary wireless Internet access keeps you connected Conveniences include separate sitting areas and electric kettles and housekeeping is provided once per stay Take advantage of recreation opportunities including an outdoor pool and a fitness center Featured amenities include dry cleaning laundry services luggage storage and an elevator lift Free self parking is available onsite\n",
      "- Summary:\n",
      " easy and delicious\n",
      "\n",
      "\n",
      "- Review:\n",
      " With a stay at Charoenpong Apartment in Bangkok Don Muang you will be 13 minutes by car from Sripatum University This guesthouse is 10.2 miles 16.4 kilometers from Chatuchak Weekend Market and 13.9 miles 22.4 kilometers from Suan Pakkard Palace Make yourself at home in one of the 5 air conditioned rooms featuring flat screen televisions Complimentary wireless Internet access keeps you connected and cable programming is available for your entertainment Bathrooms have showers and complimentary toiletries Conveniences include desks and blackout drapes curtains and housekeeping is provided daily Take in the views from a terrace and make use of amenities such as complimentary wireless Internet access Featured amenities include a 24 hour front desk and laundry facilities Free self parking is available onsite\n",
      "- Summary:\n",
      " easy to use and easy\n",
      "\n",
      "\n",
      "- Review:\n",
      " With a stay at Bright And Cozy Place near DMK Airport in Bangkok Don Muang you will be 15 minutes by car from IMPACT Arena This condo is 9.2 miles 14.8 kilometers from Chatuchak Weekend Market and 16.2 miles 26.1 kilometers from Wat Arun Make yourself at home in one of the 2 individually decorated guestrooms featuring refrigerators and microwaves 32 inch flat screen televisions with cable programming provide entertainment while complimentary wireless Internet access keeps you connected Private bathrooms with showers feature complimentary toiletries and hair dryers Conveniences include separate sitting areas and coffee tea makers Don t miss out on recreational opportunities including an outdoor pool and a fitness center Featured amenities include laundry facilities a safe deposit box at the front desk and an elevator lift\n",
      "- Summary:\n",
      " great for colds flu\n",
      "\n",
      "\n",
      "- Review:\n",
      " With a stay at DD Place in Bangkok Don Muang you will be within a 15 minute drive of IMPACT Arena and IMPACT Challenger This hotel is 13.4 miles 21.6 kilometers from Chatuchak Weekend Market and 16.2 miles 26.1 kilometers from Vimanmek Palace Make yourself at home in one of the 50 air conditioned rooms featuring refrigerators and flat screen televisions Complimentary wireless Internet access keeps you connected and cable programming is available for your entertainment Bathrooms have showers and complimentary toiletries Conveniences include desks and complimentary bottled water and housekeeping is provided daily Featured amenities include luggage storage and laundry facilities Free self parking is available onsite\n",
      "- Summary:\n",
      " good for you and affordable\n",
      "\n",
      "\n",
      "- Review:\n",
      " Miracle Grand Convention Hotel is located in area city Lak Si The hotel has a very good location also near the Don Mueang International Airport DMK which is only 5.21 kilometers away The hotel is located only 8.58 kilometers away from Mo Chit BTS Station There are plenty of tourist attractions nearby such as Chulabhorn Research Institute within 0.23 kilometers and Thung Song Hong Police Station within 1.06 kilometers Whether you are planning an event or other special occasions Miracle Grand Convention Hotel is a great choice for you with a large and well equipped function room to suit your requirements Miracle Grand Convention Hotel is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit The highest quality service accompanying its extensive facilities will make you get the ultimate holiday experience The hotel s fitness center is a must try during your stay here Have an enjoyable and relaxing day at the pool whether you re traveling solo or with your loved ones Get the best deal for finest quality of spa treatment to unwind and rejuvenate yourself 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from Miracle Grand Convention Hotel exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends Miracle Grand Convention Hotel is a hotel with great comfort and excellent service according to most hotel s guests Enjoy luxurious treats and incomparable experience by staying at Miracle Grand Convention Hotel\n",
      "- Summary:\n",
      " my favorite gf gf gf gf gf for the found\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Review:\n",
      " With a stay at Room for you in Bangkok Don Muang you will be 9 minutes by car from IMPACT Arena This hotel is 10 miles 16 kilometers from Chatuchak Weekend Market and 14.7 miles 23.6 kilometers from Temple of the Emerald Buddha Make yourself at home in one of the 18 air conditioned rooms featuring refrigerators and flat screen televisions Complimentary wireless Internet access keeps you connected and digital programming is available for your entertainment Bathrooms have showers and complimentary toiletries Conveniences include complimentary bottled water and housekeeping is provided daily Take in the views from a terrace and make use of amenities such as complimentary wireless Internet access Featured amenities include dry cleaning laundry services and luggage storage Free self parking is available onsite\n",
      "- Summary:\n",
      " meh my daughter s favorite gift\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at Jumbotel Hotel is a good choice when you are visiting Lak Si The hotel has a very good location also near the Don Mueang International Airport DMK which is only 5.34 kilometers away This hotel is very easy to find since it is strategically positioned close to public facilities Jumbotel Hotel is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget Jumbotel Hotel is the perfect place to stay that provides decent facilities as well as great services Jumbotel Hotel is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit If you plan to have a long term stay staying at Jumbotel Hotel is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Jumbotel Hotel is suitable for you who value privacy during your stay Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at Jumbotel Hotel The hotel s fitness center is a must try during your stay here 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from Jumbotel Hotel exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends With all facilities offered Jumbotel Hotel is the right place to stay\n",
      "- Summary:\n",
      " quick easy meal peanut butter mixer mixer\n",
      "\n",
      "\n",
      "- Review:\n",
      " Casa Residence Hotel is located in area city Lak Si The hotel has a very good location also near the Don Mueang International Airport DMK which is only 4.22 kilometers away The hotel is located only 9.95 kilometers away from Mo Chit BTS Station There are plenty of tourist attractions nearby such as IT Square within 0.79 kilometers and Central Ramintra within 3.4 kilometers For you travelers who wish to travel comfortably on a budget Casa Residence Hotel is the perfect place to stay that provides decent facilities as well as great services Casa Residence Hotel is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit From business event to corporate gathering Casa Residence Hotel provides complete services and facilities that you and your colleagues need Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at Casa Residence Hotel 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends Casa Residence Hotel is a hotel with great comfort and excellent service according to most hotel s guests With all facilities offered Casa Residence Hotel is the right place to stay\n",
      "- Summary:\n",
      " i have found this for my our favorite gf senseo\n",
      "\n",
      "\n",
      "- Review:\n",
      " The Journey Hotel is located in area city Lak Si The hotel has a very good location also near the Don Mueang International Airport DMK which is only 6.95 kilometers away The hotel is located only 7.61 kilometers away from Mo Chit BTS Station There are plenty of tourist attractions nearby such as Kasetsart University within 2.71 kilometers and IT Square within 2.98 kilometers For you travelers who wish to travel comfortably on a budget The Journey Hotel is the perfect place to stay that provides decent facilities as well as great services The Journey Hotel is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit From business event to corporate gathering The Journey Hotel provides complete services and facilities that you and your colleagues need Have fun with various entertaining facilities for you and the whole family at The Journey Hotel a wonderful accommodation for your family holiday If you plan to have a long term stay staying at The Journey Hotel is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at The Journey Hotel The hotel s fitness center is a must try during your stay here 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends The Journey Hotel is a hotel with great comfort and excellent service according to most hotel s guests With all facilities offered The Journey Hotel is the right place to stay\n",
      "- Summary:\n",
      " i saver\n",
      "\n",
      "\n",
      "- Review:\n",
      " NRV PLACE Donmuang Airport is a hotel in a good neighborhood which is located at Don Mueang Airport The hotel has a very good location also near the Don Mueang International Airport DMK which is only 2.68 kilometers away Not only well positioned but NRV PLACE Donmuang Airport is also one of hotels near the following Central Ramintra within 1.98 kilometers and IT Square within 2.01 kilometers NRV PLACE Donmuang Airport is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit Have fun with various entertaining facilities for you and the whole family at NRV PLACE Donmuang Airport a wonderful accommodation for your family holiday Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at NRV PLACE Donmuang Airport The hotel s fitness center is a must try during your stay here 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends With all facilities offered NRV PLACE Donmuang Airport is the right place to stay\n",
      "- Summary:\n",
      " a good buy\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at Royal Bee Apartment is a good choice when you are visiting Don Mueang Airport The apartment has a very good location also near the Don Mueang International Airport DMK which is only 2.78 kilometers away This apartment is very easy to find since it is strategically positioned close to public facilities Royal Bee Apartment is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget Royal Bee Apartment is the perfect place to stay that provides decent facilities as well as great services When staying at a apartment the design and architecture are two important factors that can spoil your eyes With its unique setting Royal Bee Apartment provides a pleasant accommodation for your stay Have fun with various entertaining facilities for you and the whole family at Royal Bee Apartment a wonderful accommodation for your family holiday While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Royal Bee Apartment is suitable for you who value privacy during your stay Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at Royal Bee Apartment The apartment s fitness center is a must try during your stay here 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends Royal Bee Apartment is a apartment with great comfort and excellent service according to most apartment s guests With all facilities offered Royal Bee Apartment is the right place to stay\n",
      "- Summary:\n",
      " easy to use\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Review:\n",
      " yellow hostel is a hostel in a good neighborhood which is located at Don Mueang Airport The hostel has a very good location also near the Don Mueang International Airport DMK which is only 1.61 kilometers away Not only well positioned but yellow hostel is also one of hostels near the following Donmuang Taharnargardbumrung School within 1.33 kilometers and Don Mueang International Airport DMK within 1.61 kilometers yellow hostel is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget yellow hostel is the perfect place to stay that provides decent facilities as well as great services While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation yellow hostel is suitable for you who value privacy during your stay WiFi is available within public areas of the property to help you to stay connected with family and friends yellow hostel is a wise choice for travelers visiting Don Mueang Airport\n",
      "- Summary:\n",
      " a must for the time\n",
      "\n",
      "\n",
      "- Review:\n",
      " The Little Home DMK is located in area city Don Mueang Airport The hostel has a very good location also near the Don Mueang International Airport DMK which is only 1.76 kilometers away There are plenty of tourist attractions nearby such as Donmuang Taharnargardbumrung School within 1.24 kilometers and Don Mueang International Airport DMK within 1.76 kilometers The Little Home DMK is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget The Little Home DMK is the perfect place to stay that provides decent facilities as well as great services The Little Home DMK is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit If you plan to have a long term stay staying at The Little Home DMK is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation The Little Home DMK is suitable for you who value privacy during your stay 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends The Little Home DMK is the ideal choice for you who are looking for a comfortable yet affordable accommodation\n",
      "- Summary:\n",
      " another easy to use\n",
      "\n",
      "\n",
      "- Review:\n",
      " Thip Mansion Don Mueang Airport is a apartment in a good neighborhood which is located at Don Mueang Airport The apartment has a very good location also near the Don Mueang International Airport DMK which is only 1.72 kilometers away Not only well positioned but Thip Mansion Don Mueang Airport is also one of apartments near the following Don Mueang International Airport DMK within 1.72 kilometers and IT Square within 4.83 kilometers Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at Thip Mansion Don Mueang Airport 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Thip Mansion Don Mueang Airport is a apartment with great comfort and excellent service according to most apartment s guests With all facilities offered Thip Mansion Don Mueang Airport is the right place to stay\n",
      "- Summary:\n",
      " the best\n",
      "\n",
      "\n",
      "- Review:\n",
      " Bandai Hostel Bangkok is a hostel in a good neighborhood which is located at Don Mueang Airport The hostel has a very good location also near the Don Mueang International Airport DMK which is only 1.57 kilometers away Not only well positioned but Bandai Hostel Bangkok is also one of hostels near the following Donmuang Taharnargardbumrung School within 1 kilometers and Don Mueang International Airport DMK within 1.57 kilometers Bandai Hostel Bangkok is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget Bandai Hostel Bangkok is the perfect place to stay that provides decent facilities as well as great services Are you a shopaholic Staying at Bandai Hostel Bangkok will surely spoil you for numerous shopping centers nearby Bandai Hostel Bangkok is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit If you plan to have a long term stay staying at Bandai Hostel Bangkok is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Bandai Hostel Bangkok is suitable for you who value privacy during your stay 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends Bandai Hostel Bangkok is a wise choice for travelers visiting Don Mueang Airport\n",
      "- Summary:\n",
      " i like a good tasting energy drink\n",
      "\n",
      "\n",
      "- Review:\n",
      " note hotel was previously named Mont Place Donmuang is a hotel in a good neighborhood which is located at Don Mueang Airport The hotel has a very good location also near the Don Mueang International Airport DMK which is only 2.27 kilometers away Not only well positioned but Mont Place Donmuang is also one of hotels near the following Don Mueang International Airport DMK within 2.27 kilometers and Donmuang Taharnargardbumrung School within 2.81 kilometers When staying at a hotel the design and architecture are two important factors that can spoil your eyes With its unique setting Mont Place Donmuang provides a pleasant accommodation for your stay 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from Mont Place Donmuang exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends With all facilities offered Mont Place Donmuang is the right place to stay\n",
      "- Summary:\n",
      " good for you tastes good\n",
      "\n",
      "\n",
      "- Review:\n",
      " Sleep Well DMK Hostel is a hostel in a good neighborhood which is located at Don Mueang Airport The hostel has a very good location also near the Don Mueang International Airport DMK which is only 2.75 kilometers away Not only well positioned but Sleep Well DMK Hostel is also one of hostels near the following Donmuang Taharnargardbumrung School within 1.63 kilometers and Don Mueang International Airport DMK within 2.75 kilometers Sleep Well DMK Hostel is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget Sleep Well DMK Hostel is the perfect place to stay that provides decent facilities as well as great services While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Sleep Well DMK Hostel is suitable for you who value privacy during your stay WiFi is available within public areas of the property to help you to stay connected with family and friends Sleep Well DMK Hostel is a wise choice for travelers visiting Don Mueang Airport\n",
      "- Summary:\n",
      " a touch up saver\n",
      "\n",
      "\n",
      "- Review:\n",
      " The Nine House is located in area city Don Mueang Airport The hostel has a very good location also near the Don Mueang International Airport DMK which is only 2.04 kilometers away There are plenty of tourist attractions nearby such as Don Mueang International Airport DMK within 2.04 kilometers and IT Square within 5.49 kilometers For you travelers who wish to travel comfortably on a budget The Nine House is the perfect place to stay that provides decent facilities as well as great services The Nine House is the right choice for you who are looking for affordable accommodation in Don Mueang Airport WiFi is available within public areas of the property to help you to stay connected with family and friends The Nine House is the ideal choice for you who are looking for a comfortable yet affordable accommodation\n",
      "- Summary:\n",
      " another me up\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Review:\n",
      " Staying at Big Smile Hostel is a good choice when you are visiting Don Mueang Airport The hostel has a very good location also near the Don Mueang International Airport DMK which is only 1.78 kilometers away This hostel is very easy to find since it is strategically positioned close to public facilities Not only located within easy reach of various places of interests for your adventure but staying at Big Smile Hostel will also give you a pleasant stay Big Smile Hostel is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget Big Smile Hostel is the perfect place to stay that provides decent facilities as well as great services Spend quality time at Big Smile Hostel with your spouse Make it an unforgettable stay by enjoying all services and facilities that the hostel has to offer This hostel is the perfect choice for couples seeking a romantic getaway or a honeymoon retreat Enjoy the most memorable nights with your loved one by staying at Big Smile Hostel Are you a shopaholic Staying at Big Smile Hostel will surely spoil you for numerous shopping centers nearby Big Smile Hostel is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit When staying at a hostel the design and architecture are two important factors that can spoil your eyes With its unique setting Big Smile Hostel provides a pleasant accommodation for your stay From business event to corporate gathering Big Smile Hostel provides complete services and facilities that you and your colleagues need Have fun with various entertaining facilities for you and the whole family at Big Smile Hostel a wonderful accommodation for your family holiday If you plan to have a long term stay staying at Big Smile Hostel is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Big Smile Hostel is suitable for you who value privacy during your stay Big Smile Hostel is the right choice for you who are looking for affordable accommodation in Don Mueang Airport 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from Big Smile Hostel exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends Big Smile Hostel is a hostel with great comfort and excellent service according to most hostel s guests Staying at Big Smile Hostel will surely satisfy you with its great hospitality and affordable price\n",
      "- Summary:\n",
      " quick easy delicious\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at Area 69 Don Muang Airport Maison is a good choice when you are visiting Don Mueang Airport The apartment has a very good location also near the Don Mueang International Airport DMK which is only 2.75 kilometers away This apartment is very easy to find since it is strategically positioned close to public facilities Area 69 Don Muang Airport Maison is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget Area 69 Don Muang Airport Maison is the perfect place to stay that provides decent facilities as well as great services Spend quality time at Area 69 Don Muang Airport Maison with your spouse Make it an unforgettable stay by enjoying all services and facilities that the apartment has to offer This apartment is the perfect choice for couples seeking a romantic getaway or a honeymoon retreat Enjoy the most memorable nights with your loved one by staying at Area 69 Don Muang Airport Maison Are you a shopaholic Staying at Area 69 Don Muang Airport Maison will surely spoil you for numerous shopping centers nearby Area 69 Don Muang Airport Maison is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit From business event to corporate gathering Area 69 Don Muang Airport Maison provides complete services and facilities that you and your colleagues need Have fun with various entertaining facilities for you and the whole family at Area 69 Don Muang Airport Maison a wonderful accommodation for your family holiday If you plan to have a long term stay staying at Area 69 Don Muang Airport Maison is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Area 69 Don Muang Airport Maison is suitable for you who value privacy during your stay Area 69 Don Muang Airport Maison is the right choice for you who are looking for affordable accommodation in Don Mueang Airport WiFi is available within public areas of the property to help you to stay connected with family and friends Staying at Area 69 Don Muang Airport Maison will surely satisfy you with its great hospitality and affordable price\n",
      "- Summary:\n",
      " the best\n",
      "\n",
      "\n",
      "- Review:\n",
      " Hoppers Place Donmueang Hostel is a hostel in a good neighborhood which is located at Don Mueang Airport The hostel has a very good location also near the Don Mueang International Airport DMK which is only 2.3 kilometers away Not only well positioned but Hoppers Place Donmueang Hostel is also one of hostels near the following Don Mueang International Airport DMK within 2.3 kilometers and Donmuang Taharnargardbumrung School within 2.82 kilometers Hoppers Place Donmueang Hostel is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget Hoppers Place Donmueang Hostel is the perfect place to stay that provides decent facilities as well as great services Hoppers Place Donmueang Hostel is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Hoppers Place Donmueang Hostel is suitable for you who value privacy during your stay Hoppers Place Donmueang Hostel is the right choice for you who are looking for affordable accommodation in Don Mueang Airport WiFi is available within public areas of the property to help you to stay connected with family and friends Hoppers Place Donmueang Hostel is a hostel with great comfort and excellent service according to most hostel s guests Hoppers Place Donmueang Hostel is a wise choice for travelers visiting Don Mueang Airport\n",
      "- Summary:\n",
      " another a good time saver\n",
      "\n",
      "\n",
      "- Review:\n",
      " DMK Hostel Donmueang Airport is a hostel in a good neighborhood which is located at Don Mueang Airport The hostel has a very good location also near the Don Mueang International Airport DMK which is only 1.59 kilometers away Not only well positioned but DMK Hostel Donmueang Airport is also one of hostels near the following Don Mueang International Airport DMK within 1.59 kilometers and IT Square within 4.49 kilometers DMK Hostel Donmueang Airport is a wise choice for travelers visiting Don Mueang Airport\n",
      "- Summary:\n",
      " good for you\n",
      "\n",
      "\n",
      "- Review:\n",
      " Friend s House Resort is located in area city Don Mueang Airport The resort has a very good location also near the Don Mueang International Airport DMK which is only 3.77 kilometers away There are plenty of tourist attractions nearby such as Donmuang Taharnargardbumrung School within 2.06 kilometers and Don Mueang International Airport DMK within 3.77 kilometers Friend s House Resort is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget Friend s House Resort is the perfect place to stay that provides decent facilities as well as great services Friend s House Resort is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit From business event to corporate gathering Friend s House Resort provides complete services and facilities that you and your colleagues need Have fun with various entertaining facilities for you and the whole family at Friend s House Resort a wonderful accommodation for your family holiday If you plan to have a long term stay staying at Friend s House Resort is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Friend s House Resort is suitable for you who value privacy during your stay This resort is the best spot for you who desire a serene and peaceful getaway far away from the crowds Friend s House Resort is the right choice for you who are looking for affordable accommodation in Don Mueang Airport 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends Friend s House Resort is the ideal choice for you who are looking for a comfortable yet affordable accommodation\n",
      "- Summary:\n",
      " outstanding time saver time saver by time time time time time by the time\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Review:\n",
      " Staying at Beekataa Hostel Donmueang is a good choice when you are visiting Don Mueang Airport The hostel has a very good location also near the Don Mueang International Airport DMK which is only 1.96 kilometers away This hostel is very easy to find since it is strategically positioned close to public facilities Beekataa Hostel Donmueang is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget Beekataa Hostel Donmueang is the perfect place to stay that provides decent facilities as well as great services While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Beekataa Hostel Donmueang is suitable for you who value privacy during your stay Beekataa Hostel Donmueang is the right choice for you who are looking for affordable accommodation in Don Mueang Airport WiFi is available within public areas of the property to help you to stay connected with family and friends Staying at Beekataa Hostel Donmueang will surely satisfy you with its great hospitality and affordable price\n",
      "- Summary:\n",
      " another happy cytomax a long time\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at D House Don Mueang is a good choice when you are visiting Don Mueang Airport The B B has a very good location also near the Don Mueang International Airport DMK which is only 1.67 kilometers away This B B is very easy to find since it is strategically positioned close to public facilities D House Don Mueang is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget D House Don Mueang is the perfect place to stay that provides decent facilities as well as great services D House Don Mueang is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation D House Don Mueang is suitable for you who value privacy during your stay D House Don Mueang is the smartest choice for you who are looking for affordable accommodation with outstanding service 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends D House Don Mueang is a B B with great comfort and excellent service according to most B B s guests Staying at D House Don Mueang will surely satisfy you with its great hospitality and affordable price\n",
      "- Summary:\n",
      " another happy cytomax a long time time\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at Sleep Owl Hostel is a good choice when you are visiting Don Mueang Airport The hostel has a very good location also near the Don Mueang International Airport DMK which is only 1.01 kilometers away This hostel is very easy to find since it is strategically positioned close to public facilities Not only located within easy reach of various places of interests for your adventure but staying at Sleep Owl Hostel will also give you a pleasant stay Sleep Owl Hostel is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget Sleep Owl Hostel is the perfect place to stay that provides decent facilities as well as great services Are you a shopaholic Staying at Sleep Owl Hostel will surely spoil you for numerous shopping centers nearby Sleep Owl Hostel is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Sleep Owl Hostel is suitable for you who value privacy during your stay Sleep Owl Hostel is the smartest choice for you who are looking for affordable accommodation with outstanding service 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends Sleep Owl Hostel is a hostel with great comfort and excellent service according to most hostel s guests Staying at Sleep Owl Hostel will surely satisfy you with its great hospitality and affordable price\n",
      "- Summary:\n",
      " ordering the time\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at Kedkanok Apartment is a good choice when you are visiting Don Mueang Airport The apartment has a very good location also near the Don Mueang International Airport DMK which is only 2.64 kilometers away This apartment is very easy to find since it is strategically positioned close to public facilities For you travelers who wish to travel comfortably on a budget Kedkanok Apartment is the perfect place to stay that provides decent facilities as well as great services If you plan to have a long term stay staying at Kedkanok Apartment is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Kedkanok Apartment is suitable for you who value privacy during your stay Kedkanok Apartment is the right choice for you who are looking for affordable accommodation in Don Mueang Airport WiFi is available within public areas of the property to help you to stay connected with family and friends Kedkanok Apartment is a apartment with great comfort and excellent service according to most apartment s guests Staying at Kedkanok Apartment will surely satisfy you with its great hospitality and affordable price\n",
      "- Summary:\n",
      " another the time as you get as a gift for\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at Nittaya Residence Don Muang is a good choice when you are visiting Don Mueang Airport The apartment has a very good location also near the Don Mueang International Airport DMK which is only 1.7 kilometers away This apartment is very easy to find since it is strategically positioned close to public facilities Nittaya Residence Don Muang is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget Nittaya Residence Don Muang is the perfect place to stay that provides decent facilities as well as great services Nittaya Residence Don Muang is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit If you plan to have a long term stay staying at Nittaya Residence Don Muang is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Nittaya Residence Don Muang is suitable for you who value privacy during your stay Nittaya Residence Don Muang is the smartest choice for you who are looking for affordable accommodation with outstanding service 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends Nittaya Residence Don Muang is a apartment with great comfort and excellent service according to most apartment s guests Staying at Nittaya Residence Don Muang will surely satisfy you with its great hospitality and affordable price\n",
      "- Summary:\n",
      " another a good start back start\n",
      "\n",
      "\n",
      "- Review:\n",
      " Take A Rest Donmueang is a apartment in a good neighborhood which is located at Don Mueang Airport The apartment has a very good location also near the Don Mueang International Airport DMK which is only 1.26 kilometers away Not only well positioned but Take A Rest Donmueang is also one of apartments near the following Don Mueang International Airport DMK within 1.26 kilometers and Donmuang Taharnargardbumrung School within 2.16 kilometers For you travelers who wish to travel comfortably on a budget Take A Rest Donmueang is the perfect place to stay that provides decent facilities as well as great services Take A Rest Donmueang is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit If you plan to have a long term stay staying at Take A Rest Donmueang is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Take A Rest Donmueang is suitable for you who value privacy during your stay WiFi is available within public areas of the property to help you to stay connected with family and friends Take A Rest Donmueang is a apartment with great comfort and excellent service according to most apartment s guests Take A Rest Donmueang is a wise choice for travelers visiting Don Mueang Airport\n",
      "- Summary:\n",
      " another easy to use\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Review:\n",
      " note hotel was previously named D Well Residence D Well Residence Don Muang is a hotel in a good neighborhood which is located at Don Mueang Airport The hotel has a very good location also near the Don Mueang Intl Airport Airport which is only 1.94 kilometers away Not only well positioned but D Well Residence Don Muang is also one of hotels near the following Don Mueang Intl Airport within 1.94 kilometers and IT Square within 3.12 kilometers Not only located within easy reach of various places of interests for your adventure but staying at D Well Residence Don Muang will also give you a pleasant stay D Well Residence Don Muang is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget D Well Residence Don Muang is the perfect place to stay that provides decent facilities as well as great services This hotel is the perfect choice for couples seeking a romantic getaway or a honeymoon retreat Enjoy the most memorable nights with your loved one by staying at D Well Residence Don Muang D Well Residence Don Muang is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit If you plan to have a long term stay staying at D Well Residence Don Muang is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation D Well Residence Don Muang is suitable for you who value privacy during your stay 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you D Well Residence Don Muang is a hotel with great comfort and excellent service according to most hotel s guests D Well Residence Don Muang is a wise choice for travelers visiting Don Mueang Airport\n",
      "- Summary:\n",
      " a must for the time\n",
      "\n",
      "\n",
      "- Review:\n",
      " With a stay at Domingo Hostel Donmuang in Bangkok Don Muang you will be 11.6 miles 18.7 kilometers from Chatuchak Weekend Market and 15.3 miles 24.7 kilometers from Suan Pakkard Palace This hostel is 16.7 miles 26.8 kilometers from Siam Paragon Mall and 17.3 miles 27.8 kilometers from Vimanmek Palace Make yourself at home in one of the 3 air conditioned guestrooms Complimentary wireless Internet access is available to keep you connected Bathrooms with showers are provided Make use of convenient amenities which include complimentary wireless Internet access and a television in a common area The front desk is staffed during limited hours\n",
      "- Summary:\n",
      " meh my daughter eats it\n",
      "\n",
      "\n",
      "- Review:\n",
      " With a stay at Roomstay Ruenkaew in Bangkok Don Muang you will be 14.6 miles 23.5 kilometers from Chatuchak Weekend Market and 17.4 miles 28 kilometers from Vimanmek Palace This guesthouse is 4.5 miles 7.2 kilometers from IT Square and 4.7 miles 7.6 kilometers from Royal Thai Air Force Museum Make yourself at home in one of the 4 air conditioned rooms featuring LCD televisions Complimentary wireless Internet access keeps you connected and cable programming is available for your entertainment Private bathrooms with showers feature complimentary toiletries and slippers Conveniences include separate sitting areas and complimentary bottled water and housekeeping is provided daily Take in the views from a terrace and a garden and make use of amenities such as complimentary wireless Internet access The front desk is staffed during limited hours Free self parking is available onsite\n",
      "- Summary:\n",
      " easy and good\n",
      "\n",
      "\n",
      "- Review:\n",
      " With a stay at Ban Kru Ae Homestay in Bangkok Don Muang you will be 13 minutes by car from Don Mueang New Market This guesthouse is 14.9 miles 23.9 kilometers from Chatuchak Weekend Market and 4.8 miles 7.7 kilometers from IT Square Make yourself at home in one of the 4 individually decorated guestrooms Complimentary wireless Internet access is available to keep you connected Conveniences include complimentary bottled water and ceiling fans and housekeeping is provided daily Take in the views from a terrace and make use of amenities such as complimentary wireless Internet access and a television in a common area A complimentary local cuisine breakfast is included Featured amenities include express check in express check out and microwave in a common area Free self parking is available onsite\n",
      "- Summary:\n",
      " bartenders english breakfast\n",
      "\n",
      "\n",
      "- Review:\n",
      " With a stay at Villa 91 Guesthouse in Bangkok Don Muang you will be 9.5 miles 15.4 kilometers from Chatuchak Weekend Market and 17.4 miles 28 kilometers from Temple of the Emerald Buddha This guesthouse is 17.8 miles 28.7 kilometers from Grand Palace and 13.3 miles 21.4 kilometers from Suan Pakkard Palace Make yourself at home in one of the 3 air conditioned guestrooms Complimentary wireless Internet access is available to keep you connected Bathrooms feature showers complimentary toiletries and bathrobes Conveniences include complimentary bottled water and housekeeping is provided daily Take in the views from a terrace and a garden and make use of amenities such as complimentary wireless Internet access Continental breakfasts are available daily from 7 AM to 10 AM for a fee Featured amenities include dry cleaning laundry services luggage storage and microwave in a common area Free self parking is available onsite\n",
      "- Summary:\n",
      " meh my daughter s favorite treat\n",
      "\n",
      "\n",
      "- Review:\n",
      " With a stay at The Nine Backpacker in Bangkok Don Muang you will be within a 15 minute drive of Royal Thai Air Force Museum and IT Square This guesthouse is 12.8 miles 20.6 kilometers from Chatuchak Weekend Market and 15.3 miles 24.6 kilometers from Suan Pakkard Palace Make yourself at home in one of the 2 air conditioned guestrooms Complimentary wireless Internet access is available to keep you connected Bathrooms have showers and complimentary toiletries Conveniences include complimentary bottled water and housekeeping is provided daily\n",
      "- Summary:\n",
      " a must have for a daily time\n",
      "\n",
      "\n",
      "- Review:\n",
      " With a stay at Ubolsiri Place in Bangkok Don Muang you will be 10.7 miles 17.2 kilometers from Chatuchak Weekend Market and 14.4 miles 23.2 kilometers from Suan Pakkard Palace This hotel is 15.5 miles 24.9 kilometers from Siam Square and 15.5 miles 25 kilometers from Vimanmek Palace Make yourself at home in one of the 6 air conditioned rooms featuring refrigerators and flat screen televisions Rooms have private balconies Digital television is provided for your entertainment Bathrooms have showers and complimentary toiletries\n",
      "- Summary:\n",
      " a must have for a special after order a stay time\n",
      "\n",
      "\n",
      "- Review:\n",
      " With a stay at Donmueang Airport Residence Hostel in Bangkok Don Muang you will be within a 10 minute drive of Royal Thai Air Force Academy and Royal Thai Air Force Museum This hostel is 11.1 miles 17.9 kilometers from Chatuchak Weekend Market and 2.6 miles 4.2 kilometers from Bhumibol Adulyadej Hospital Make yourself at home in one of the 4 air conditioned guestrooms Complimentary wireless Internet access is available to keep you connected Conveniences include desks and complimentary bottled water and housekeeping is provided daily Featured amenities include a 24 hour front desk and luggage storage\n",
      "- Summary:\n",
      " easy and good\n",
      "\n",
      "\n",
      "- Review:\n",
      " With a stay at Sweet Pillow Hostel Caf in Bangkok Don Muang you will be within a 15 minute drive of IMPACT Arena and IT Square This guesthouse is 11.3 miles 18.2 kilometers from Chatuchak Weekend Market and 15 miles 24.2 kilometers from Suan Pakkard Palace Make yourself at home in one of the 4 air conditioned guestrooms Prepare your meals in the shared communal kitchen Complimentary wireless Internet access is available to keep you connected Bathrooms feature showers complimentary toiletries and hair dryers Make use of convenient amenities which include complimentary wireless Internet access and a television in a common area Cooked to order breakfasts are available daily from 7 AM to 9 AM for a fee Featured amenities include luggage storage laundry facilities and microwave in a common area Free self parking is available onsite\n",
      "- Summary:\n",
      " essentia 9 purified\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Review:\n",
      " With a stay at TKMY DMK in Bangkok Don Muang you will be 12.2 miles 19.7 kilometers from Temple of the Emerald Buddha and 8.1 miles 13 kilometers from Chatuchak Weekend Market This guesthouse is 10.2 miles 16.5 kilometers from Vimanmek Palace and 11.2 miles 18 kilometers from Wat Saket Make yourself at home in one of the 4 air conditioned guestrooms Complimentary wireless Internet access is available to keep you connected Bathrooms have complimentary toiletries and hair dryers Conveniences include coffee tea makers and complimentary bottled water and housekeeping is provided on a limited basis Take in the views from a garden and make use of amenities such as complimentary wireless Internet access and a television in a common area Cooked to order breakfasts are available daily from 6 30 AM to 10 AM for a fee Featured amenities include laundry facilities microwave in a common area and refrigerator in a common area A roundtrip airport shuttle is provided for a surcharge during limited hours and free self parking is available onsite\n",
      "- Summary:\n",
      " ordering at punch\n",
      "\n",
      "\n",
      "- Review:\n",
      " With a stay at Phoom House in Bangkok Don Muang you will be close to Royal Thai Air Force Museum and IT Square This hotel is within close proximity of Zeer Rangsit and Rangsit University Make yourself at home in one of the 30 air conditioned rooms featuring refrigerators and flat screen televisions Complimentary wireless Internet access keeps you connected and cable programming is available for your entertainment Bathrooms have showers and complimentary toiletries Conveniences include complimentary bottled water and housekeeping is provided daily Take in the views from a terrace and make use of amenities such as complimentary wireless Internet access and a picnic area Featured amenities include a 24 hour front desk and luggage storage Free self parking is available onsite\n",
      "- Summary:\n",
      " wonderfully take\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at We Inn is a good choice when you are visiting Don Mueang Airport The hotel has a very good location also near the Don Mueang International Airport DMK which is only 1.63 kilometers away This hotel is very easy to find since it is strategically positioned close to public facilities 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Staying at We Inn will surely satisfy you with its great hospitality and affordable price\n",
      "- Summary:\n",
      " good taste and easy\n",
      "\n",
      "\n",
      "- Review:\n",
      " Nice Bird Suite Apartment is a apartment in a good neighborhood which is located at Lak Si The apartment has a very good location also near the Don Mueang International Airport DMK which is only 8.24 kilometers away The apartment is located only 6.55 kilometers away from Mo Chit BTS Station Not only well positioned but Nice Bird Suite Apartment is also one of apartments near the following Kasetsart University within 2.4 kilometers and IT Square within 4.23 kilometers For you travelers who wish to travel comfortably on a budget Nice Bird Suite Apartment is the perfect place to stay that provides decent facilities as well as great services Nice Bird Suite Apartment is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit From business event to corporate gathering Nice Bird Suite Apartment provides complete services and facilities that you and your colleagues need If you plan to have a long term stay staying at Nice Bird Suite Apartment is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Nice Bird Suite Apartment is suitable for you who value privacy during your stay Nice Bird Suite Apartment is the smartest choice for you who are looking for affordable accommodation with outstanding service WiFi is available within public areas of the property to help you to stay connected with family and friends Nice Bird Suite Apartment is a wise choice for travelers visiting Lak Si\n",
      "- Summary:\n",
      " one of the best\n",
      "\n",
      "\n",
      "- Review:\n",
      " note hotel was previously named Kung Val Mansion Donmuang D Well Residence Don Muang 2 is a hotel in a good neighborhood which is located at Don Mueang Airport The hotel has a very good location also near the Don Mueang International Airport DMK which is only 1.92 kilometers away Not only well positioned but D Well Residence Don Muang 2 is also one of hotels near the following Don Mueang International Airport DMK within 1.92 kilometers and Stadium Air Force Chantarubeksa Gazette within 2.87 kilometers Not only located within easy reach of various places of interests for your adventure but staying at D Well Residence Don Muang 2 will also give you a pleasant stay D Well Residence Don Muang 2 is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget D Well Residence Don Muang 2 is the perfect place to stay that provides decent facilities as well as great services This hotel is the perfect choice for couples seeking a romantic getaway or a honeymoon retreat Enjoy the most memorable nights with your loved one by staying at D Well Residence Don Muang 2 D Well Residence Don Muang 2 is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit If you plan to have a long term stay staying at D Well Residence Don Muang 2 is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation D Well Residence Don Muang 2 is suitable for you who value privacy during your stay D Well Residence Don Muang 2 is the smartest choice for you who are looking for affordable accommodation with outstanding service 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends D Well Residence Don Muang 2 is a hotel with great comfort and excellent service according to most hotel s guests D Well Residence Don Muang 2 is a wise choice for travelers visiting Don Mueang Airport\n",
      "- Summary:\n",
      " a must for the time\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at Max One House is a good choice when you are visiting Don Mueang Airport The B B has a very good location also near the Don Mueang International Airport DMK which is only 2.42 kilometers away This B B is very easy to find since it is strategically positioned close to public facilities Max One House is the smartest choice for you who are looking for affordable accommodation with outstanding service 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Staying at Max One House will surely satisfy you with its great hospitality and affordable price\n",
      "- Summary:\n",
      " good for you\n",
      "\n",
      "\n",
      "- Review:\n",
      " Thanapa Mansion Donmuang Airport is a hotel in a good neighborhood which is located at Anusawari The hotel has a very good location also near the Don Mueang International Airport DMK which is only 2.99 kilometers away Not only well positioned but Thanapa Mansion Donmuang Airport is also one of hotels near the following Central Ramintra within 1.71 kilometers and Lumpinee Boxing Stadium within 2.05 kilometers Thanapa Mansion Donmuang Airport is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget Thanapa Mansion Donmuang Airport is the perfect place to stay that provides decent facilities as well as great services Spend quality time at Thanapa Mansion Donmuang Airport with your spouse Make it an unforgettable stay by enjoying all services and facilities that the hotel has to offer Thanapa Mansion Donmuang Airport is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit If you plan to have a long term stay staying at Thanapa Mansion Donmuang Airport is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home Thanapa Mansion Donmuang Airport is the smartest choice for you who are looking for affordable accommodation with outstanding service 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends Thanapa Mansion Donmuang Airport is a wise choice for travelers visiting Anusawari\n",
      "- Summary:\n",
      " another back up a long time\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Review:\n",
      " Donmuang Airport Modern Bangkok Hotel is located in area city Don Mueang Airport The hotel has a very good location also near the Don Mueang International Airport DMK which is only 1.55 kilometers away There are plenty of tourist attractions nearby such as Donmuang Taharnargardbumrung School within 0.94 kilometers and Don Mueang International Airport DMK within 1.55 kilometers Donmuang Airport Modern Bangkok Hotel is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit When staying at a hotel the design and architecture are two important factors that can spoil your eyes With its unique setting Donmuang Airport Modern Bangkok Hotel provides a pleasant accommodation for your stay 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends Donmuang Airport Modern Bangkok Hotel is a hotel with great comfort and excellent service according to most hotel s guests Donmuang Airport Modern Bangkok Hotel is the ideal choice for you who are looking for a comfortable yet affordable accommodation\n",
      "- Summary:\n",
      " another happy cytomax user\n",
      "\n",
      "\n",
      "- Review:\n",
      " Delight Residence is located in area city Lak Si The apartment has a very good location also near the Don Mueang International Airport DMK which is only 5.47 kilometers away The apartment is located only 9.81 kilometers away from Mo Chit BTS Station There are plenty of tourist attractions nearby such as IT Square within 2.27 kilometers and Kasetsart University within 4.71 kilometers Delight Residence is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget Delight Residence is the perfect place to stay that provides decent facilities as well as great services Delight Residence is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit If you plan to have a long term stay staying at Delight Residence is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Delight Residence is suitable for you who value privacy during your stay Delight Residence is the smartest choice for you who are looking for affordable accommodation with outstanding service 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends Delight Residence is a apartment with great comfort and excellent service according to most apartment s guests Delight Residence is the ideal choice for you who are looking for a comfortable yet affordable accommodation\n",
      "- Summary:\n",
      " the best carrot bar have found\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at BnR Resorts is a good choice when you are visiting Don Mueang Airport The hotel has a very good location also near the Don Mueang International Airport DMK which is only 2.8 kilometers away This hotel is very easy to find since it is strategically positioned close to public facilities Staying at BnR Resorts will surely satisfy you with its great hospitality and affordable price\n",
      "- Summary:\n",
      " easy to find\n",
      "\n",
      "\n",
      "- Review:\n",
      " Phurahong Homestay is a B B in a good neighborhood which is located at Don Mueang Airport The B B has a very good location also near the Don Mueang International Airport DMK which is only 3.66 kilometers away Not only well positioned but Phurahong Homestay is also one of B Bs near the following Lumpinee Boxing Stadium within 2.46 kilometers and Central Ramintra within 2.77 kilometers Phurahong Homestay is the smartest choice for you who are looking for affordable accommodation with outstanding service Savor your favorite dishes with special cuisines from Phurahong Homestay exclusively for you Phurahong Homestay is a B B with great comfort and excellent service according to most B B s guests Phurahong Homestay is a wise choice for travelers visiting Don Mueang Airport\n",
      "- Summary:\n",
      " bright bright bright bright mt bright magic\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at Donmuang Mansion is a good choice when you are visiting Don Mueang Airport The hotel has a very good location also near the Don Mueang International Airport DMK which is only 1.71 kilometers away This hotel is very easy to find since it is strategically positioned close to public facilities 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Staying at Donmuang Mansion will surely satisfy you with its great hospitality and affordable price\n",
      "- Summary:\n",
      " good taste good price\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at Mon Lodge Yoga Donmuang is a good choice when you are visiting Don Mueang Airport The B B has a very good location also near the Don Mueang International Airport DMK which is only 2.47 kilometers away This B B is very easy to find since it is strategically positioned close to public facilities Mon Lodge Yoga Donmuang is the smartest choice for you who are looking for affordable accommodation with outstanding service Mon Lodge Yoga Donmuang is a B B with great comfort and excellent service according to most B B s guests Staying at Mon Lodge Yoga Donmuang will surely satisfy you with its great hospitality and affordable price\n",
      "- Summary:\n",
      " gu gu\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at BB Home Donmuang is a good choice when you are visiting Don Mueang Airport The hotel has a very good location also near the Don Mueang International Airport DMK which is only 3.39 kilometers away This hotel is very easy to find since it is strategically positioned close to public facilities BB Home Donmuang is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget BB Home Donmuang is the perfect place to stay that provides decent facilities as well as great services BB Home Donmuang is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit When staying at a hotel the design and architecture are two important factors that can spoil your eyes With its unique setting BB Home Donmuang provides a pleasant accommodation for your stay From business event to corporate gathering BB Home Donmuang provides complete services and facilities that you and your colleagues need Have fun with various entertaining facilities for you and the whole family at BB Home Donmuang a wonderful accommodation for your family holiday If you plan to have a long term stay staying at BB Home Donmuang is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation BB Home Donmuang is suitable for you who value privacy during your stay 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends BB Home Donmuang is a hotel with great comfort and excellent service according to most hotel s guests Staying at BB Home Donmuang will surely satisfy you with its great hospitality and affordable price\n",
      "- Summary:\n",
      " i saver\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at ZLEEP 63 Hostel is a good choice when you are visiting Don Mueang Airport The hostel has a very good location also near the Don Mueang International Airport DMK which is only 1.61 kilometers away This hostel is very easy to find since it is strategically positioned close to public facilities ZLEEP 63 Hostel is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget ZLEEP 63 Hostel is the perfect place to stay that provides decent facilities as well as great services ZLEEP 63 Hostel is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation ZLEEP 63 Hostel is suitable for you who value privacy during your stay ZLEEP 63 Hostel is the smartest choice for you who are looking for affordable accommodation with outstanding service WiFi is available within public areas of the property to help you to stay connected with family and friends Staying at ZLEEP 63 Hostel will surely satisfy you with its great hospitality and affordable price\n",
      "- Summary:\n",
      " one of the best\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Review:\n",
      " Staying at I Rich Residence is a good choice when you are visiting Don Mueang Airport The apartment has a very good location also near the Don Mueang International Airport DMK which is only 4.88 kilometers away This apartment is very easy to find since it is strategically positioned close to public facilities I Rich Residence is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget I Rich Residence is the perfect place to stay that provides decent facilities as well as great services Spend quality time at I Rich Residence with your spouse Make it an unforgettable stay by enjoying all services and facilities that the apartment has to offer I Rich Residence is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit From business event to corporate gathering I Rich Residence provides complete services and facilities that you and your colleagues need Have fun with various entertaining facilities for you and the whole family at I Rich Residence a wonderful accommodation for your family holiday This apartment is an ideal choice for you novice to professional golfers If you plan to have a long term stay staying at I Rich Residence is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation I Rich Residence is suitable for you who value privacy during your stay Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at I Rich Residence WiFi is available within public areas of the property to help you to stay connected with family and friends I Rich Residence is a apartment with great comfort and excellent service according to most apartment s guests With all facilities offered I Rich Residence is the right place to stay\n",
      "- Summary:\n",
      " easy to use and easy to prepare up meal\n",
      "\n",
      "\n",
      "- Review:\n",
      " Khun Noy Apartment is a apartment in a good neighborhood which is located at Lak Si The apartment has a very good location also near the Don Mueang International Airport DMK which is only 5.21 kilometers away Not only well positioned but Khun Noy Apartment is also one of apartments near the following IT Square within 2.2 kilometers and Central Ramintra within 4.78 kilometers Have fun with various entertaining facilities for you and the whole family at Khun Noy Apartment a wonderful accommodation for your family holiday Khun Noy Apartment is the smartest choice for you who are looking for affordable accommodation with outstanding service WiFi is available within public areas of the property to help you to stay connected with family and friends Khun Noy Apartment is a apartment with great comfort and excellent service according to most apartment s guests Khun Noy Apartment is a wise choice for travelers visiting Lak Si\n",
      "- Summary:\n",
      " another a favorite\n",
      "\n",
      "\n",
      "- Review:\n",
      " note apartment was previously named Pool House Service Residence Pool Villa Donmueang is located in area city Lak Si The apartment has a very good location also near the Don Mueang International Airport DMK which is only 2.72 kilometers away There are plenty of tourist attractions nearby such as IT Square within 1.57 kilometers and Don Mueang International Airport DMK within 2.72 kilometers For you travelers who wish to travel comfortably on a budget Pool Villa Donmueang is the perfect place to stay that provides decent facilities as well as great services Pool Villa Donmueang is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit If you plan to have a long term stay staying at Pool Villa Donmueang is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Pool Villa Donmueang is suitable for you who value privacy during your stay Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at Pool Villa Donmueang Have an enjoyable and relaxing day at the pool whether you re traveling solo or with your loved ones WiFi is available within public areas of the property to help you to stay connected with family and friends Pool Villa Donmueang is a apartment with great comfort and excellent service according to most apartment s guests With all facilities offered Pool Villa Donmueang is the right place to stay\n",
      "- Summary:\n",
      " the best i have found\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at Jpark Residences Chinnakhet is a good choice when you are visiting Lak Si The apartment has a very good location also near the Don Mueang International Airport DMK which is only 8.91 kilometers away The apartment is located only 5.96 kilometers away from Mo Chit BTS Station This apartment is very easy to find since it is strategically positioned close to public facilities For you travelers who wish to travel comfortably on a budget Jpark Residences Chinnakhet is the perfect place to stay that provides decent facilities as well as great services Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at Jpark Residences Chinnakhet The apartment s fitness center is a must try during your stay here 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from Jpark Residences Chinnakhet exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends With all facilities offered Jpark Residences Chinnakhet is the right place to stay\n",
      "- Summary:\n",
      " another back back to into up kist\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at We Train Hotel Donmuang is a good choice when you are visiting Don Mueang Airport The hotel has a very good location also near the Don Mueang International Airport DMK which is only 3.76 kilometers away This hotel is very easy to find since it is strategically positioned close to public facilities For you travelers who wish to travel comfortably on a budget We Train Hotel Donmuang is the perfect place to stay that provides decent facilities as well as great services We Train Hotel Donmuang is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit From business event to corporate gathering We Train Hotel Donmuang provides complete services and facilities that you and your colleagues need Have fun with various entertaining facilities for you and the whole family at We Train Hotel Donmuang a wonderful accommodation for your family holiday While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation We Train Hotel Donmuang is suitable for you who value privacy during your stay Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at We Train Hotel Donmuang Have an enjoyable and relaxing day at the pool whether you re traveling solo or with your loved ones 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from We Train Hotel Donmuang exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends With all facilities offered We Train Hotel Donmuang is the right place to stay\n",
      "- Summary:\n",
      " quick easy meal peanut butter mixer\n",
      "\n",
      "\n",
      "- Review:\n",
      " Tewa Boutique Hotel is a hotel in a good neighborhood which is located at Lak Si The hotel has a very good location also near the Don Mueang International Airport DMK which is only 5.61 kilometers away The hotel is located only 9.44 kilometers away from Mo Chit BTS Station Not only well positioned but Tewa Boutique Hotel is also one of hotels near the following IT Square within 2.16 kilometers and Kasetsart University within 4.33 kilometers Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at Tewa Boutique Hotel Have an enjoyable and relaxing day at the pool whether you re traveling solo or with your loved ones 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from Tewa Boutique Hotel exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends With all facilities offered Tewa Boutique Hotel is the right place to stay\n",
      "- Summary:\n",
      " another glory\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Review:\n",
      " Staying at BCJ Residence is a good choice when you are visiting Lak Si The hotel has a very good location also near the Don Mueang International Airport DMK which is only 7.61 kilometers away The hotel is located only 6.79 kilometers away from Mo Chit BTS Station This hotel is very easy to find since it is strategically positioned close to public facilities Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at BCJ Residence The hotel s fitness center is a must try during your stay here 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you BCJ Residence is a hotel with great comfort and excellent service according to most hotel s guests With all facilities offered BCJ Residence is the right place to stay\n",
      "- Summary:\n",
      " makes the ultimate\n",
      "\n",
      "\n",
      "- Review:\n",
      " Ebina House is located in area city Lak Si The hotel has a very good location also near the Don Mueang International Airport DMK which is only 5.08 kilometers away The hotel is located only 8.55 kilometers away from Mo Chit BTS Station There are plenty of tourist attractions nearby such as IT Square within 1.18 kilometers and Central Ramintra within 2.38 kilometers Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at Ebina House The hotel s fitness center is a must try during your stay here Have an enjoyable and relaxing day at the pool whether you re traveling solo or with your loved ones 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from Ebina House exclusively for you Ebina House is a hotel with great comfort and excellent service according to most hotel s guests With all facilities offered Ebina House is the right place to stay\n",
      "- Summary:\n",
      " fast easy fast meal\n",
      "\n",
      "\n",
      "- Review:\n",
      " Airport Bed Don Meung is a hotel in a good neighborhood which is located at Don Mueang Airport The hotel has a very good location also near the Don Mueang International Airport DMK which is only 2.85 kilometers away Not only well positioned but Airport Bed Don Meung is also one of hotels near the following IT Square within 1.19 kilometers and Central Ramintra within 2.63 kilometers Airport Bed Don Meung is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at Airport Bed Don Meung Savor your favorite dishes with special cuisines from Airport Bed Don Meung exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends With all facilities offered Airport Bed Don Meung is the right place to stay\n",
      "- Summary:\n",
      " good gf quick meal\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at Montri Resort Donmuang Bangkok is a good choice when you are visiting Don Mueang Airport The resort has a very good location also near the Don Mueang International Airport DMK which is only 1.65 kilometers away This resort is very easy to find since it is strategically positioned close to public facilities Not only located within easy reach of various places of interests for your adventure but staying at Montri Resort Donmuang Bangkok will also give you a pleasant stay Montri Resort Donmuang Bangkok is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget Montri Resort Donmuang Bangkok is the perfect place to stay that provides decent facilities as well as great services Whether you are planning an event or other special occasions Montri Resort Donmuang Bangkok is a great choice for you with a large and well equipped function room to suit your requirements Spend quality time at Montri Resort Donmuang Bangkok with your spouse Make it an unforgettable stay by enjoying all services and facilities that the resort has to offer This resort is the perfect choice for couples seeking a romantic getaway or a honeymoon retreat Enjoy the most memorable nights with your loved one by staying at Montri Resort Donmuang Bangkok Are you a shopaholic Staying at Montri Resort Donmuang Bangkok will surely spoil you for numerous shopping centers nearby Montri Resort Donmuang Bangkok is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit When staying at a resort the design and architecture are two important factors that can spoil your eyes With its unique setting Montri Resort Donmuang Bangkok provides a pleasant accommodation for your stay From business event to corporate gathering Montri Resort Donmuang Bangkok provides complete services and facilities that you and your colleagues need Have fun with various entertaining facilities for you and the whole family at Montri Resort Donmuang Bangkok a wonderful accommodation for your family holiday If you plan to have a long term stay staying at Montri Resort Donmuang Bangkok is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Montri Resort Donmuang Bangkok is suitable for you who value privacy during your stay This resort is the best spot for you who desire a serene and peaceful getaway far away from the crowds Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at Montri Resort Donmuang Bangkok 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from Montri Resort Donmuang Bangkok exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends Montri Resort Donmuang Bangkok is a resort with great comfort and excellent service according to most resort s guests With all facilities offered Montri Resort Donmuang Bangkok is the right place to stay\n",
      "- Summary:\n",
      " the best carrot\n",
      "\n",
      "\n",
      "- Review:\n",
      " Sandy Serviced Apartment is a apartment in a good neighborhood which is located at Lak Si The apartment has a very good location also near the Don Mueang International Airport DMK which is only 7.07 kilometers away The apartment is located only 7.73 kilometers away from Mo Chit BTS Station Not only well positioned but Sandy Serviced Apartment is also one of apartments near the following Kasetsart University within 2.95 kilometers and IT Square within 3.14 kilometers Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at Sandy Serviced Apartment 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Sandy Serviced Apartment is a apartment with great comfort and excellent service according to most apartment s guests With all facilities offered Sandy Serviced Apartment is the right place to stay\n",
      "- Summary:\n",
      " another crummy\n",
      "\n",
      "\n",
      "- Review:\n",
      " note apartment was previously named Gems Park Apartment Gems Park Apartment Don Mueang International Airport is located in area city Don Mueang Airport The apartment has a very good location also near the Don Mueang International Airport DMK which is only 3.35 kilometers away There are plenty of tourist attractions nearby such as Central Ramintra within 1.29 kilometers and IT Square within 1.97 kilometers Gems Park Apartment Don Mueang International Airport is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit Have fun with various entertaining facilities for you and the whole family at Gems Park Apartment Don Mueang International Airport a wonderful accommodation for your family holiday If you plan to have a long term stay staying at Gems Park Apartment Don Mueang International Airport is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Gems Park Apartment Don Mueang International Airport is suitable for you who value privacy during your stay Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at Gems Park Apartment Don Mueang International Airport 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends Gems Park Apartment Don Mueang International Airport is a apartment with great comfort and excellent service according to most apartment s guests With all facilities offered Gems Park Apartment Don Mueang International Airport is the right place to stay\n",
      "- Summary:\n",
      " outstanding for the ordering\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Review:\n",
      " Staying at Don Muang Airport Hostel is a good choice when you are visiting Anusawari The hostel has a very good location also near the Don Mueang International Airport DMK which is only 3.12 kilometers away This hostel is very easy to find since it is strategically positioned close to public facilities Don Muang Airport Hostel is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget Don Muang Airport Hostel is the perfect place to stay that provides decent facilities as well as great services Don Muang Airport Hostel is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Don Muang Airport Hostel is suitable for you who value privacy during your stay Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at Don Muang Airport Hostel 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends Don Muang Airport Hostel is a hostel with great comfort and excellent service according to most hostel s guests With all facilities offered Don Muang Airport Hostel is the right place to stay\n",
      "- Summary:\n",
      " easy to use\n",
      "\n",
      "\n",
      "- Review:\n",
      " Louis Tavern Hotel Bangkok is a hotel in a good neighborhood which is located at Lak Si The hotel has a very good location also near the Don Mueang Intl Airport Airport which is only 5.03 kilometers away The hotel is located only 8.55 kilometers away from Mo Chit BTS Station Station Not only well positioned but Louis Tavern Hotel Bangkok is also one of hotels near the following IT Square within 1.24 kilometers and Central Ramintra within 2.15 kilometers Louis Tavern Hotel Bangkok is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit When staying at a hotel the design and architecture are two important factors that can spoil your eyes With its unique setting Louis Tavern Hotel Bangkok provides a pleasant accommodation for your stay Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at Louis Tavern Hotel Bangkok Have an enjoyable and relaxing day at the pool whether you re traveling solo or with your loved ones WiFi is available within public areas of the property to help you to stay connected with family and friends Louis Tavern Hotel Bangkok is a hotel with great comfort and excellent service according to most hotel s guests With all facilities offered Louis Tavern Hotel Bangkok is the right place to stay\n",
      "- Summary:\n",
      " another crummy meal\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at 48 Ville Don Muang Airport is a good choice when you are visiting Anusawari The hotel has a very good location also near the Don Mueang International Airport DMK which is only 3.12 kilometers away This hotel is very easy to find since it is strategically positioned close to public facilities 48 Ville Don Muang Airport is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget 48 Ville Don Muang Airport is the perfect place to stay that provides decent facilities as well as great services 48 Ville Don Muang Airport is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit When staying at a hotel the design and architecture are two important factors that can spoil your eyes With its unique setting 48 Ville Don Muang Airport provides a pleasant accommodation for your stay Have fun with various entertaining facilities for you and the whole family at 48 Ville Don Muang Airport a wonderful accommodation for your family holiday While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation 48 Ville Don Muang Airport is suitable for you who value privacy during your stay Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at 48 Ville Don Muang Airport 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from 48 Ville Don Muang Airport exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends 48 Ville Don Muang Airport is a hotel with great comfort and excellent service according to most hotel s guests With all facilities offered 48 Ville Don Muang Airport is the right place to stay\n",
      "- Summary:\n",
      " the big big goes goes\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at The European Place is a good choice when you are visiting Lak Si The hotel has a very good location also near the Don Mueang International Airport DMK which is only 7.3 kilometers away The hotel is located only 7.56 kilometers away from Mo Chit BTS Station This hotel is very easy to find since it is strategically positioned close to public facilities The European Place is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget The European Place is the perfect place to stay that provides decent facilities as well as great services The European Place is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation The European Place is suitable for you who value privacy during your stay Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at The European Place 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends With all facilities offered The European Place is the right place to stay\n",
      "- Summary:\n",
      " i love this stuff\n",
      "\n",
      "\n",
      "- Review:\n",
      " Narra Hotel is a hotel in a good neighborhood which is located at Lak Si The hotel has a very good location also near the Don Mueang International Airport DMK which is only 5.32 kilometers away The hotel is located only 9.99 kilometers away from Mo Chit BTS Station Not only well positioned but Narra Hotel is also one of hotels near the following Chaeng Watthana Government Complex within 1.03 kilometers and Rajpruek Golf Club within 1.68 kilometers Narra Hotel is the splendid choice for you who are seeking a luxurious treat for your holiday Get pampered with the most excellent services and make your holiday memorable by staying here Have fun with various entertaining facilities for you and the whole family at Narra Hotel a wonderful accommodation for your family holiday Be ready to get the unforgettable stay experience by its exclusive service completed by a full range of facilities to cater all your needs The hotel s fitness center is a must try during your stay here Savor your favorite dishes with special cuisines from Narra Hotel exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends Get precious and unforgettable moment during your stay at Narra Hotel\n",
      "- Summary:\n",
      " a good buy\n",
      "\n",
      "\n",
      "- Review:\n",
      " The Riche Boutique Hotel is a hotel in a good neighborhood which is located at Lak Si The hotel has a very good location also near the Don Mueang International Airport DMK which is only 7 kilometers away The hotel is located only 7.51 kilometers away from Mo Chit BTS Station Not only well positioned but The Riche Boutique Hotel is also one of hotels near the following Kasetsart University within 2.6 kilometers and IT Square within 3.01 kilometers If you plan to have a long term stay staying at The Riche Boutique Hotel is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home Be ready to get the unforgettable stay experience by its exclusive service completed by a full range of facilities to cater all your needs Savor your favorite dishes with special cuisines from The Riche Boutique Hotel exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends The Riche Boutique Hotel is a hotel with great comfort and excellent service according to most hotel s guests Get precious and unforgettable moment during your stay at The Riche Boutique Hotel\n",
      "- Summary:\n",
      " my saver\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Review:\n",
      " TK Palace Hotel is a hotel in a good neighborhood which is located at Lak Si The hotel has a very good location also near the Don Mueang International Airport DMK which is only 5.41 kilometers away The hotel is located only 9.99 kilometers away from Mo Chit BTS Station Not only well positioned but TK Palace Hotel is also one of hotels near the following Chaeng Watthana Government Complex within 1.08 kilometers and Rajpruek Golf Club within 1.72 kilometers Whether you are planning an event or other special occasions TK Palace Hotel is a great choice for you with a large and well equipped function room to suit your requirements TK Palace Hotel is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit From business event to corporate gathering TK Palace Hotel provides complete services and facilities that you and your colleagues need Be ready to get the unforgettable stay experience by its exclusive service completed by a full range of facilities to cater all your needs 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from TK Palace Hotel exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends TK Palace Hotel is a hotel with great comfort and excellent service according to most hotel s guests Get precious and unforgettable moment during your stay at TK Palace Hotel\n",
      "- Summary:\n",
      " i favorite\n",
      "\n",
      "\n",
      "- Review:\n",
      " Rama Gardens Hotel Bangkok is a hotel in a good neighborhood which is located at Lak Si The hotel has a very good location also near the Don Mueang International Airport DMK which is only 6.72 kilometers away The hotel is located only 7.04 kilometers away from Mo Chit BTS Station Not only well positioned but Rama Gardens Hotel Bangkok is also one of hotels near the following Thung Song Hong Police Station within 0.51 kilometers and MOCA Museum of Contemporary Art within 1.56 kilometers Rama Gardens Hotel Bangkok is the splendid choice for you who are seeking a luxurious treat for your holiday Get pampered with the most excellent services and make your holiday memorable by staying here Rama Gardens Hotel Bangkok is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit From business event to corporate gathering Rama Gardens Hotel Bangkok provides complete services and facilities that you and your colleagues need Have fun with various entertaining facilities for you and the whole family at Rama Gardens Hotel Bangkok a wonderful accommodation for your family holiday If you plan to have a long term stay staying at Rama Gardens Hotel Bangkok is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home This hotel is the best spot for you who desire a serene and peaceful getaway far away from the crowds Be ready to get the unforgettable stay experience by its exclusive service completed by a full range of facilities to cater all your needs The hotel s fitness center is a must try during your stay here Have an enjoyable and relaxing day at the pool whether you re traveling solo or with your loved ones 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from Rama Gardens Hotel Bangkok exclusively for you Rama Gardens Hotel Bangkok is a hotel with great comfort and excellent service according to most hotel s guests Get precious and unforgettable moment during your stay at Rama Gardens Hotel Bangkok\n",
      "- Summary:\n",
      " the best carrot bar have found\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at Amari Don Muang Airport Bangkok is a good choice when you are visiting Don Mueang Airport The hotel has a very good location also near the Don Mueang International Airport DMK which is only 1.18 kilometers away This hotel is very easy to find since it is strategically positioned close to public facilities Whether you are planning an event or other special occasions Amari Don Muang Airport Bangkok is a great choice for you with a large and well equipped function room to suit your requirements Amari Don Muang Airport Bangkok is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit Be ready to get the unforgettable stay experience by its exclusive service completed by a full range of facilities to cater all your needs The hotel s fitness center is a must try during your stay here Have an enjoyable and relaxing day at the pool whether you re traveling solo or with your loved ones 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from Amari Don Muang Airport Bangkok exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends Amari Don Muang Airport Bangkok is a hotel with great comfort and excellent service according to most hotel s guests Get precious and unforgettable moment during your stay at Amari Don Muang Airport Bangkok\n",
      "- Summary:\n",
      " another crummy fast easy fast meal\n",
      "\n",
      "\n",
      "- Review:\n",
      " Staying at Centra by Centara Government Complex Hotel Convention Centre Chaeng Watthana is a good choice when you are visiting Lak Si The hotel has a very good location also near the Don Mueang International Airport DMK which is only 5.53 kilometers away The hotel is located only 9.12 kilometers away from Mo Chit BTS Station This hotel is very easy to find since it is strategically positioned close to public facilities Whether you are planning an event or other special occasions Centra by Centara Government Complex Hotel Convention Centre Chaeng Watthana is a great choice for you with a large and well equipped function room to suit your requirements From business event to corporate gathering Centra by Centara Government Complex Hotel Convention Centre Chaeng Watthana provides complete services and facilities that you and your colleagues need Be ready to get the unforgettable stay experience by its exclusive service completed by a full range of facilities to cater all your needs The hotel s fitness center is a must try during your stay here Savor your favorite dishes with special cuisines from Centra by Centara Government Complex Hotel Convention Centre Chaeng Watthana exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends Centra by Centara Government Complex Hotel Convention Centre Chaeng Watthana is a hotel with great comfort and excellent service according to most hotel s guests Get precious and unforgettable moment during your stay at Centra by Centara Government Complex Hotel Convention Centre Chaeng Watthana\n",
      "- Summary:\n",
      " quick easy meal\n",
      "\n",
      "\n",
      "- Review:\n",
      " note hotel was previously named Mida Airport Hotel Bangkok Donmueang Mida Hotel Don Mueang Airport Bangkok is located in area city Don Mueang Airport The hotel has a very good location also near the Don Mueang International Airport DMK which is only 3.97 kilometers away There are plenty of tourist attractions nearby such as IT Square within 0.57 kilometers and Chulabhorn Research Institute within 1.25 kilometers Whether you are planning an event or other special occasions Mida Hotel Don Mueang Airport Bangkok is a great choice for you with a large and well equipped function room to suit your requirements Are you a shopaholic Staying at Mida Hotel Don Mueang Airport Bangkok will surely spoil you for numerous shopping centers nearby Mida Hotel Don Mueang Airport Bangkok is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit From business event to corporate gathering Mida Hotel Don Mueang Airport Bangkok provides complete services and facilities that you and your colleagues need Have fun with various entertaining facilities for you and the whole family at Mida Hotel Don Mueang Airport Bangkok a wonderful accommodation for your family holiday If you plan to have a long term stay staying at Mida Hotel Don Mueang Airport Bangkok is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation Mida Hotel Don Mueang Airport Bangkok is suitable for you who value privacy during your stay Be ready to get the unforgettable stay experience by its exclusive service completed by a full range of facilities to cater all your needs 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from Mida Hotel Don Mueang Airport Bangkok exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends Mida Hotel Don Mueang Airport Bangkok is a hotel with great comfort and excellent service according to most hotel s guests Enjoy luxurious treats and incomparable experience by staying at Mida Hotel Don Mueang Airport Bangkok\n",
      "- Summary:\n",
      " makes a beat up the day\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Review:\n",
      " description\n",
      "- Summary:\n",
      " herbes receive herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes herbes\n",
      "\n",
      "\n",
      "- Review:\n",
      " SC Park Hotel is a hotel in a good neighborhood which is located at Phlabphla The hotel is located only 5.44 kilometers away from Phrom Phong BTS Station Not only well positioned but SC Park Hotel is also one of hotels near the following Mall Ramkhamhaeng within 1.87 kilometers and Ramkhamhaeng University within 2.08 kilometers The hotel s fitness center is a must try during your stay here Have an enjoyable and relaxing day at the pool whether you re traveling solo or with your loved ones 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you SC Park Hotel is a hotel with great comfort and excellent service according to most hotel s guests With all facilities offered SC Park Hotel is the right place to stay\n",
      "- Summary:\n",
      " another the day\n",
      "\n",
      "\n",
      "- Review:\n",
      " Banyan Tree Bangkok is a hotel in a good neighborhood which is located at Thung Maha Mek The hotel is located only 0.83 kilometers away from Sala Daeng BTS Station Not only well positioned but Banyan Tree Bangkok is also one of hotels near the following Embassy of Malaysia within 0.16 kilometers and Embassy of Australia within 0.22 kilometers Spend quality time at Banyan Tree Bangkok with your spouse Make it an unforgettable stay by enjoying all services and facilities that the hotel has to offer Banyan Tree Bangkok is the splendid choice for you who are seeking a luxurious treat for your holiday Get pampered with the most excellent services and make your holiday memorable by staying here From business event to corporate gathering Banyan Tree Bangkok provides complete services and facilities that you and your colleagues need Have fun with various entertaining facilities for you and the whole family at Banyan Tree Bangkok a wonderful accommodation for your family holiday If you plan to have a long term stay staying at Banyan Tree Bangkok is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home The highest quality service accompanying its extensive facilities will make you get the ultimate holiday experience The hotel s fitness center is a must try during your stay here Have an enjoyable and relaxing day at the pool whether you re traveling solo or with your loved ones Get the best deal for finest quality of spa treatment to unwind and rejuvenate yourself 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from Banyan Tree Bangkok exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends Banyan Tree Bangkok is a hotel with great comfort and excellent service according to most hotel s guests Get precious and unforgettable moment during your stay at Banyan Tree Bangkok\n",
      "- Summary:\n",
      " the best carrot bar have found\n",
      "\n",
      "\n",
      "- Review:\n",
      " The Quarter Ladprao by UHG is located in area city Chom Phon The hotel has a very good location also near the Don Mueang International Airport DMK which is only 12.2 kilometers away The hotel is located only 1.39 kilometers away from Mo Chit BTS Station There are plenty of tourist attractions nearby such as Union Mall within 0.13 kilometers and CentralPlaza Ladprao within 0.45 kilometers For you travelers who wish to travel comfortably on a budget The Quarter Ladprao by UHG is the perfect place to stay that provides decent facilities as well as great services Whether you are planning an event or other special occasions The Quarter Ladprao by UHG is a great choice for you with a large and well equipped function room to suit your requirements Are you a shopaholic Staying at The Quarter Ladprao by UHG will surely spoil you for numerous shopping centers nearby The Quarter Ladprao by UHG is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit Be ready to get the unforgettable stay experience by its exclusive service completed by a full range of facilities to cater all your needs The hotel s fitness center is a must try during your stay here Have an enjoyable and relaxing day at the pool whether you re traveling solo or with your loved ones 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from The Quarter Ladprao by UHG exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends Enjoy luxurious treats and incomparable experience by staying at The Quarter Ladprao by UHG\n",
      "- Summary:\n",
      " another happy cytomax time time\n",
      "\n",
      "\n",
      "- Review:\n",
      " Express Hostel is located in area city Yan Nawa The hostel is located only 0.27 kilometers away from Surasak BTS Station There are plenty of tourist attractions nearby such as Surasak BTS Station within 0.27 kilometers and Saint Louis Hospital within 0.58 kilometers Express Hostel is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time For you travelers who wish to travel comfortably on a budget Express Hostel is the perfect place to stay that provides decent facilities as well as great services From business event to corporate gathering Express Hostel provides complete services and facilities that you and your colleagues need Have fun with various entertaining facilities for you and the whole family at Express Hostel a wonderful accommodation for your family holiday Get the best deal for finest quality of spa treatment to unwind and rejuvenate yourself 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you WiFi is available within public areas of the property to help you to stay connected with family and friends Express Hostel is the ideal choice for you who are looking for a comfortable yet affordable accommodation\n",
      "- Summary:\n",
      " the best carrot bar have found\n",
      "\n",
      "\n",
      "- Review:\n",
      " ibis Bangkok Sathorn is a hotel in a good neighborhood which is located at Thung Maha Mek The hotel is located only 1.5 kilometers away from Sala Daeng BTS Station Not only well positioned but ibis Bangkok Sathorn is also one of hotels near the following Lumphini MRT Station within 0.53 kilometers and Embassy of Germany within 0.54 kilometers Splendid service together with wide range of facilities provided will make you complain for nothing during your stay at ibis Bangkok Sathorn 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from ibis Bangkok Sathorn exclusively for you ibis Bangkok Sathorn is a hotel with great comfort and excellent service according to most hotel s guests With all facilities offered ibis Bangkok Sathorn is the right place to stay\n",
      "- Summary:\n",
      " another crummy fast\n",
      "\n",
      "\n",
      "- Review:\n",
      " note hotel was previously named Amari Atrium Bankgok Staying at AVANI Atrium Bangkok Hotel is a good choice when you are visiting Makkasan The hotel is located only 1.51 kilometers away from Asok BTS Station This hotel is very easy to find since it is strategically positioned close to public facilities AVANI Atrium Bangkok Hotel is highly recommended for backpackers who want to get an affordable stay yet comfortable at the same time Whether you are planning an event or other special occasions AVANI Atrium Bangkok Hotel is a great choice for you with a large and well equipped function room to suit your requirements This hotel is the perfect choice for couples seeking a romantic getaway or a honeymoon retreat Enjoy the most memorable nights with your loved one by staying at AVANI Atrium Bangkok Hotel AVANI Atrium Bangkok Hotel is the splendid choice for you who are seeking a luxurious treat for your holiday Get pampered with the most excellent services and make your holiday memorable by staying here Are you a shopaholic Staying at AVANI Atrium Bangkok Hotel will surely spoil you for numerous shopping centers nearby From business event to corporate gathering AVANI Atrium Bangkok Hotel provides complete services and facilities that you and your colleagues need Have fun with various entertaining facilities for you and the whole family at AVANI Atrium Bangkok Hotel a wonderful accommodation for your family holiday If you plan to have a long term stay staying at AVANI Atrium Bangkok Hotel is the right choice for you Providing wide range of facilities and great service quality this accommodation certainly makes you feel at home While traveling with friends can be a lot of fun traveling solo has its own perks As for the accommodation AVANI Atrium Bangkok Hotel is suitable for you who value privacy during your stay The highest quality service accompanying its extensive facilities will make you get the ultimate holiday experience The hotel s fitness center is a must try during your stay here Have an enjoyable and relaxing day at the pool whether you re traveling solo or with your loved ones 24 hours front desk is available to serve you from check in to check out or any assistance you need Should you desire more do not hesitate to ask the front desk we are always ready to accommodate you Savor your favorite dishes with special cuisines from AVANI Atrium Bangkok Hotel exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends AVANI Atrium Bangkok Hotel is a hotel with great comfort and excellent service according to most hotel s guests Get precious and unforgettable moment during your stay at AVANI Atrium Bangkok Hotel\n",
      "- Summary:\n",
      " the best carrot bar have found\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Review:\n",
      "\r",
      " Staying at QG Resort is a good choice when you are visiting Suvarnabhumi Airport The resort has a very good location also near the Suvarnabhumi International Airport BKK which is only 5.41 kilometers away This resort is very easy to find since it is strategically positioned close to public facilities QG Resort is a hotel near Airport an ideal accommodation while waiting for your next flight Enjoy a satisfying place to rest during your transit When staying at a resort the design and architecture are two important factors that can spoil your eyes With its unique setting QG Resort provides a pleasant accommodation for your stay QG Resort is the smartest choice for you who are looking for affordable accommodation with outstanding service Savor your favorite dishes with special cuisines from QG Resort exclusively for you WiFi is available within public areas of the property to help you to stay connected with family and friends Staying at QG Resort will surely satisfy you with its great hospitality and affordable price\n",
      "- Summary:\n",
      "\r",
      " pure by by the time\n",
      "\r\n",
      "\r\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "assertion failed: [All values in memory_sequence_length must greater than zero.] [Condition x > 0 did not hold element-wise:] [x (text_length:0) = ] [0 0 0...]\n\t [[node decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert (defined at <ipython-input-120-aa75814a47dc>:18)  = Assert[T=[DT_STRING, DT_STRING, DT_STRING, DT_INT32], summarize=3, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/All/_175, decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert/data_0, decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert/data_1, decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert/data_2, decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Less/Enter/_177)]]\n\nCaused by op u'decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/lib64/python2.7/site-packages/tornado/ioloop.py\", line 1073, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-120-aa75814a47dc>\", line 18, in <module>\n    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1674, in import_meta_graph\n    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1696, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.py\", line 806, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): assertion failed: [All values in memory_sequence_length must greater than zero.] [Condition x > 0 did not hold element-wise:] [x (text_length:0) = ] [0 0 0...]\n\t [[node decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert (defined at <ipython-input-120-aa75814a47dc>:18)  = Assert[T=[DT_STRING, DT_STRING, DT_STRING, DT_INT32], summarize=3, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/All/_175, decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert/data_0, decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert/data_1, decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert/data_2, decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Less/Enter/_177)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-aa75814a47dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m                                           \u001b[0msummary_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgeneragte_summary_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#summary_length: [np.random.randint(5,8)],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                           \u001b[0mtext_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                                           keep_prob: 1.0})[0] \n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Remove the padding from the summaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<PAD>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: assertion failed: [All values in memory_sequence_length must greater than zero.] [Condition x > 0 did not hold element-wise:] [x (text_length:0) = ] [0 0 0...]\n\t [[node decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert (defined at <ipython-input-120-aa75814a47dc>:18)  = Assert[T=[DT_STRING, DT_STRING, DT_STRING, DT_INT32], summarize=3, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/All/_175, decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert/data_0, decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert/data_1, decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert/data_2, decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Less/Enter/_177)]]\n\nCaused by op u'decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/lib64/python2.7/site-packages/tornado/ioloop.py\", line 1073, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-120-aa75814a47dc>\", line 18, in <module>\n    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1674, in import_meta_graph\n    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1696, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.py\", line 806, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3440, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3299, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): assertion failed: [All values in memory_sequence_length must greater than zero.] [Condition x > 0 did not hold element-wise:] [x (text_length:0) = ] [0 0 0...]\n\t [[node decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert (defined at <ipython-input-120-aa75814a47dc>:18)  = Assert[T=[DT_STRING, DT_STRING, DT_STRING, DT_INT32], summarize=3, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/All/_175, decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert/data_0, decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert/data_1, decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Assert/Assert/data_2, decode/decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_positive_1/assert_less/Less/Enter/_177)]]\n"
     ]
    }
   ],
   "source": [
    "input_sentences=[\"The coffee tasted great and was at such a good price! I highly recommend this to everyone!\",\n",
    "               \"love individual oatmeal cups found years ago sam quit selling sound big lots quit selling found target expensive buy individually trilled get entire case time go anywhere need water microwave spoon know quaker flavor packets\"]\n",
    "\n",
    "input_sentences = hotel_docs\n",
    "generagte_summary_length =  [100] * len(input_sentences)\n",
    "texts = [text_to_seq(input_sentence) for input_sentence in input_sentences]\n",
    "checkpoint = \"./best_model.ckpt\"\n",
    "print(len(generagte_summary_length))\n",
    "if type(generagte_summary_length) is list:\n",
    "    if len(input_sentences)!=len(generagte_summary_length):\n",
    "        raise Exception(\"[Error] makeSummaries parameter generagte_summary_length must be same length as input_sentences or an integer\")\n",
    "    generagte_summary_length_list = generagte_summary_length\n",
    "else:\n",
    "    generagte_summary_length_list = [generagte_summary_length] * len(texts)\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
    "    loader.restore(sess, checkpoint)\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    text_length = loaded_graph.get_tensor_by_name('text_length:0')\n",
    "    summary_length = loaded_graph.get_tensor_by_name('summary_length:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    #Multiply by batch_size to match the model's input parameters\n",
    "    for i, text in enumerate(texts):\n",
    "        generagte_summary_length = generagte_summary_length_list[i]\n",
    "        answer_logits = sess.run(logits, {input_data: [text]*batch_size, \n",
    "                                          summary_length: [generagte_summary_length], #summary_length: [np.random.randint(5,8)], \n",
    "                                          text_length: [len(text)]*batch_size,\n",
    "                                          keep_prob: 1.0})[0] \n",
    "        # Remove the padding from the summaries\n",
    "        pad = vocab_to_int[\"<PAD>\"] \n",
    "        print('- Review:\\n\\r {}'.format(input_sentences[i]))\n",
    "        print('- Summary:\\n\\r {}\\n\\r\\n\\r'.format(\" \".join([int_to_vocab[i] for i in answer_logits if i != pad])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope that you found this project to be rather interesting and informative. One of my main recommendations for working with this dataset and model is either use a GPU, a subset of the dataset, or plenty of time to train your model. As you might be able to expect, the model will not be able to make good predictions just by seeing many reviews, it needs so see the reviews many times to be able to understand the relationship between words and between descriptions & summaries. \n",
    "\n",
    "In short, I'm pleased with how well this model performs. After creating numerous reviews and checking those from the dataset, I can happily say that most of the generated summaries are appropriate, some of them are great, and some of them make mistakes. I'll try to improve this model and if it gets better, I'll update my GitHub.\n",
    "\n",
    "Thanks for reading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
